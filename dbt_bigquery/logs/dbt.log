2021-07-13 17:28:42.952537 (MainThread): Running with dbt=0.19.2
2021-07-13 17:28:43.614192 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 17:28:43.616293 (MainThread): Tracking: tracking
2021-07-13 17:28:43.629711 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff03356ac40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff041d6ca00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff03357d3d0>]}
2021-07-13 17:28:43.642524 (MainThread): Partial parsing not enabled
2021-07-13 17:28:43.644400 (MainThread): Parsing macros/adapters.sql
2021-07-13 17:28:43.664306 (MainThread): Parsing macros/catalog.sql
2021-07-13 17:28:43.670077 (MainThread): Parsing macros/etc.sql
2021-07-13 17:28:43.672496 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 17:28:43.677124 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 17:28:43.688657 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 17:28:43.691303 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 17:28:43.693124 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 17:28:43.701497 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 17:28:43.706252 (MainThread): Parsing macros/core.sql
2021-07-13 17:28:43.709701 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 17:28:43.745170 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 17:28:43.752371 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 17:28:43.753366 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 17:28:43.754892 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 17:28:43.756647 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 17:28:43.758101 (MainThread): Parsing macros/etc/query.sql
2021-07-13 17:28:43.759142 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 17:28:43.766537 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 17:28:43.777578 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 17:28:43.779340 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 17:28:43.784565 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 17:28:43.802823 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 17:28:43.827787 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 17:28:43.829500 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 17:28:43.843381 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 17:28:43.848739 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 17:28:43.852799 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 17:28:43.857701 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 17:28:43.860115 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 17:28:43.862561 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 17:28:43.864243 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 17:28:43.870335 (MainThread): Partial parsing not enabled
2021-07-13 17:28:44.120058 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging
- models.spotify_project

2021-07-13 17:28:44.123986 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd615fd0-6502-4a8c-95d2-5cfa1890ec0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff03346eb80>]}
2021-07-13 17:28:44.130696 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd615fd0-6502-4a8c-95d2-5cfa1890ec0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff03341d340>]}
2021-07-13 17:28:44.131040 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-13 17:28:44.131800 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-13 17:28:44.132380 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0334cc460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0334cca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0334cc400>]}
2021-07-13 17:28:44.132698 (MainThread): Flushing usage events
2021-07-13 17:30:51.507074 (MainThread): Running with dbt=0.19.2
2021-07-13 17:30:52.170794 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 17:30:52.171842 (MainThread): Tracking: tracking
2021-07-13 17:30:52.186150 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a65ae5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a742def70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a65af9310>]}
2021-07-13 17:30:52.199932 (MainThread): Partial parsing not enabled
2021-07-13 17:30:52.202258 (MainThread): Parsing macros/adapters.sql
2021-07-13 17:30:52.224467 (MainThread): Parsing macros/catalog.sql
2021-07-13 17:30:52.230533 (MainThread): Parsing macros/etc.sql
2021-07-13 17:30:52.232926 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 17:30:52.237717 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 17:30:52.249894 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 17:30:52.252659 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 17:30:52.254549 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 17:30:52.263211 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 17:30:52.267226 (MainThread): Parsing macros/core.sql
2021-07-13 17:30:52.270597 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 17:30:52.305173 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 17:30:52.312267 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 17:30:52.313227 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 17:30:52.314709 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 17:30:52.316474 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 17:30:52.317892 (MainThread): Parsing macros/etc/query.sql
2021-07-13 17:30:52.318936 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 17:30:52.326402 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 17:30:52.337307 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 17:30:52.339074 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 17:30:52.344297 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 17:30:52.360388 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 17:30:52.384125 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 17:30:52.385757 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 17:30:52.399465 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 17:30:52.404710 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 17:30:52.408737 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 17:30:52.413623 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 17:30:52.415899 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 17:30:52.417274 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 17:30:52.418909 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 17:30:52.425183 (MainThread): Partial parsing not enabled
2021-07-13 17:30:52.638014 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:30:52.648933 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 17:30:52.654406 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:30:52.665894 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:30:52.756195 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e5373b5-0822-40a0-8704-27030666c4b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a65832f70>]}
2021-07-13 17:30:52.761609 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e5373b5-0822-40a0-8704-27030666c4b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a65830eb0>]}
2021-07-13 17:30:52.761908 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 17:30:52.763194 (MainThread): 
2021-07-13 17:30:52.763633 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:30:52.764666 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 17:30:52.764963 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 17:30:53.170002 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 17:30:53.170788 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 17:30:53.184610 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 17:30:53.549834 (MainThread): 12:30:53 | Concurrency: 1 threads (target='prod')
2021-07-13 17:30:53.551347 (MainThread): 12:30:53 | 
2021-07-13 17:30:53.579540 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 17:30:53.580466 (Thread-1): 12:30:53 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 17:30:53.582538 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:30:53.583224 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 17:30:53.590111 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:30:53.598146 (Thread-1): finished collecting timing info
2021-07-13 17:30:53.653300 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:30:53.655638 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:30:53.662153 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 17:30:54.569752 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/4c08c51f-2b3e-48c9-b55f-91cbed99c84d?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]')
2021-07-13 17:30:56.278941 (Thread-1): finished collecting timing info
2021-07-13 17:30:56.281482 (Thread-1): Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/9593240d-3214-4cf9-82a2-11b8da6b2ca1?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]

(job ID: 9593240d-3214-4cf9-82a2-11b8da6b2ca1)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 17:30:56.315588 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5373b5-0822-40a0-8704-27030666c4b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a658fe190>]}
2021-07-13 17:30:56.316753 (Thread-1): 12:30:56 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 2.73s]
2021-07-13 17:30:56.336245 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 17:30:56.336901 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 17:30:56.338227 (Thread-1): 12:30:56 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 17:30:56.339864 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:30:56.340202 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 17:30:56.342100 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58855, 0, 0), raddr=('2607:f8b0:4000:801::200a', 443, 0, 0)>
2021-07-13 17:30:56.342885 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58856, 0, 0), raddr=('2607:f8b0:4000:800::200a', 443, 0, 0)>
2021-07-13 17:30:56.349073 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:30:56.353031 (Thread-1): finished collecting timing info
2021-07-13 17:30:56.361765 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:30:56.367686 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:30:56.385052 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY')) AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 17:30:56.878284 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/e7efb240-853d-4eeb-8cd2-f1757cf186b9?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ")" at [13:46]')
2021-07-13 17:30:57.441532 (Thread-1): finished collecting timing info
2021-07-13 17:30:57.442987 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Syntax error: Expected end of input but got ")" at [13:46]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/c66e42a7-f6ab-4488-aa4e-44808a20f40f?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ")" at [13:46]

(job ID: c66e42a7-f6ab-4488-aa4e-44808a20f40f)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY')) AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Syntax error: Expected end of input but got ")" at [13:46]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:30:57.446066 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5373b5-0822-40a0-8704-27030666c4b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a64e6ee50>]}
2021-07-13 17:30:57.447180 (Thread-1): 12:30:57 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 1.11s]
2021-07-13 17:30:57.449303 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 17:30:57.449926 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 17:30:57.451043 (Thread-1): 12:30:57 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 17:30:57.452602 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 17:30:57.453173 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 17:30:57.454019 (Thread-1): 12:30:57 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 17:30:57.455540 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 17:30:57.462689 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:30:57.464271 (MainThread): 12:30:57 | 
2021-07-13 17:30:57.465420 (MainThread): 12:30:57 | Finished running 4 view models in 4.70s.
2021-07-13 17:30:57.466488 (MainThread): Connection 'master' was properly closed.
2021-07-13 17:30:57.466904 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 17:30:57.473437 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58852, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 17:30:57.474532 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58851, 0, 0), raddr=('2607:f8b0:4000:807::200a', 443, 0, 0)>
2021-07-13 17:30:57.475484 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58853, 0, 0), raddr=('2607:f8b0:4000:801::200a', 443, 0, 0)>
2021-07-13 17:30:57.476460 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58854, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 17:30:57.481462 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58857, 0, 0), raddr=('2607:f8b0:4000:807::200a', 443, 0, 0)>
2021-07-13 17:30:57.482537 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58858, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 17:30:57.504483 (MainThread): 
2021-07-13 17:30:57.505618 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 17:30:57.506842 (MainThread): 
2021-07-13 17:30:57.507832 (MainThread): Database Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 17:30:57.508733 (MainThread):   Type not found: varchar at [12:30]
2021-07-13 17:30:57.509710 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 17:30:57.510541 (MainThread): 
2021-07-13 17:30:57.511212 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 17:30:57.512097 (MainThread):   Syntax error: Expected end of input but got ")" at [13:46]
2021-07-13 17:30:57.514632 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:30:57.516586 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 17:30:57.535640 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6580ba30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a659ba550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a65807100>]}
2021-07-13 17:30:57.536251 (MainThread): Flushing usage events
2021-07-13 17:35:26.835477 (MainThread): Running with dbt=0.19.2
2021-07-13 17:35:27.496666 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 17:35:27.497897 (MainThread): Tracking: tracking
2021-07-13 17:35:27.513483 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9e31d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feec862cbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9e473a0>]}
2021-07-13 17:35:27.526749 (MainThread): Partial parsing not enabled
2021-07-13 17:35:27.528384 (MainThread): Parsing macros/adapters.sql
2021-07-13 17:35:27.548480 (MainThread): Parsing macros/catalog.sql
2021-07-13 17:35:27.554268 (MainThread): Parsing macros/etc.sql
2021-07-13 17:35:27.556828 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 17:35:27.564122 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 17:35:27.575756 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 17:35:27.578341 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 17:35:27.580118 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 17:35:27.588450 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 17:35:27.592715 (MainThread): Parsing macros/core.sql
2021-07-13 17:35:27.596131 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 17:35:27.630719 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 17:35:27.637760 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 17:35:27.638689 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 17:35:27.640198 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 17:35:27.641937 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 17:35:27.643384 (MainThread): Parsing macros/etc/query.sql
2021-07-13 17:35:27.644409 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 17:35:27.651728 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 17:35:27.662578 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 17:35:27.664157 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 17:35:27.669142 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 17:35:27.685073 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 17:35:27.709418 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 17:35:27.711000 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 17:35:27.724555 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 17:35:27.729710 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 17:35:27.734505 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 17:35:27.739532 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 17:35:27.741848 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 17:35:27.743285 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 17:35:27.744942 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 17:35:27.751375 (MainThread): Partial parsing not enabled
2021-07-13 17:35:27.966172 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:35:27.976429 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 17:35:27.980301 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:35:27.983965 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:35:28.065151 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9ff27b72-590e-4b89-950b-aa5ba491f66d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9b813a0>]}
2021-07-13 17:35:28.070382 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9ff27b72-590e-4b89-950b-aa5ba491f66d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9b7a0d0>]}
2021-07-13 17:35:28.070691 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 17:35:28.071964 (MainThread): 
2021-07-13 17:35:28.072459 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:35:28.073507 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 17:35:28.073707 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 17:35:28.444154 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 17:35:28.444813 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 17:35:28.459688 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 17:35:28.792179 (MainThread): 12:35:28 | Concurrency: 1 threads (target='prod')
2021-07-13 17:35:28.793631 (MainThread): 12:35:28 | 
2021-07-13 17:35:28.821204 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 17:35:28.822072 (Thread-1): 12:35:28 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 17:35:28.823717 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:35:28.824536 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 17:35:28.831671 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:35:28.834091 (Thread-1): finished collecting timing info
2021-07-13 17:35:28.895341 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:35:28.896508 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:35:28.901616 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS string) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 17:35:29.961862 (Thread-1): finished collecting timing info
2021-07-13 17:35:29.962931 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ff27b72-590e-4b89-950b-aa5ba491f66d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9bf6070>]}
2021-07-13 17:35:29.963887 (Thread-1): 12:35:29 | 1 of 4 OK created view model tap_csv.stg_artists..................... [OK in 1.14s]
2021-07-13 17:35:29.965392 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 17:35:29.965844 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 17:35:29.966706 (Thread-1): 12:35:29 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 17:35:29.968331 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:35:29.968819 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 17:35:29.970534 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55656, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 17:35:29.971093 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55657, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 17:35:29.976362 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:35:29.978621 (Thread-1): finished collecting timing info
2021-07-13 17:35:29.983599 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:35:29.985951 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:35:29.999205 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		PARSE_DATE('%Y', release_date)) AS release_year,
		CAST(danceability AS float64) AS danceability,
		CAST(energy AS float64) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float64) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float64) AS speechiness,
		CAST(acousticness AS float64) AS acousticness,
		CAST(instrumentalness AS float64) AS instrumentalness,
		CAST(liveness AS float64) AS liveness,
		CAST(valence AS float64) AS valence,
		CAST(tempo AS float64) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 17:35:30.493518 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/8e0eab50-6fde-4aec-8d53-2b1e2729cf4c?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ")" at [13:47]')
2021-07-13 17:35:31.775026 (Thread-1): finished collecting timing info
2021-07-13 17:35:31.776404 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Syntax error: Expected end of input but got ")" at [13:47]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/b57bec27-0e0c-4468-986a-bd917dc2f58b?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ")" at [13:47]

(job ID: b57bec27-0e0c-4468-986a-bd917dc2f58b)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		PARSE_DATE('%Y', release_date)) AS release_year,
  14:		CAST(danceability AS float64) AS danceability,
  15:		CAST(energy AS float64) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float64) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float64) AS speechiness,
  20:		CAST(acousticness AS float64) AS acousticness,
  21:		CAST(instrumentalness AS float64) AS instrumentalness,
  22:		CAST(liveness AS float64) AS liveness,
  23:		CAST(valence AS float64) AS valence,
  24:		CAST(tempo AS float64) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Syntax error: Expected end of input but got ")" at [13:47]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:35:31.799923 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ff27b72-590e-4b89-950b-aa5ba491f66d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb92bee50>]}
2021-07-13 17:35:31.801003 (Thread-1): 12:35:31 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 1.83s]
2021-07-13 17:35:31.802694 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 17:35:31.803263 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 17:35:31.804742 (Thread-1): 12:35:31 | 3 of 4 START view model tap_csv.top20_artist_genres.................. [RUN]
2021-07-13 17:35:31.806408 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:35:31.806958 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 17:35:31.814970 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55653, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 17:35:31.815732 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55652, 0, 0), raddr=('2607:f8b0:4000:807::200a', 443, 0, 0)>
2021-07-13 17:35:31.816429 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55654, 0, 0), raddr=('2607:f8b0:4000:80a::200a', 443, 0, 0)>
2021-07-13 17:35:31.817016 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55655, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 17:35:31.821651 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55659, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 17:35:31.822335 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55658, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 17:35:31.827166 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 17:35:31.833047 (Thread-1): finished collecting timing info
2021-07-13 17:35:31.839323 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 17:35:31.844481 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:35:31.865827 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
),
cte2 AS
(
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		rnk_followers,
		REPLACE(
			UNNEST(
				string_to_array(
					REPLACE(
						REPLACE(genres,'[',''),
					']',''),
				', '))
			, '''', '') AS genres
FROM cte1
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		CAST(genres AS VARCHAR) AS genres
FROM cte2
WHERE rnk_followers<=20;


2021-07-13 17:35:32.440264 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/c13942c6-1d21-4ef9-a46b-3f2600310c54?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword UNNEST at [20:25]')
2021-07-13 17:35:33.738805 (Thread-1): finished collecting timing info
2021-07-13 17:35:33.741010 (Thread-1): Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [20:25]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/d5efdaef-8626-44fb-a291-2efbfc2abdd6?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword UNNEST at [20:25]

(job ID: d5efdaef-8626-44fb-a291-2efbfc2abdd6)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
   5:  OPTIONS()
   6:  as WITH cte1 AS
   7:(
   8:SELECT *,
   9:		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
  10:FROM `spotify600k`.`tap_csv`.`stg_artists`
  11:),
  12:cte2 AS
  13:(
  14:SELECT artist_id,
  15:		artist_name,
  16:		followers,
  17:		artist_popularity,
  18:		rnk_followers,
  19:		REPLACE(
  20:			UNNEST(
  21:				string_to_array(
  22:					REPLACE(
  23:						REPLACE(genres,'[',''),
  24:					']',''),
  25:				', '))
  26:			, '''', '') AS genres
  27:FROM cte1
  28:)
  29:SELECT artist_id,
  30:		artist_name,
  31:		followers,
  32:		artist_popularity,
  33:		CAST(genres AS VARCHAR) AS genres
  34:FROM cte2
  35:WHERE rnk_followers<=20;
  36:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [20:25]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
2021-07-13 17:35:33.747195 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ff27b72-590e-4b89-950b-aa5ba491f66d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb91632b0>]}
2021-07-13 17:35:33.748536 (Thread-1): 12:35:33 | 3 of 4 ERROR creating view model tap_csv.top20_artist_genres......... [ERROR in 1.94s]
2021-07-13 17:35:33.750845 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 17:35:33.751561 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 17:35:33.752714 (Thread-1): 12:35:33 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 17:35:33.754108 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 17:35:33.762722 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:35:33.764303 (MainThread): 12:35:33 | 
2021-07-13 17:35:33.765600 (MainThread): 12:35:33 | Finished running 4 view models in 5.69s.
2021-07-13 17:35:33.766839 (MainThread): Connection 'master' was properly closed.
2021-07-13 17:35:33.767318 (MainThread): Connection 'model.spotify_project.top20_artist_genres' was properly closed.
2021-07-13 17:35:33.789601 (MainThread): 
2021-07-13 17:35:33.791683 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 17:35:33.793788 (MainThread): 
2021-07-13 17:35:33.795424 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 17:35:33.796737 (MainThread):   Syntax error: Expected end of input but got ")" at [13:47]
2021-07-13 17:35:33.797719 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:35:33.798645 (MainThread): 
2021-07-13 17:35:33.799919 (MainThread): Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
2021-07-13 17:35:33.800953 (MainThread):   Syntax error: Expected ")" but got keyword UNNEST at [20:25]
2021-07-13 17:35:33.802052 (MainThread):   compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
2021-07-13 17:35:33.804872 (MainThread): 
Done. PASS=1 WARN=0 ERROR=2 SKIP=1 TOTAL=4
2021-07-13 17:35:33.811040 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9cede80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9b56460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeb9b56190>]}
2021-07-13 17:35:33.812630 (MainThread): Flushing usage events
2021-07-13 17:36:24.088850 (MainThread): Running with dbt=0.19.2
2021-07-13 17:36:24.746502 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 17:36:24.747551 (MainThread): Tracking: tracking
2021-07-13 17:36:24.763929 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391d94ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03b08bd220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391daa400>]}
2021-07-13 17:36:24.782510 (MainThread): Partial parsing not enabled
2021-07-13 17:36:24.784219 (MainThread): Parsing macros/adapters.sql
2021-07-13 17:36:24.804616 (MainThread): Parsing macros/catalog.sql
2021-07-13 17:36:24.811720 (MainThread): Parsing macros/etc.sql
2021-07-13 17:36:24.815238 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 17:36:24.822721 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 17:36:24.833709 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 17:36:24.836122 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 17:36:24.837768 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 17:36:24.845826 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 17:36:24.849702 (MainThread): Parsing macros/core.sql
2021-07-13 17:36:24.852942 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 17:36:24.888305 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 17:36:24.895166 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 17:36:24.896066 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 17:36:24.897526 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 17:36:24.899189 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 17:36:24.900561 (MainThread): Parsing macros/etc/query.sql
2021-07-13 17:36:24.901554 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 17:36:24.908765 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 17:36:24.919685 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 17:36:24.921330 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 17:36:24.926582 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 17:36:24.943806 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 17:36:24.968264 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 17:36:24.969900 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 17:36:24.983725 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 17:36:24.988884 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 17:36:24.992925 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 17:36:24.997957 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 17:36:25.000229 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 17:36:25.001631 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 17:36:25.003290 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 17:36:25.009489 (MainThread): Partial parsing not enabled
2021-07-13 17:36:25.221626 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:36:25.230973 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 17:36:25.234814 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:36:25.238513 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:36:25.310206 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391ae13a0>]}
2021-07-13 17:36:25.315159 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391ad9100>]}
2021-07-13 17:36:25.315471 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 17:36:25.317060 (MainThread): 
2021-07-13 17:36:25.317612 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:36:25.318839 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 17:36:25.319152 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 17:36:25.704727 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 17:36:25.705517 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 17:36:25.720912 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 17:36:26.150706 (MainThread): 12:36:26 | Concurrency: 1 threads (target='prod')
2021-07-13 17:36:26.152237 (MainThread): 12:36:26 | 
2021-07-13 17:36:26.182498 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 17:36:26.183477 (Thread-1): 12:36:26 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 17:36:26.184961 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:36:26.185600 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 17:36:26.195027 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:36:26.197494 (Thread-1): finished collecting timing info
2021-07-13 17:36:26.267548 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:36:26.268745 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:36:26.273807 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS string) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 17:36:27.346025 (Thread-1): finished collecting timing info
2021-07-13 17:36:27.347336 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391b5f190>]}
2021-07-13 17:36:27.348403 (Thread-1): 12:36:27 | 1 of 4 OK created view model tap_csv.stg_artists..................... [OK in 1.16s]
2021-07-13 17:36:27.350232 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 17:36:27.350800 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 17:36:27.352103 (Thread-1): 12:36:27 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 17:36:27.353791 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:36:27.354243 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 17:36:27.356563 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55795, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 17:36:27.357558 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55796, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 17:36:27.364130 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:36:27.366466 (Thread-1): finished collecting timing info
2021-07-13 17:36:27.373007 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:36:27.376108 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:36:27.390301 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		PARSE_DATE('%Y', release_date) AS release_year,
		CAST(danceability AS float64) AS danceability,
		CAST(energy AS float64) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float64) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float64) AS speechiness,
		CAST(acousticness AS float64) AS acousticness,
		CAST(instrumentalness AS float64) AS instrumentalness,
		CAST(liveness AS float64) AS liveness,
		CAST(valence AS float64) AS valence,
		CAST(tempo AS float64) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 17:36:28.390743 (Thread-1): finished collecting timing info
2021-07-13 17:36:28.392042 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391b552b0>]}
2021-07-13 17:36:28.393078 (Thread-1): 12:36:28 | 2 of 4 OK created view model tap_csv.stg_tracks...................... [OK in 1.04s]
2021-07-13 17:36:28.394922 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 17:36:28.395473 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 17:36:28.396525 (Thread-1): 12:36:28 | 3 of 4 START view model tap_csv.top20_artist_genres.................. [RUN]
2021-07-13 17:36:28.398092 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:36:28.398524 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 17:36:28.405375 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 17:36:28.408779 (Thread-1): finished collecting timing info
2021-07-13 17:36:28.412186 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55792, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 17:36:28.413092 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55791, 0, 0), raddr=('2607:f8b0:4000:801::200a', 443, 0, 0)>
2021-07-13 17:36:28.413874 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55793, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 17:36:28.414358 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55794, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 17:36:28.419112 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55798, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 17:36:28.419840 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55797, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 17:36:28.427897 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 17:36:28.430564 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:36:28.446271 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
),
cte2 AS
(
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		rnk_followers,
		REPLACE(
			UNNEST(
				string_to_array(
					REPLACE(
						REPLACE(genres,'[',''),
					']',''),
				', '))
			, '''', '') AS genres
FROM cte1
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		CAST(genres AS VARCHAR) AS genres
FROM cte2
WHERE rnk_followers<=20;


2021-07-13 17:36:28.966271 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/bad4c564-2fcc-4ed3-a040-cfb792747d49?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword UNNEST at [20:25]')
2021-07-13 17:36:30.289445 (Thread-1): finished collecting timing info
2021-07-13 17:36:30.290854 (Thread-1): Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [20:25]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/20803414-1fd5-477e-8ec6-b45fdf3dd88e?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword UNNEST at [20:25]

(job ID: 20803414-1fd5-477e-8ec6-b45fdf3dd88e)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
   5:  OPTIONS()
   6:  as WITH cte1 AS
   7:(
   8:SELECT *,
   9:		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
  10:FROM `spotify600k`.`tap_csv`.`stg_artists`
  11:),
  12:cte2 AS
  13:(
  14:SELECT artist_id,
  15:		artist_name,
  16:		followers,
  17:		artist_popularity,
  18:		rnk_followers,
  19:		REPLACE(
  20:			UNNEST(
  21:				string_to_array(
  22:					REPLACE(
  23:						REPLACE(genres,'[',''),
  24:					']',''),
  25:				', '))
  26:			, '''', '') AS genres
  27:FROM cte1
  28:)
  29:SELECT artist_id,
  30:		artist_name,
  31:		followers,
  32:		artist_popularity,
  33:		CAST(genres AS VARCHAR) AS genres
  34:FROM cte2
  35:WHERE rnk_followers<=20;
  36:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [20:25]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
2021-07-13 17:36:30.310460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03911c69a0>]}
2021-07-13 17:36:30.311462 (Thread-1): 12:36:30 | 3 of 4 ERROR creating view model tap_csv.top20_artist_genres......... [ERROR in 1.91s]
2021-07-13 17:36:30.313108 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 17:36:30.313604 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 17:36:30.314699 (Thread-1): 12:36:30 | 4 of 4 START view model tap_csv.top20_artist_tracks.................. [RUN]
2021-07-13 17:36:30.316123 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 17:36:30.316521 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-13 17:36:30.324529 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 17:36:30.327982 (Thread-1): finished collecting timing info
2021-07-13 17:36:30.333816 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 17:36:30.337421 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:36:30.352409 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_tracks`
  OPTIONS()
  as WITH cte1 AS
(
SELECT unnest(
			string_to_array(
			REPLACE(REPLACE(artist_id,'[',''),']',''),',')) AS new_artist_id,
		*
FROM `spotify600k`.`tap_csv`.`stg_tracks`
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=20;


2021-07-13 17:36:30.884296 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/eaa45e3d-9eb5-47af-812d-455e1e0fbbc0?maxResults=0&location=US&prettyPrint=false: Syntax error: Unexpected keyword UNNEST at [8:8]')
2021-07-13 17:36:32.168533 (Thread-1): finished collecting timing info
2021-07-13 17:36:32.169984 (Thread-1): Database Error in model top20_artist_tracks (models/analysis/top20_artist_tracks.sql)
  Syntax error: Unexpected keyword UNNEST at [8:8]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/3043e8cf-3ffa-40f8-bbb9-4b8ec11bac0a?maxResults=0&location=US&prettyPrint=false: Syntax error: Unexpected keyword UNNEST at [8:8]

(job ID: 3043e8cf-3ffa-40f8-bbb9-4b8ec11bac0a)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`top20_artist_tracks`
   5:  OPTIONS()
   6:  as WITH cte1 AS
   7:(
   8:SELECT unnest(
   9:			string_to_array(
  10:			REPLACE(REPLACE(artist_id,'[',''),']',''),',')) AS new_artist_id,
  11:		*
  12:FROM `spotify600k`.`tap_csv`.`stg_tracks`
  13:),
  14:cte2 AS
  15:(
  16:SELECT *,
  17:		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
  18:FROM `spotify600k`.`tap_csv`.`stg_artists`
  19:)
  20:SELECT c2.artist_id,
  21:		c2.artist_name,
  22:		c2.followers,
  23:		c2.artist_popularity,
  24:		c1.track_id,
  25:		c1.track_name,
  26:		c1.track_popularity,
  27:		c1.release_year,
  28:		c1.explicit,
  29:		c1.danceability,
  30:		c1.energy,
  31:		c1.speechiness,
  32:		c1.acousticness,
  33:		c1.instrumentalness,
  34:		c1.liveness,
  35:		c1.valence
  36:FROM cte1 c1
  37:INNER JOIN cte2 c2
  38:ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
  39:WHERE c2.rnk_followers<=20;
  40:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model top20_artist_tracks (models/analysis/top20_artist_tracks.sql)
  Syntax error: Unexpected keyword UNNEST at [8:8]
  compiled SQL at target/run/spotify_project/models/analysis/top20_artist_tracks.sql
2021-07-13 17:36:32.173771 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a91295c-b593-4d33-8651-c67b6e82b989', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391067a90>]}
2021-07-13 17:36:32.175273 (Thread-1): 12:36:32 | 4 of 4 ERROR creating view model tap_csv.top20_artist_tracks......... [ERROR in 1.86s]
2021-07-13 17:36:32.177624 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 17:36:32.185673 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:36:32.187213 (MainThread): 12:36:32 | 
2021-07-13 17:36:32.189668 (MainThread): 12:36:32 | Finished running 4 view models in 6.87s.
2021-07-13 17:36:32.191101 (MainThread): Connection 'master' was properly closed.
2021-07-13 17:36:32.191616 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-13 17:36:32.212127 (MainThread): 
2021-07-13 17:36:32.213159 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 17:36:32.214450 (MainThread): 
2021-07-13 17:36:32.215361 (MainThread): Database Error in model top20_artist_genres (models/analysis/top20_artist_genres.sql)
2021-07-13 17:36:32.216523 (MainThread):   Syntax error: Expected ")" but got keyword UNNEST at [20:25]
2021-07-13 17:36:32.217672 (MainThread):   compiled SQL at target/run/spotify_project/models/analysis/top20_artist_genres.sql
2021-07-13 17:36:32.218905 (MainThread): 
2021-07-13 17:36:32.224841 (MainThread): Database Error in model top20_artist_tracks (models/analysis/top20_artist_tracks.sql)
2021-07-13 17:36:32.226735 (MainThread):   Syntax error: Unexpected keyword UNNEST at [8:8]
2021-07-13 17:36:32.227771 (MainThread):   compiled SQL at target/run/spotify_project/models/analysis/top20_artist_tracks.sql
2021-07-13 17:36:32.228984 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-07-13 17:36:32.231006 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391d1cee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391d1c160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391c09b80>]}
2021-07-13 17:36:32.232368 (MainThread): Flushing usage events
2021-07-13 19:10:43.447753 (MainThread): Running with dbt=0.19.2
2021-07-13 19:10:44.151063 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 19:10:44.152217 (MainThread): Tracking: tracking
2021-07-13 19:10:44.168010 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a32b64f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a5168d250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a32b77430>]}
2021-07-13 19:10:44.182851 (MainThread): Partial parsing not enabled
2021-07-13 19:10:44.184807 (MainThread): Parsing macros/adapters.sql
2021-07-13 19:10:44.207632 (MainThread): Parsing macros/catalog.sql
2021-07-13 19:10:44.213462 (MainThread): Parsing macros/etc.sql
2021-07-13 19:10:44.215789 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 19:10:44.220491 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 19:10:44.232323 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 19:10:44.235247 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 19:10:44.237186 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 19:10:44.246546 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 19:10:44.251380 (MainThread): Parsing macros/core.sql
2021-07-13 19:10:44.254981 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 19:10:44.290719 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 19:10:44.298461 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 19:10:44.299528 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 19:10:44.301045 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 19:10:44.302798 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 19:10:44.304250 (MainThread): Parsing macros/etc/query.sql
2021-07-13 19:10:44.305284 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 19:10:44.312916 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 19:10:44.324085 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 19:10:44.325841 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 19:10:44.331037 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 19:10:44.347632 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 19:10:44.372208 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 19:10:44.373967 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 19:10:44.388029 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 19:10:44.393642 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 19:10:44.397769 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 19:10:44.402729 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 19:10:44.405019 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 19:10:44.406534 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 19:10:44.408946 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 19:10:44.415156 (MainThread): Partial parsing not enabled
2021-07-13 19:10:44.636519 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:10:44.646219 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:10:44.650158 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:10:44.653869 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:10:44.729430 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a328aa460>]}
2021-07-13 19:10:44.734721 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a328b1160>]}
2021-07-13 19:10:44.735073 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 19:10:44.736363 (MainThread): 
2021-07-13 19:10:44.736794 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:10:44.737848 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 19:10:44.738149 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 19:10:45.113304 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 19:10:45.114153 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 19:10:45.128487 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 19:10:45.476230 (MainThread): 14:10:45 | Concurrency: 1 threads (target='prod')
2021-07-13 19:10:45.478355 (MainThread): 14:10:45 | 
2021-07-13 19:10:45.509142 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 19:10:45.510332 (Thread-1): 14:10:45 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 19:10:45.512715 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:10:45.513246 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 19:10:45.520550 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:10:45.525152 (Thread-1): finished collecting timing info
2021-07-13 19:10:45.588092 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:10:45.589671 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:10:45.595296 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS string) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 19:10:46.675843 (Thread-1): finished collecting timing info
2021-07-13 19:10:46.677225 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a3288a0d0>]}
2021-07-13 19:10:46.678376 (Thread-1): 14:10:46 | 1 of 4 OK created view model tap_csv.stg_artists..................... [OK in 1.16s]
2021-07-13 19:10:46.680378 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 19:10:46.680985 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 19:10:46.682149 (Thread-1): 14:10:46 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 19:10:46.684140 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:10:46.684628 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 19:10:46.686861 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59067, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:10:46.687778 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59068, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:10:46.696056 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:10:46.699304 (Thread-1): finished collecting timing info
2021-07-13 19:10:46.706458 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:10:46.710729 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:10:46.728197 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		PARSE_DATE('%Y', release_date) AS release_year,
		CAST(danceability AS float64) AS danceability,
		CAST(energy AS float64) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float64) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float64) AS speechiness,
		CAST(acousticness AS float64) AS acousticness,
		CAST(instrumentalness AS float64) AS instrumentalness,
		CAST(liveness AS float64) AS liveness,
		CAST(valence AS float64) AS valence,
		CAST(tempo AS float64) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 19:10:48.036323 (Thread-1): finished collecting timing info
2021-07-13 19:10:48.038264 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a32a3dd90>]}
2021-07-13 19:10:48.039785 (Thread-1): 14:10:48 | 2 of 4 OK created view model tap_csv.stg_tracks...................... [OK in 1.35s]
2021-07-13 19:10:48.043338 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 19:10:48.044699 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 19:10:48.047013 (Thread-1): 14:10:48 | 3 of 4 START view model tap_csv.top20_artist_genres.................. [RUN]
2021-07-13 19:10:48.049581 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:10:48.050247 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 19:10:48.062618 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:10:48.066627 (Thread-1): finished collecting timing info
2021-07-13 19:10:48.070850 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59064, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 19:10:48.072237 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59063, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:10:48.073297 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59065, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:10:48.074254 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59066, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:10:48.081758 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59070, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 19:10:48.082720 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 59069, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:10:48.091242 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:10:48.096524 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:10:48.116842 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
),
cte2 AS
(
SELECT *
FROM cte1,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(genres,']',''),'[',''),"'",''), ', ')) genre
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		genre
FROM cte2
WHERE rnk_followers<=20;


2021-07-13 19:10:49.177484 (Thread-1): finished collecting timing info
2021-07-13 19:10:49.179460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a329c9c70>]}
2021-07-13 19:10:49.181050 (Thread-1): 14:10:49 | 3 of 4 OK created view model tap_csv.top20_artist_genres............. [OK in 1.13s]
2021-07-13 19:10:49.183664 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 19:10:49.184570 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 19:10:49.186261 (Thread-1): 14:10:49 | 4 of 4 START view model tap_csv.top20_artist_tracks.................. [RUN]
2021-07-13 19:10:49.188733 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:10:49.189396 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-13 19:10:49.204827 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:10:49.209649 (Thread-1): finished collecting timing info
2021-07-13 19:10:49.223042 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:10:49.229392 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:10:49.250888 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_tracks`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *
FROM `spotify600k`.`tap_csv`.`stg_tracks`,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(artist_id,']',''),'[',''),"'",''), ', ')) new_artist_id
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=20;


2021-07-13 19:10:50.574761 (Thread-1): finished collecting timing info
2021-07-13 19:10:50.575341 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '030930ab-c0de-405a-bd78-b974ceaca585', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a3288a0d0>]}
2021-07-13 19:10:50.575760 (Thread-1): 14:10:50 | 4 of 4 OK created view model tap_csv.top20_artist_tracks............. [OK in 1.39s]
2021-07-13 19:10:50.576456 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 19:10:50.578645 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:10:50.579134 (MainThread): 14:10:50 | 
2021-07-13 19:10:50.579415 (MainThread): 14:10:50 | Finished running 4 view models in 5.84s.
2021-07-13 19:10:50.579674 (MainThread): Connection 'master' was properly closed.
2021-07-13 19:10:50.579795 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-13 19:10:50.585999 (MainThread): 
2021-07-13 19:10:50.586339 (MainThread): Completed successfully
2021-07-13 19:10:50.586616 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-13 19:10:50.587647 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a32a2a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a328e8cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a328f5100>]}
2021-07-13 19:10:50.588000 (MainThread): Flushing usage events
2021-07-13 19:16:52.868423 (MainThread): Running with dbt=0.19.2
2021-07-13 19:16:53.539804 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 19:16:53.540847 (MainThread): Tracking: tracking
2021-07-13 19:16:53.557263 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2362d5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc244abed30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2362eb3d0>]}
2021-07-13 19:16:53.576126 (MainThread): Partial parsing not enabled
2021-07-13 19:16:53.577765 (MainThread): Parsing macros/adapters.sql
2021-07-13 19:16:53.608362 (MainThread): Parsing macros/catalog.sql
2021-07-13 19:16:53.617707 (MainThread): Parsing macros/etc.sql
2021-07-13 19:16:53.621046 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 19:16:53.626593 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 19:16:53.637282 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 19:16:53.640102 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 19:16:53.641820 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 19:16:53.649902 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 19:16:53.653811 (MainThread): Parsing macros/core.sql
2021-07-13 19:16:53.657495 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 19:16:53.691890 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 19:16:53.699353 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 19:16:53.700307 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 19:16:53.701790 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 19:16:53.703536 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 19:16:53.705093 (MainThread): Parsing macros/etc/query.sql
2021-07-13 19:16:53.706193 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 19:16:53.713740 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 19:16:53.725008 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 19:16:53.726703 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 19:16:53.731710 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 19:16:53.748162 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 19:16:53.772585 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 19:16:53.774254 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 19:16:53.788303 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 19:16:53.793676 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 19:16:53.797693 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 19:16:53.802506 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 19:16:53.805011 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 19:16:53.806462 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 19:16:53.808105 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 19:16:53.814227 (MainThread): Partial parsing not enabled
2021-07-13 19:16:54.027388 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:16:54.034748 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-07-13 19:16:54.037383 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:16:54.040416 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-07-13 19:16:54.041892 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:16:54.044722 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-07-13 19:16:54.046172 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:16:54.048771 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-07-13 19:16:54.123496 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc236026940>]}
2021-07-13 19:16:54.128530 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2361a6e80>]}
2021-07-13 19:16:54.128833 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 19:16:54.130100 (MainThread): 
2021-07-13 19:16:54.130535 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:16:54.131585 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 19:16:54.131872 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 19:16:54.489191 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_spotify600k_tap_csv_spotify".
2021-07-13 19:16:54.490060 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_spotify600k_tap_csv_spotify".
2021-07-13 19:16:54.490485 (ThreadPoolExecutor-0_0): Creating schema "spotify600k.tap_csv_spotify".
2021-07-13 19:16:54.490814 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-07-13 19:16:54.504295 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 19:16:55.068592 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv_spotify".
2021-07-13 19:16:55.069425 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 19:16:55.083587 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 19:16:55.169893 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64062, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 19:16:55.170892 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64063, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:16:55.452505 (MainThread): 14:16:55 | Concurrency: 1 threads (target='prod')
2021-07-13 19:16:55.454478 (MainThread): 14:16:55 | 
2021-07-13 19:16:55.491823 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 19:16:55.492844 (Thread-1): 14:16:55 | 1 of 4 START view model tap_csv_spotify.stg_artists.................. [RUN]
2021-07-13 19:16:55.495406 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:16:55.496118 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 19:16:55.507313 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:16:55.510066 (Thread-1): finished collecting timing info
2021-07-13 19:16:55.599694 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:16:55.602263 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:16:55.616210 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv_spotify`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS string) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 19:16:56.972549 (Thread-1): finished collecting timing info
2021-07-13 19:16:56.975658 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc236081400>]}
2021-07-13 19:16:56.977992 (Thread-1): 14:16:56 | 1 of 4 OK created view model tap_csv_spotify.stg_artists............. [OK in 1.48s]
2021-07-13 19:16:56.981227 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 19:16:56.982066 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 19:16:56.984137 (Thread-1): 14:16:56 | 2 of 4 START view model tap_csv_spotify.stg_tracks................... [RUN]
2021-07-13 19:16:56.986188 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:16:56.986801 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 19:16:56.998095 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:16:57.001857 (Thread-1): finished collecting timing info
2021-07-13 19:16:57.016483 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:16:57.021679 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:16:57.036009 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv_spotify`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		PARSE_DATE('%Y', release_date) AS release_year,
		CAST(danceability AS float64) AS danceability,
		CAST(energy AS float64) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float64) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float64) AS speechiness,
		CAST(acousticness AS float64) AS acousticness,
		CAST(instrumentalness AS float64) AS instrumentalness,
		CAST(liveness AS float64) AS liveness,
		CAST(valence AS float64) AS valence,
		CAST(tempo AS float64) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 19:16:58.262254 (Thread-1): finished collecting timing info
2021-07-13 19:16:58.264457 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2360c93a0>]}
2021-07-13 19:16:58.266522 (Thread-1): 14:16:58 | 2 of 4 OK created view model tap_csv_spotify.stg_tracks.............. [OK in 1.28s]
2021-07-13 19:16:58.269450 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 19:16:58.270317 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 19:16:58.272630 (Thread-1): 14:16:58 | 3 of 4 START view model tap_csv_spotify.top20_artist_genres.......... [RUN]
2021-07-13 19:16:58.276184 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:16:58.277245 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 19:16:58.283501 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64061, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:16:58.284983 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64060, 0, 0), raddr=('2607:f8b0:4000:807::200a', 443, 0, 0)>
2021-07-13 19:16:58.294676 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64064, 0, 0), raddr=('2607:f8b0:4000:800::200a', 443, 0, 0)>
2021-07-13 19:16:58.296284 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64065, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:16:58.297968 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64066, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 19:16:58.299238 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64067, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 19:16:58.300226 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64068, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:16:58.301054 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64069, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:16:58.317766 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:16:58.321925 (Thread-1): finished collecting timing info
2021-07-13 19:16:58.331678 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:16:58.335948 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:16:58.356450 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */


  create or replace view `spotify600k`.`tap_csv_spotify`.`top20_artist_genres`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv_spotify`.`stg_artists`
),
cte2 AS
(
SELECT *
FROM cte1,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(genres,']',''),'[',''),"'",''), ', ')) genre
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		genre
FROM cte2
WHERE rnk_followers<=20;


2021-07-13 19:16:59.295190 (Thread-1): finished collecting timing info
2021-07-13 19:16:59.297785 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2360bff10>]}
2021-07-13 19:16:59.299555 (Thread-1): 14:16:59 | 3 of 4 OK created view model tap_csv_spotify.top20_artist_genres..... [OK in 1.02s]
2021-07-13 19:16:59.302529 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 19:16:59.303800 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 19:16:59.306495 (Thread-1): 14:16:59 | 4 of 4 START view model tap_csv_spotify.top20_artist_tracks.......... [RUN]
2021-07-13 19:16:59.309455 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:16:59.310381 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-13 19:16:59.330191 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:16:59.333753 (Thread-1): finished collecting timing info
2021-07-13 19:16:59.345189 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:16:59.348837 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:16:59.377725 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_tracks"} */


  create or replace view `spotify600k`.`tap_csv_spotify`.`top20_artist_tracks`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *
FROM `spotify600k`.`tap_csv_spotify`.`stg_tracks`,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(artist_id,']',''),'[',''),"'",''), ', ')) new_artist_id
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv_spotify`.`stg_artists`
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=20;


2021-07-13 19:17:00.568266 (Thread-1): finished collecting timing info
2021-07-13 19:17:00.569242 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94bdbcfd-87b1-4521-9e77-ea01ac8cb418', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2360c93a0>]}
2021-07-13 19:17:00.570017 (Thread-1): 14:17:00 | 4 of 4 OK created view model tap_csv_spotify.top20_artist_tracks..... [OK in 1.26s]
2021-07-13 19:17:00.571512 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 19:17:00.577841 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:17:00.579155 (MainThread): 14:17:00 | 
2021-07-13 19:17:00.580083 (MainThread): 14:17:00 | Finished running 4 view models in 6.45s.
2021-07-13 19:17:00.581399 (MainThread): Connection 'master' was properly closed.
2021-07-13 19:17:00.582152 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-13 19:17:00.603724 (MainThread): 
2021-07-13 19:17:00.604842 (MainThread): Completed successfully
2021-07-13 19:17:00.606774 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-13 19:17:00.620030 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23618d4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc236145d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2360d2df0>]}
2021-07-13 19:17:00.620810 (MainThread): Flushing usage events
2021-07-13 19:18:17.883849 (MainThread): Running with dbt=0.19.2
2021-07-13 19:18:18.535310 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 19:18:18.536342 (MainThread): Tracking: tracking
2021-07-13 19:18:18.551010 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e5605e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0f3ddebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e561d340>]}
2021-07-13 19:18:18.564162 (MainThread): Partial parsing not enabled
2021-07-13 19:18:18.565765 (MainThread): Parsing macros/adapters.sql
2021-07-13 19:18:18.585796 (MainThread): Parsing macros/catalog.sql
2021-07-13 19:18:18.591874 (MainThread): Parsing macros/etc.sql
2021-07-13 19:18:18.594092 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 19:18:18.598676 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 19:18:18.610853 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 19:18:18.613562 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 19:18:18.615415 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 19:18:18.624239 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 19:18:18.628315 (MainThread): Parsing macros/core.sql
2021-07-13 19:18:18.631729 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 19:18:18.667002 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 19:18:18.674114 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 19:18:18.675055 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 19:18:18.676511 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 19:18:18.678312 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 19:18:18.679889 (MainThread): Parsing macros/etc/query.sql
2021-07-13 19:18:18.680957 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 19:18:18.688347 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 19:18:18.699502 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 19:18:18.701120 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 19:18:18.706224 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 19:18:18.722559 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 19:18:18.747682 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 19:18:18.749349 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 19:18:18.764409 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 19:18:18.769677 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 19:18:18.774020 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 19:18:18.779000 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 19:18:18.781291 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 19:18:18.782661 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 19:18:18.784292 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 19:18:18.790547 (MainThread): Partial parsing not enabled
2021-07-13 19:18:19.008196 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:18:19.017874 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:18:19.021746 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:18:19.025563 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:18:19.101883 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e5351fd0>]}
2021-07-13 19:18:19.107101 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e5483f70>]}
2021-07-13 19:18:19.107414 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 19:18:19.108663 (MainThread): 
2021-07-13 19:18:19.109141 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:18:19.110171 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 19:18:19.110353 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 19:18:19.468019 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 19:18:19.468711 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 19:18:19.482792 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 19:18:19.879749 (MainThread): 14:18:19 | Concurrency: 1 threads (target='prod')
2021-07-13 19:18:19.881761 (MainThread): 14:18:19 | 
2021-07-13 19:18:19.916913 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 19:18:19.917960 (Thread-1): 14:18:19 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 19:18:19.920467 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:18:19.921274 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 19:18:19.932477 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:18:19.935703 (Thread-1): finished collecting timing info
2021-07-13 19:18:20.019085 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:18:20.020757 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:18:20.027549 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS string) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 19:18:21.157756 (Thread-1): finished collecting timing info
2021-07-13 19:18:21.159396 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e5413cd0>]}
2021-07-13 19:18:21.160730 (Thread-1): 14:18:21 | 1 of 4 OK created view model tap_csv.stg_artists..................... [OK in 1.24s]
2021-07-13 19:18:21.163039 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 19:18:21.163769 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 19:18:21.165166 (Thread-1): 14:18:21 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 19:18:21.167997 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:18:21.168885 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 19:18:21.172659 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58363, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 19:18:21.173756 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58364, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:18:21.183133 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:18:21.186534 (Thread-1): finished collecting timing info
2021-07-13 19:18:21.196771 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:18:21.199864 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:18:21.216807 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		PARSE_DATE('%Y', release_date) AS release_year,
		CAST(danceability AS float64) AS danceability,
		CAST(energy AS float64) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float64) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float64) AS speechiness,
		CAST(acousticness AS float64) AS acousticness,
		CAST(instrumentalness AS float64) AS instrumentalness,
		CAST(liveness AS float64) AS liveness,
		CAST(valence AS float64) AS valence,
		CAST(tempo AS float64) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 19:18:22.026367 (Thread-1): finished collecting timing info
2021-07-13 19:18:22.028350 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e53a7be0>]}
2021-07-13 19:18:22.029704 (Thread-1): 14:18:22 | 2 of 4 OK created view model tap_csv.stg_tracks...................... [OK in 0.86s]
2021-07-13 19:18:22.032082 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 19:18:22.033458 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 19:18:22.035756 (Thread-1): 14:18:22 | 3 of 4 START view model tap_csv.top20_artist_genres.................. [RUN]
2021-07-13 19:18:22.040421 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:18:22.041626 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 19:18:22.051322 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:18:22.056524 (Thread-1): finished collecting timing info
2021-07-13 19:18:22.063990 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58360, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 19:18:22.065186 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58359, 0, 0), raddr=('2607:f8b0:4023:1004::5f', 443, 0, 0)>
2021-07-13 19:18:22.065982 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58361, 0, 0), raddr=('2607:f8b0:4000:817::200a', 443, 0, 0)>
2021-07-13 19:18:22.066657 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58362, 0, 0), raddr=('2607:f8b0:4000:800::200a', 443, 0, 0)>
2021-07-13 19:18:22.075330 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58366, 0, 0), raddr=('2607:f8b0:4000:800::200a', 443, 0, 0)>
2021-07-13 19:18:22.077361 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 58365, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 19:18:22.083844 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:18:22.086166 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:18:22.096366 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_genres"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_genres`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
),
cte2 AS
(
SELECT *
FROM cte1,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(genres,']',''),'[',''),"'",''), ', ')) genre
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		genre
FROM cte2
WHERE rnk_followers<=20;


2021-07-13 19:18:23.151722 (Thread-1): finished collecting timing info
2021-07-13 19:18:23.153340 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e534ff10>]}
2021-07-13 19:18:23.155048 (Thread-1): 14:18:23 | 3 of 4 OK created view model tap_csv.top20_artist_genres............. [OK in 1.11s]
2021-07-13 19:18:23.157428 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 19:18:23.158385 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 19:18:23.159673 (Thread-1): 14:18:23 | 4 of 4 START view model tap_csv.top20_artist_tracks.................. [RUN]
2021-07-13 19:18:23.161810 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:18:23.162557 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-13 19:18:23.179336 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:18:23.182495 (Thread-1): finished collecting timing info
2021-07-13 19:18:23.191849 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:18:23.195144 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 19:18:23.213755 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.top20_artist_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`top20_artist_tracks`
  OPTIONS()
  as WITH cte1 AS
(
SELECT *
FROM `spotify600k`.`tap_csv`.`stg_tracks`,
	UNNEST(SPLIT(REPLACE(REPLACE(REPLACE(artist_id,']',''),'[',''),"'",''), ', ')) new_artist_id
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM `spotify600k`.`tap_csv`.`stg_artists`
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=20;


2021-07-13 19:18:24.183857 (Thread-1): finished collecting timing info
2021-07-13 19:18:24.185298 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf2a642-10df-476b-8191-537ec3b6b32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e54d69a0>]}
2021-07-13 19:18:24.186250 (Thread-1): 14:18:24 | 4 of 4 OK created view model tap_csv.top20_artist_tracks............. [OK in 1.02s]
2021-07-13 19:18:24.188171 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 19:18:24.193841 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:18:24.194857 (MainThread): 14:18:24 | 
2021-07-13 19:18:24.195838 (MainThread): 14:18:24 | Finished running 4 view models in 5.09s.
2021-07-13 19:18:24.197821 (MainThread): Connection 'master' was properly closed.
2021-07-13 19:18:24.198366 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-13 19:18:24.217388 (MainThread): 
2021-07-13 19:18:24.218354 (MainThread): Completed successfully
2021-07-13 19:18:24.232337 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-13 19:18:24.239081 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e5598dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e547a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0e547a370>]}
2021-07-13 19:18:24.240644 (MainThread): Flushing usage events
2021-07-13 19:18:50.353196 (MainThread): Running with dbt=0.19.2
2021-07-13 19:18:51.051877 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-07-13 19:18:51.053059 (MainThread): Tracking: tracking
2021-07-13 19:18:51.067672 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3add4f3bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc00d100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3add50f400>]}
2021-07-13 19:18:51.081380 (MainThread): Partial parsing not enabled
2021-07-13 19:18:51.083696 (MainThread): Parsing macros/adapters.sql
2021-07-13 19:18:51.110695 (MainThread): Parsing macros/catalog.sql
2021-07-13 19:18:51.116725 (MainThread): Parsing macros/etc.sql
2021-07-13 19:18:51.119063 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 19:18:51.124834 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 19:18:51.136772 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 19:18:51.139555 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 19:18:51.141438 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 19:18:51.150754 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 19:18:51.155360 (MainThread): Parsing macros/core.sql
2021-07-13 19:18:51.159158 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 19:18:51.195924 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 19:18:51.203213 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 19:18:51.204271 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 19:18:51.205815 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 19:18:51.207620 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 19:18:51.209022 (MainThread): Parsing macros/etc/query.sql
2021-07-13 19:18:51.210316 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 19:18:51.217861 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 19:18:51.229539 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 19:18:51.231259 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 19:18:51.236591 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 19:18:51.253888 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 19:18:51.279875 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 19:18:51.281542 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 19:18:51.296081 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 19:18:51.301706 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 19:18:51.306153 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 19:18:51.311394 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 19:18:51.313834 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 19:18:51.315264 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 19:18:51.317009 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 19:18:51.333906 (MainThread): Partial parsing not enabled
2021-07-13 19:18:51.674041 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:18:51.684496 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:18:51.688888 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:18:51.693072 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:18:51.771468 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ff30704-7f31-4b89-ad3c-6ce1371c4719', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3add241f70>]}
2021-07-13 19:18:51.776597 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ff30704-7f31-4b89-ad3c-6ce1371c4719', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3add370340>]}
2021-07-13 19:18:51.776897 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 19:18:51.778129 (MainThread): 
2021-07-13 19:18:51.778555 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 19:18:51.779539 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 19:18:51.779821 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 19:18:51.784395 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 19:18:52.128451 (MainThread): 14:18:52 | Concurrency: 1 threads (target='prod')
2021-07-13 19:18:52.130174 (MainThread): 14:18:52 | 
2021-07-13 19:18:52.160014 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 19:18:52.161483 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 19:18:52.162130 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 19:18:52.172062 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 19:18:52.175032 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.175819 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.177106 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 19:18:52.177707 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 19:18:52.179322 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 19:18:52.179734 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 19:18:52.186176 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 19:18:52.188500 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.188900 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.189560 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 19:18:52.189867 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 19:18:52.190727 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 19:18:52.191250 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-13 19:18:52.195321 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-13 19:18:52.196754 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.197073 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.197579 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 19:18:52.197818 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 19:18:52.198534 (Thread-1): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 19:18:52.198749 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-13 19:18:52.202472 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-13 19:18:52.203724 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.204008 (Thread-1): finished collecting timing info
2021-07-13 19:18:52.204429 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 19:18:52.206914 (MainThread): Connection 'master' was properly closed.
2021-07-13 19:18:52.207235 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-13 19:18:52.213269 (MainThread): 14:18:52 | Done.
2021-07-13 19:18:52.445747 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-07-13 19:18:52.446044 (MainThread): 14:18:52 | Building catalog
2021-07-13 19:18:52.447528 (MainThread): Opening a new connection, currently in state init
2021-07-13 19:18:52.766455 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "spotify600k.information_schema".
2021-07-13 19:18:52.781409 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-13 19:18:52.787011 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "connection_name": "spotify600k.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `spotify600k`.`tap_csv`.__TABLES__
        where (upper(dataset_id) = upper('tap_csv'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `spotify600k`.`tap_csv`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `spotify600k`.`tap_csv`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-07-13 19:18:55.744843 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 63231, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 19:18:55.745977 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 63230, 0, 0), raddr=('2607:f8b0:4000:80a::200a', 443, 0, 0)>
2021-07-13 19:18:55.824855 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "spotify600k.information_schema".
2021-07-13 19:18:55.826788 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 19:18:55.831878 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "connection_name": "spotify600k.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `spotify600k`.`spotify`.__TABLES__
        where (upper(dataset_id) = upper('spotify'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `spotify600k`.`spotify`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `spotify600k`.`spotify`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-07-13 19:19:00.082179 (MainThread): 14:19:00 | Catalog written to /home/zfan/meltano-projects/dbt_bigquery/target/catalog.json
2021-07-13 19:19:00.083277 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3add4f3bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3adc94b130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3adc94b670>]}
2021-07-13 19:19:00.083655 (MainThread): Flushing usage events
2021-07-13 19:19:00.371328 (MainThread): Connection 'generate_catalog' was properly closed.
2021-07-13 19:19:00.372273 (MainThread): Connection 'spotify600k.information_schema' was properly closed.
2021-07-13 19:19:19.141752 (MainThread): Running with dbt=0.19.2
2021-07-13 19:19:19.861073 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-07-13 19:19:19.862299 (MainThread): Tracking: tracking
2021-07-13 19:19:19.880220 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f7facbe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f8e29ed30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f7fadb2e0>]}
2021-07-13 19:19:19.884517 (MainThread): Serving docs at 0.0.0.0:8080
2021-07-13 19:19:19.885407 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-07-13 19:19:19.885945 (MainThread): Press Ctrl+C to exit.


