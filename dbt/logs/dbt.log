2021-07-12 02:06:03.125048 (MainThread): Running with dbt=0.19.2
2021-07-12 02:06:03.905902 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 02:06:03.909239 (MainThread): Tracking: tracking
2021-07-12 02:06:03.931012 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364e6ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa36697fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364e95250>]}
2021-07-12 02:06:03.959930 (MainThread): Partial parsing not enabled
2021-07-12 02:06:03.973530 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:06:04.009063 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:06:04.017660 (MainThread): Parsing macros/relations.sql
2021-07-12 02:06:04.027084 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:06:04.041348 (MainThread): Parsing macros/core.sql
2021-07-12 02:06:04.055738 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:06:04.101699 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:06:04.115590 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:06:04.123102 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:06:04.131595 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:06:04.139764 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:06:04.147685 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:06:04.155489 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:06:04.172070 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:06:04.191412 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:06:04.199945 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:06:04.213150 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:06:04.245176 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:06:04.282599 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:06:04.295155 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:06:04.317360 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:06:04.330007 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:06:04.341036 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:06:04.355245 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:06:04.363938 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:06:04.371743 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:06:04.379773 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:06:04.386869 (MainThread): Partial parsing not enabled
2021-07-12 02:06:04.561055 (MainThread): Acquiring new postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:04.580849 (MainThread): Acquiring new postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:04.673557 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 02:06:04.675486 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '815a3320-4d92-4490-998a-54b167030e71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364c1a280>]}
2021-07-12 02:06:04.683263 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '815a3320-4d92-4490-998a-54b167030e71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364eb43a0>]}
2021-07-12 02:06:04.683737 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:06:04.684651 (MainThread): 
2021-07-12 02:06:04.685032 (MainThread): Acquiring new postgres connection "master".
2021-07-12 02:06:04.686156 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k".
2021-07-12 02:06:04.698900 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k".
2021-07-12 02:06:04.699085 (ThreadPoolExecutor-0_0): On list_spotify600k: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "list_spotify600k"} */

    select distinct nspname from pg_namespace
  
2021-07-12 02:06:04.699194 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 02:06:04.769209 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.07 seconds
2021-07-12 02:06:04.778683 (ThreadPoolExecutor-0_0): On list_spotify600k: Close
2021-07-12 02:06:04.779534 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_spotify600k_dbt_spotify".
2021-07-12 02:06:04.780002 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_spotify600k_dbt_spotify".
2021-07-12 02:06:04.780271 (ThreadPoolExecutor-0_0): Creating schema ""spotify600k"."dbt_spotify""
2021-07-12 02:06:04.786163 (ThreadPoolExecutor-0_0): Using postgres connection "create_spotify600k_dbt_spotify".
2021-07-12 02:06:04.786330 (ThreadPoolExecutor-0_0): On create_spotify600k_dbt_spotify: BEGIN
2021-07-12 02:06:04.786424 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-07-12 02:06:04.832411 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 02:06:04.832598 (ThreadPoolExecutor-0_0): Using postgres connection "create_spotify600k_dbt_spotify".
2021-07-12 02:06:04.832685 (ThreadPoolExecutor-0_0): On create_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "create_spotify600k_dbt_spotify"} */
create schema if not exists "dbt_spotify"
2021-07-12 02:06:04.845227 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.01 seconds
2021-07-12 02:06:04.846259 (ThreadPoolExecutor-0_0): On create_spotify600k_dbt_spotify: COMMIT
2021-07-12 02:06:04.846394 (ThreadPoolExecutor-0_0): Using postgres connection "create_spotify600k_dbt_spotify".
2021-07-12 02:06:04.846477 (ThreadPoolExecutor-0_0): On create_spotify600k_dbt_spotify: COMMIT
2021-07-12 02:06:04.848127 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-07-12 02:06:04.848324 (ThreadPoolExecutor-0_0): On create_spotify600k_dbt_spotify: Close
2021-07-12 02:06:04.850255 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:06:04.856797 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:06:04.856972 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 02:06:04.857075 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 02:06:04.907800 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 02:06:04.907969 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:06:04.908046 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 02:06:04.919631 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.01 seconds
2021-07-12 02:06:04.920019 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 02:06:04.920238 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 02:06:04.925126 (MainThread): Using postgres connection "master".
2021-07-12 02:06:04.925442 (MainThread): On master: BEGIN
2021-07-12 02:06:04.925555 (MainThread): Opening a new connection, currently in state init
2021-07-12 02:06:05.138804 (MainThread): SQL status: BEGIN in 0.21 seconds
2021-07-12 02:06:05.139066 (MainThread): Using postgres connection "master".
2021-07-12 02:06:05.139209 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 02:06:05.162793 (MainThread): SQL status: SELECT 0 in 0.02 seconds
2021-07-12 02:06:05.163141 (MainThread): On master: ROLLBACK
2021-07-12 02:06:05.163350 (MainThread): Using postgres connection "master".
2021-07-12 02:06:05.163436 (MainThread): On master: BEGIN
2021-07-12 02:06:05.165306 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-07-12 02:06:05.165407 (MainThread): On master: COMMIT
2021-07-12 02:06:05.165476 (MainThread): Using postgres connection "master".
2021-07-12 02:06:05.165541 (MainThread): On master: COMMIT
2021-07-12 02:06:05.165748 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 02:06:05.165849 (MainThread): On master: Close
2021-07-12 02:06:05.166184 (MainThread): 21:06:05 | Concurrency: 1 threads (target='dev')
2021-07-12 02:06:05.166853 (MainThread): 21:06:05 | 
2021-07-12 02:06:05.182913 (Thread-1): Began running node model.spotify_project.my_first_dbt_model
2021-07-12 02:06:05.183568 (Thread-1): 21:06:05 | 1 of 2 START table model dbt_spotify.my_first_dbt_model.............. [RUN]
2021-07-12 02:06:05.184496 (Thread-1): Acquiring new postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.184794 (Thread-1): Compiling model.spotify_project.my_first_dbt_model
2021-07-12 02:06:05.190012 (Thread-1): Writing injected SQL for node "model.spotify_project.my_first_dbt_model"
2021-07-12 02:06:05.194222 (Thread-1): finished collecting timing info
2021-07-12 02:06:05.212275 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.212547 (Thread-1): On model.spotify_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_first_dbt_model"} */
drop table if exists "spotify600k"."dbt_spotify"."my_first_dbt_model__dbt_tmp" cascade
2021-07-12 02:06:05.212693 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 02:06:05.264251 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-07-12 02:06:05.266223 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.266350 (Thread-1): On model.spotify_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_first_dbt_model"} */
drop table if exists "spotify600k"."dbt_spotify"."my_first_dbt_model__dbt_backup" cascade
2021-07-12 02:06:05.267967 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-07-12 02:06:05.276834 (Thread-1): Writing runtime SQL for node "model.spotify_project.my_first_dbt_model"
2021-07-12 02:06:05.279790 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.280024 (Thread-1): On model.spotify_project.my_first_dbt_model: BEGIN
2021-07-12 02:06:05.282652 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 02:06:05.282806 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.282894 (Thread-1): On model.spotify_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_first_dbt_model"} */


  create  table "spotify600k"."dbt_spotify"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-07-12 02:06:05.301231 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2021-07-12 02:06:05.306464 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.306634 (Thread-1): On model.spotify_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_first_dbt_model"} */
alter table "spotify600k"."dbt_spotify"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-07-12 02:06:05.309732 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 02:06:05.316052 (Thread-1): On model.spotify_project.my_first_dbt_model: COMMIT
2021-07-12 02:06:05.316222 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.316316 (Thread-1): On model.spotify_project.my_first_dbt_model: COMMIT
2021-07-12 02:06:05.317631 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 02:06:05.320461 (Thread-1): Using postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:06:05.320667 (Thread-1): On model.spotify_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_first_dbt_model"} */
drop table if exists "spotify600k"."dbt_spotify"."my_first_dbt_model__dbt_backup" cascade
2021-07-12 02:06:05.322551 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-07-12 02:06:05.323642 (Thread-1): finished collecting timing info
2021-07-12 02:06:05.323810 (Thread-1): On model.spotify_project.my_first_dbt_model: Close
2021-07-12 02:06:05.324238 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '815a3320-4d92-4490-998a-54b167030e71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364eb4190>]}
2021-07-12 02:06:05.324689 (Thread-1): 21:06:05 | 1 of 2 OK created table model dbt_spotify.my_first_dbt_model......... [SELECT 2 in 0.14s]
2021-07-12 02:06:05.325468 (Thread-1): Finished running node model.spotify_project.my_first_dbt_model
2021-07-12 02:06:05.326569 (Thread-1): Began running node model.spotify_project.my_second_dbt_model
2021-07-12 02:06:05.327057 (Thread-1): 21:06:05 | 2 of 2 START view model dbt_spotify.my_second_dbt_model.............. [RUN]
2021-07-12 02:06:05.327902 (Thread-1): Acquiring new postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.328080 (Thread-1): Compiling model.spotify_project.my_second_dbt_model
2021-07-12 02:06:05.330907 (Thread-1): Writing injected SQL for node "model.spotify_project.my_second_dbt_model"
2021-07-12 02:06:05.332613 (Thread-1): finished collecting timing info
2021-07-12 02:06:05.346094 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.346395 (Thread-1): On model.spotify_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_second_dbt_model"} */
drop view if exists "spotify600k"."dbt_spotify"."my_second_dbt_model__dbt_tmp" cascade
2021-07-12 02:06:05.346666 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 02:06:05.507457 (Thread-1): SQL status: DROP VIEW in 0.16 seconds
2021-07-12 02:06:05.509820 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.509974 (Thread-1): On model.spotify_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_second_dbt_model"} */
drop view if exists "spotify600k"."dbt_spotify"."my_second_dbt_model__dbt_backup" cascade
2021-07-12 02:06:05.511958 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 02:06:05.516865 (Thread-1): Writing runtime SQL for node "model.spotify_project.my_second_dbt_model"
2021-07-12 02:06:05.519328 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.519574 (Thread-1): On model.spotify_project.my_second_dbt_model: BEGIN
2021-07-12 02:06:05.522219 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 02:06:05.522418 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.522517 (Thread-1): On model.spotify_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_second_dbt_model"} */

  create view "spotify600k"."dbt_spotify"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "spotify600k"."dbt_spotify"."my_first_dbt_model"
where id = 1
  );

2021-07-12 02:06:05.537031 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 02:06:05.539142 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.539282 (Thread-1): On model.spotify_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_second_dbt_model"} */
alter table "spotify600k"."dbt_spotify"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-07-12 02:06:05.540811 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 02:06:05.542345 (Thread-1): On model.spotify_project.my_second_dbt_model: COMMIT
2021-07-12 02:06:05.542516 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.542612 (Thread-1): On model.spotify_project.my_second_dbt_model: COMMIT
2021-07-12 02:06:05.544109 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 02:06:05.545713 (Thread-1): Using postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:06:05.545852 (Thread-1): On model.spotify_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "node_id": "model.spotify_project.my_second_dbt_model"} */
drop view if exists "spotify600k"."dbt_spotify"."my_second_dbt_model__dbt_backup" cascade
2021-07-12 02:06:05.547680 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 02:06:05.548836 (Thread-1): finished collecting timing info
2021-07-12 02:06:05.549014 (Thread-1): On model.spotify_project.my_second_dbt_model: Close
2021-07-12 02:06:05.549437 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '815a3320-4d92-4490-998a-54b167030e71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364c34a60>]}
2021-07-12 02:06:05.549899 (Thread-1): 21:06:05 | 2 of 2 OK created view model dbt_spotify.my_second_dbt_model......... [CREATE VIEW in 0.22s]
2021-07-12 02:06:05.551178 (Thread-1): Finished running node model.spotify_project.my_second_dbt_model
2021-07-12 02:06:05.553827 (MainThread): Acquiring new postgres connection "master".
2021-07-12 02:06:05.554114 (MainThread): Using postgres connection "master".
2021-07-12 02:06:05.554251 (MainThread): On master: BEGIN
2021-07-12 02:06:05.554391 (MainThread): Opening a new connection, currently in state closed
2021-07-12 02:06:05.617839 (MainThread): SQL status: BEGIN in 0.06 seconds
2021-07-12 02:06:05.618091 (MainThread): On master: COMMIT
2021-07-12 02:06:05.618203 (MainThread): Using postgres connection "master".
2021-07-12 02:06:05.618300 (MainThread): On master: COMMIT
2021-07-12 02:06:05.618588 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 02:06:05.618733 (MainThread): On master: Close
2021-07-12 02:06:05.619108 (MainThread): 21:06:05 | 
2021-07-12 02:06:05.620058 (MainThread): 21:06:05 | Finished running 1 table model, 1 view model in 0.93s.
2021-07-12 02:06:05.620515 (MainThread): Connection 'master' was properly closed.
2021-07-12 02:06:05.620881 (MainThread): Connection 'create_spotify600k_dbt_spotify' was properly closed.
2021-07-12 02:06:05.621048 (MainThread): Connection 'model.spotify_project.my_second_dbt_model' was properly closed.
2021-07-12 02:06:05.627773 (MainThread): 
2021-07-12 02:06:05.628144 (MainThread): Completed successfully
2021-07-12 02:06:05.628731 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-07-12 02:06:05.629926 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364eb4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364d4d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3643aef70>]}
2021-07-12 02:06:05.630483 (MainThread): Flushing usage events
2021-07-12 02:11:35.757560 (MainThread): Running with dbt=0.19.2
2021-07-12 02:11:35.841312 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-07-12 02:11:35.842349 (MainThread): Tracking: tracking
2021-07-12 02:11:35.855385 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacfe01f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbb04a4e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbad0022b0>]}
2021-07-12 02:11:35.868157 (MainThread): Partial parsing not enabled
2021-07-12 02:11:35.869637 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:11:35.891233 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:11:35.894139 (MainThread): Parsing macros/relations.sql
2021-07-12 02:11:35.896057 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:11:35.899708 (MainThread): Parsing macros/core.sql
2021-07-12 02:11:35.903858 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:11:35.950001 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:11:35.964202 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:11:35.965979 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:11:35.968916 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:11:35.971937 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:11:35.974710 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:11:35.976753 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:11:35.992825 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:11:36.022365 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:11:36.025977 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:11:36.032948 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:11:36.058321 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:11:36.085973 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:11:36.087952 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:11:36.103567 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:11:36.109285 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:11:36.113618 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:11:36.119014 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:11:36.121526 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:11:36.123083 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:11:36.124954 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:11:36.131320 (MainThread): Partial parsing not enabled
2021-07-12 02:11:36.304430 (MainThread): Acquiring new postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:11:36.315705 (MainThread): Acquiring new postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:11:36.387855 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 02:11:36.390836 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4ff7ad1-a3a5-48ac-ad60-5a0c74af9f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacd86f70>]}
2021-07-12 02:11:36.396866 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4ff7ad1-a3a5-48ac-ad60-5a0c74af9f84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacf8bb50>]}
2021-07-12 02:11:36.397182 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:11:36.398207 (MainThread): 
2021-07-12 02:11:36.398958 (MainThread): Acquiring new postgres connection "master".
2021-07-12 02:11:36.401522 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:11:36.411065 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:11:36.411376 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 02:11:36.411514 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 02:11:36.466456 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 02:11:36.466652 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 02:11:36.466743 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 02:11:36.474759 (ThreadPoolExecutor-0_0): SQL status: SELECT 2 in 0.01 seconds
2021-07-12 02:11:36.477596 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 02:11:36.478023 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 02:11:36.484896 (MainThread): Using postgres connection "master".
2021-07-12 02:11:36.485078 (MainThread): On master: BEGIN
2021-07-12 02:11:36.485177 (MainThread): Opening a new connection, currently in state init
2021-07-12 02:11:36.533589 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 02:11:36.533782 (MainThread): Using postgres connection "master".
2021-07-12 02:11:36.533873 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 02:11:36.546041 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-07-12 02:11:36.546671 (MainThread): On master: ROLLBACK
2021-07-12 02:11:36.546965 (MainThread): On master: Close
2021-07-12 02:11:36.547450 (MainThread): 21:11:36 | Concurrency: 1 threads (target='dev')
2021-07-12 02:11:36.548154 (MainThread): 21:11:36 | 
2021-07-12 02:11:36.557927 (Thread-1): Began running node model.spotify_project.my_first_dbt_model
2021-07-12 02:11:36.558976 (Thread-1): Acquiring new postgres connection "model.spotify_project.my_first_dbt_model".
2021-07-12 02:11:36.559232 (Thread-1): Compiling model.spotify_project.my_first_dbt_model
2021-07-12 02:11:36.563575 (Thread-1): Writing injected SQL for node "model.spotify_project.my_first_dbt_model"
2021-07-12 02:11:36.565460 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.565751 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.566098 (Thread-1): Finished running node model.spotify_project.my_first_dbt_model
2021-07-12 02:11:36.566785 (Thread-1): Began running node model.spotify_project.my_second_dbt_model
2021-07-12 02:11:36.567070 (Thread-1): Acquiring new postgres connection "model.spotify_project.my_second_dbt_model".
2021-07-12 02:11:36.567191 (Thread-1): Compiling model.spotify_project.my_second_dbt_model
2021-07-12 02:11:36.569222 (Thread-1): Writing injected SQL for node "model.spotify_project.my_second_dbt_model"
2021-07-12 02:11:36.570154 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.570338 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.570671 (Thread-1): Finished running node model.spotify_project.my_second_dbt_model
2021-07-12 02:11:36.570809 (Thread-1): Began running node test.spotify_project.not_null_my_first_dbt_model_id
2021-07-12 02:11:36.571324 (Thread-1): Acquiring new postgres connection "test.spotify_project.not_null_my_first_dbt_model_id".
2021-07-12 02:11:36.571456 (Thread-1): Compiling test.spotify_project.not_null_my_first_dbt_model_id
2021-07-12 02:11:36.579940 (Thread-1): Writing injected SQL for node "test.spotify_project.not_null_my_first_dbt_model_id"
2021-07-12 02:11:36.581784 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.582054 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.582395 (Thread-1): Finished running node test.spotify_project.not_null_my_first_dbt_model_id
2021-07-12 02:11:36.582535 (Thread-1): Began running node test.spotify_project.unique_my_first_dbt_model_id
2021-07-12 02:11:36.582896 (Thread-1): Acquiring new postgres connection "test.spotify_project.unique_my_first_dbt_model_id".
2021-07-12 02:11:36.583009 (Thread-1): Compiling test.spotify_project.unique_my_first_dbt_model_id
2021-07-12 02:11:36.590797 (Thread-1): Writing injected SQL for node "test.spotify_project.unique_my_first_dbt_model_id"
2021-07-12 02:11:36.592296 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.592585 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.593045 (Thread-1): Finished running node test.spotify_project.unique_my_first_dbt_model_id
2021-07-12 02:11:36.593321 (Thread-1): Began running node test.spotify_project.not_null_my_second_dbt_model_id
2021-07-12 02:11:36.594157 (Thread-1): Acquiring new postgres connection "test.spotify_project.not_null_my_second_dbt_model_id".
2021-07-12 02:11:36.594560 (Thread-1): Compiling test.spotify_project.not_null_my_second_dbt_model_id
2021-07-12 02:11:36.597535 (Thread-1): Writing injected SQL for node "test.spotify_project.not_null_my_second_dbt_model_id"
2021-07-12 02:11:36.598987 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.599340 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.599973 (Thread-1): Finished running node test.spotify_project.not_null_my_second_dbt_model_id
2021-07-12 02:11:36.600169 (Thread-1): Began running node test.spotify_project.unique_my_second_dbt_model_id
2021-07-12 02:11:36.600717 (Thread-1): Acquiring new postgres connection "test.spotify_project.unique_my_second_dbt_model_id".
2021-07-12 02:11:36.600904 (Thread-1): Compiling test.spotify_project.unique_my_second_dbt_model_id
2021-07-12 02:11:36.604263 (Thread-1): Writing injected SQL for node "test.spotify_project.unique_my_second_dbt_model_id"
2021-07-12 02:11:36.606133 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.606443 (Thread-1): finished collecting timing info
2021-07-12 02:11:36.606912 (Thread-1): Finished running node test.spotify_project.unique_my_second_dbt_model_id
2021-07-12 02:11:36.608757 (MainThread): Connection 'master' was properly closed.
2021-07-12 02:11:36.608926 (MainThread): Connection 'test.spotify_project.unique_my_second_dbt_model_id' was properly closed.
2021-07-12 02:11:36.614032 (MainThread): 21:11:36 | Done.
2021-07-12 02:11:36.793329 (MainThread): Acquiring new postgres connection "generate_catalog".
2021-07-12 02:11:36.793560 (MainThread): 21:11:36 | Building catalog
2021-07-12 02:11:36.796399 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "spotify600k.information_schema".
2021-07-12 02:11:36.802570 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 02:11:36.802738 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: BEGIN
2021-07-12 02:11:36.802835 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 02:11:36.860337 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2021-07-12 02:11:36.860532 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 02:11:36.860621 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "dev", "connection_name": "spotify600k.information_schema"} */

    
    

    select
        'spotify600k' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('dbt_spotify'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2021-07-12 02:11:36.877918 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.02 seconds
2021-07-12 02:11:36.881404 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: ROLLBACK
2021-07-12 02:11:36.881728 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: Close
2021-07-12 02:11:36.890303 (MainThread): 21:11:36 | Catalog written to /home/zfan/meltano-projects/dbt/target/catalog.json
2021-07-12 02:11:36.891143 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacfe01f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacd36d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbacfd7a30>]}
2021-07-12 02:11:36.891530 (MainThread): Flushing usage events
2021-07-12 02:11:37.137192 (MainThread): Connection 'generate_catalog' was properly closed.
2021-07-12 02:11:37.138152 (MainThread): Connection 'spotify600k.information_schema' was properly closed.
2021-07-12 02:11:53.179185 (MainThread): Running with dbt=0.19.2
2021-07-12 02:11:53.260260 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-07-12 02:11:53.261401 (MainThread): Tracking: tracking
2021-07-12 02:11:53.274795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d9b47c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29dd004e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d9b632e0>]}
2021-07-12 02:11:53.278135 (MainThread): Serving docs at 0.0.0.0:8080
2021-07-12 02:11:53.278664 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-07-12 02:11:53.279248 (MainThread): Press Ctrl+C to exit.


2021-07-12 02:24:05.267893 (MainThread): Running with dbt=0.19.2
2021-07-12 02:24:05.344486 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 02:24:05.345516 (MainThread): Tracking: tracking
2021-07-12 02:24:05.357612 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538ee9efa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5392364e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538eec42b0>]}
2021-07-12 02:24:05.369591 (MainThread): Partial parsing not enabled
2021-07-12 02:24:05.371211 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:24:05.391715 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:24:05.394060 (MainThread): Parsing macros/relations.sql
2021-07-12 02:24:05.395540 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:24:05.400117 (MainThread): Parsing macros/core.sql
2021-07-12 02:24:05.403808 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:24:05.442892 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:24:05.451175 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:24:05.452434 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:24:05.454311 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:24:05.456485 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:24:05.458258 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:24:05.459712 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:24:05.469224 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:24:05.482538 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:24:05.484553 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:24:05.490696 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:24:05.508398 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:24:05.532792 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:24:05.534428 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:24:05.548378 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:24:05.553763 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:24:05.557813 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:24:05.562660 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:24:05.564879 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:24:05.566203 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:24:05.567809 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:24:05.573917 (MainThread): Partial parsing not enabled
2021-07-12 02:24:05.773287 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 02:24:05.774753 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a503fe45-fbcb-4a12-995c-7ca0f677ce8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5390e24670>]}
2021-07-12 02:24:05.778856 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a503fe45-fbcb-4a12-995c-7ca0f677ce8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538edb09d0>]}
2021-07-12 02:24:05.779157 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:24:05.779927 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 02:24:05.780396 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538eee3370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538eee3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538ed85d90>]}
2021-07-12 02:24:05.780581 (MainThread): Flushing usage events
2021-07-12 02:45:57.763804 (MainThread): Running with dbt=0.19.2
2021-07-12 02:45:57.844032 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 02:45:57.845279 (MainThread): Tracking: tracking
2021-07-12 02:45:57.857485 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4ac88100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c7a0af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4acb5160>]}
2021-07-12 02:45:57.874447 (MainThread): Partial parsing not enabled
2021-07-12 02:45:57.875844 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:45:57.896815 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:45:57.900471 (MainThread): Parsing macros/relations.sql
2021-07-12 02:45:57.902674 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:45:57.908071 (MainThread): Parsing macros/core.sql
2021-07-12 02:45:57.911675 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:45:57.955806 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:45:57.969107 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:45:57.970840 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:45:57.973478 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:45:57.976672 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:45:57.979138 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:45:57.980797 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:45:57.995154 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:45:58.012421 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:45:58.014200 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:45:58.019712 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:45:58.036688 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:45:58.061843 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:45:58.063496 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:45:58.077747 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:45:58.083098 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:45:58.087085 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:45:58.092782 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:45:58.095132 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:45:58.096651 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:45:58.098311 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:45:58.104167 (MainThread): Partial parsing not enabled
2021-07-12 02:45:58.307053 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 02:45:58.308811 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b31292c-ba90-4534-b4b3-7aa3e0f11868', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4abd6910>]}
2021-07-12 02:45:58.312881 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8b31292c-ba90-4534-b4b3-7aa3e0f11868', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4ab916d0>]}
2021-07-12 02:45:58.313190 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:45:58.314057 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 02:45:58.314549 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4acdea30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4ac204c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4ac24c70>]}
2021-07-12 02:45:58.314748 (MainThread): Flushing usage events
2021-07-12 02:57:01.219603 (MainThread): Running with dbt=0.19.2
2021-07-12 02:57:01.295825 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 02:57:01.296861 (MainThread): Tracking: tracking
2021-07-12 02:57:01.313577 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5b91e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb766fca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5b450a0>]}
2021-07-12 02:57:01.329950 (MainThread): Partial parsing not enabled
2021-07-12 02:57:01.331763 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:57:01.352475 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:57:01.354631 (MainThread): Parsing macros/relations.sql
2021-07-12 02:57:01.355961 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:57:01.359136 (MainThread): Parsing macros/core.sql
2021-07-12 02:57:01.362576 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:57:01.416993 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:57:01.431571 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:57:01.433169 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:57:01.435994 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:57:01.439243 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:57:01.441733 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:57:01.443574 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:57:01.458194 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:57:01.470615 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:57:01.472345 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:57:01.477587 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:57:01.495524 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:57:01.521438 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:57:01.523070 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:57:01.537139 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:57:01.542385 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:57:01.546321 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:57:01.551359 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:57:01.553896 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:57:01.555259 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:57:01.556880 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:57:01.562676 (MainThread): Partial parsing not enabled
2021-07-12 02:57:01.779586 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging

2021-07-12 02:57:01.781283 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37937a37-2f78-4757-955e-50648a0cae97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5a89a60>]}
2021-07-12 02:57:01.786160 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '37937a37-2f78-4757-955e-50648a0cae97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5a5e790>]}
2021-07-12 02:57:01.786557 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:57:01.787407 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 02:57:01.787895 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5b6fd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5afd9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fb5aa7610>]}
2021-07-12 02:57:01.788128 (MainThread): Flushing usage events
2021-07-12 02:58:07.247923 (MainThread): Running with dbt=0.19.2
2021-07-12 02:58:07.323875 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 02:58:07.324854 (MainThread): Tracking: tracking
2021-07-12 02:58:07.337096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a2802fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29b40be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a280530d0>]}
2021-07-12 02:58:07.353104 (MainThread): Partial parsing not enabled
2021-07-12 02:58:07.354640 (MainThread): Parsing macros/adapters.sql
2021-07-12 02:58:07.379176 (MainThread): Parsing macros/catalog.sql
2021-07-12 02:58:07.382781 (MainThread): Parsing macros/relations.sql
2021-07-12 02:58:07.384866 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 02:58:07.389590 (MainThread): Parsing macros/core.sql
2021-07-12 02:58:07.395426 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 02:58:07.437512 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 02:58:07.445222 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 02:58:07.446398 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 02:58:07.448215 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 02:58:07.450437 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 02:58:07.453511 (MainThread): Parsing macros/etc/query.sql
2021-07-12 02:58:07.455399 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 02:58:07.468237 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 02:58:07.481122 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 02:58:07.483104 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 02:58:07.490409 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 02:58:07.507668 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 02:58:07.532371 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 02:58:07.534206 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 02:58:07.548283 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 02:58:07.554026 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 02:58:07.558168 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 02:58:07.563085 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 02:58:07.565365 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 02:58:07.566769 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 02:58:07.568957 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 02:58:07.574918 (MainThread): Partial parsing not enabled
2021-07-12 02:58:07.793041 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging

2021-07-12 02:58:07.795891 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10a822cf-82bd-474f-85b3-620cd8889eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a2dda11f0>]}
2021-07-12 02:58:07.800474 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10a822cf-82bd-474f-85b3-620cd8889eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a27f307c0>]}
2021-07-12 02:58:07.801126 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 02:58:07.802391 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 02:58:07.803008 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a27fc1d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a27fc1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a27f15d60>]}
2021-07-12 02:58:07.803318 (MainThread): Flushing usage events
2021-07-12 03:11:23.771908 (MainThread): Running with dbt=0.19.2
2021-07-12 03:11:23.847636 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 03:11:23.848593 (MainThread): Tracking: tracking
2021-07-12 03:11:23.860643 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466b09aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466cb6fc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466b045130>]}
2021-07-12 03:11:23.875385 (MainThread): Partial parsing not enabled
2021-07-12 03:11:23.877483 (MainThread): Parsing macros/adapters.sql
2021-07-12 03:11:23.906336 (MainThread): Parsing macros/catalog.sql
2021-07-12 03:11:23.908525 (MainThread): Parsing macros/relations.sql
2021-07-12 03:11:23.909929 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 03:11:23.913273 (MainThread): Parsing macros/core.sql
2021-07-12 03:11:23.917465 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 03:11:23.961401 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 03:11:23.974319 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 03:11:23.975925 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 03:11:23.978573 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 03:11:23.980617 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 03:11:23.982232 (MainThread): Parsing macros/etc/query.sql
2021-07-12 03:11:23.983429 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 03:11:23.992130 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 03:11:24.004526 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 03:11:24.006441 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 03:11:24.012798 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 03:11:24.029984 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 03:11:24.054180 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 03:11:24.055795 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 03:11:24.069766 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 03:11:24.075145 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 03:11:24.079157 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 03:11:24.084026 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 03:11:24.086320 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 03:11:24.087691 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 03:11:24.089433 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 03:11:24.095304 (MainThread): Partial parsing not enabled
2021-07-12 03:11:24.296293 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 03:11:24.297778 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6845efad-d3ab-4162-9f4e-8555ae9224a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466af77760>]}
2021-07-12 03:11:24.301861 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6845efad-d3ab-4162-9f4e-8555ae9224a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466af5f7f0>]}
2021-07-12 03:11:24.302158 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 03:11:24.303105 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 03:11:24.303627 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466b07fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466b06f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f466b06f130>]}
2021-07-12 03:11:24.303925 (MainThread): Flushing usage events
2021-07-12 03:12:34.548671 (MainThread): Running with dbt=0.19.2
2021-07-12 03:12:34.626419 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 03:12:34.627410 (MainThread): Tracking: tracking
2021-07-12 03:12:34.639435 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f60d0df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f7ba0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f60711f0>]}
2021-07-12 03:12:34.651452 (MainThread): Partial parsing not enabled
2021-07-12 03:12:34.652961 (MainThread): Parsing macros/adapters.sql
2021-07-12 03:12:34.673219 (MainThread): Parsing macros/catalog.sql
2021-07-12 03:12:34.675606 (MainThread): Parsing macros/relations.sql
2021-07-12 03:12:34.678212 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 03:12:34.683682 (MainThread): Parsing macros/core.sql
2021-07-12 03:12:34.689879 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 03:12:34.733426 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 03:12:34.744051 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 03:12:34.745768 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 03:12:34.748504 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 03:12:34.751692 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 03:12:34.754100 (MainThread): Parsing macros/etc/query.sql
2021-07-12 03:12:34.755309 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 03:12:34.764748 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 03:12:34.779317 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 03:12:34.782360 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 03:12:34.788709 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 03:12:34.810386 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 03:12:34.835825 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 03:12:34.837463 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 03:12:34.852301 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 03:12:34.857560 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 03:12:34.861929 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 03:12:34.867068 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 03:12:34.869362 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 03:12:34.870745 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 03:12:34.872389 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 03:12:34.878633 (MainThread): Partial parsing not enabled
2021-07-12 03:12:35.096021 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging

2021-07-12 03:12:35.097188 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efbbcf6b-e2f2-4d03-9b99-a9e10b43cb23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f5fcd850>]}
2021-07-12 03:12:35.101441 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'efbbcf6b-e2f2-4d03-9b99-a9e10b43cb23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f5f906d0>]}
2021-07-12 03:12:35.101780 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 03:12:35.102557 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 03:12:35.102976 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f6023d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f6025820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6f6025850>]}
2021-07-12 03:12:35.103184 (MainThread): Flushing usage events
2021-07-12 03:14:00.372012 (MainThread): Running with dbt=0.19.2
2021-07-12 03:14:00.470454 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 03:14:00.471564 (MainThread): Tracking: tracking
2021-07-12 03:14:00.487881 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda49731fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda4b23fb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda49755070>]}
2021-07-12 03:14:00.502592 (MainThread): Partial parsing not enabled
2021-07-12 03:14:00.504093 (MainThread): Parsing macros/adapters.sql
2021-07-12 03:14:00.531254 (MainThread): Parsing macros/catalog.sql
2021-07-12 03:14:00.533577 (MainThread): Parsing macros/relations.sql
2021-07-12 03:14:00.535016 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 03:14:00.538739 (MainThread): Parsing macros/core.sql
2021-07-12 03:14:00.546878 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 03:14:00.606786 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 03:14:00.623410 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 03:14:00.625937 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 03:14:00.628285 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 03:14:00.631455 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 03:14:00.633263 (MainThread): Parsing macros/etc/query.sql
2021-07-12 03:14:00.634942 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 03:14:00.646542 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 03:14:00.663141 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 03:14:00.665015 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 03:14:00.678663 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 03:14:00.708647 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 03:14:00.755175 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 03:14:00.756809 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 03:14:00.781810 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 03:14:00.788144 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 03:14:00.794389 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 03:14:00.805231 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 03:14:00.810033 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 03:14:00.813493 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 03:14:00.819119 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 03:14:00.827376 (MainThread): Partial parsing not enabled
2021-07-12 03:14:01.153919 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 03:14:01.155201 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e4746c0-757d-454a-8e4d-f49694560009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda496598b0>]}
2021-07-12 03:14:01.166686 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e4746c0-757d-454a-8e4d-f49694560009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda4962f790>]}
2021-07-12 03:14:01.166983 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 03:14:01.167797 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 03:14:01.168225 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda497805e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda49780d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda49780c10>]}
2021-07-12 03:14:01.168557 (MainThread): Flushing usage events
2021-07-12 03:24:43.325262 (MainThread): Running with dbt=0.19.2
2021-07-12 03:24:43.403861 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 03:24:43.405093 (MainThread): Tracking: tracking
2021-07-12 03:24:43.422851 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9055e80be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9054369f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9054369fa0>]}
2021-07-12 03:24:43.440536 (MainThread): Partial parsing not enabled
2021-07-12 03:24:43.442563 (MainThread): Parsing macros/adapters.sql
2021-07-12 03:24:43.471868 (MainThread): Parsing macros/catalog.sql
2021-07-12 03:24:43.474027 (MainThread): Parsing macros/relations.sql
2021-07-12 03:24:43.475450 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 03:24:43.479274 (MainThread): Parsing macros/core.sql
2021-07-12 03:24:43.482750 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 03:24:43.533570 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 03:24:43.543194 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 03:24:43.544383 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 03:24:43.546167 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 03:24:43.548232 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 03:24:43.550016 (MainThread): Parsing macros/etc/query.sql
2021-07-12 03:24:43.551313 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 03:24:43.566078 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 03:24:43.586350 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 03:24:43.589301 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 03:24:43.594559 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 03:24:43.611555 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 03:24:43.643182 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 03:24:43.644877 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 03:24:43.659283 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 03:24:43.664817 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 03:24:43.668890 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 03:24:43.674301 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 03:24:43.676649 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 03:24:43.678070 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 03:24:43.679967 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 03:24:43.685854 (MainThread): Partial parsing not enabled
2021-07-12 03:24:43.905526 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 03:24:43.907275 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'abd86124-baba-4908-872a-79be16114d19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90542a0490>]}
2021-07-12 03:24:43.911820 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'abd86124-baba-4908-872a-79be16114d19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f905426f6a0>]}
2021-07-12 03:24:43.912153 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 03:24:43.913054 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 03:24:43.913562 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90543b7400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90543038e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9054303820>]}
2021-07-12 03:24:43.913781 (MainThread): Flushing usage events
2021-07-12 03:55:53.637953 (MainThread): Running with dbt=0.19.2
2021-07-12 03:55:53.712199 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 03:55:53.713302 (MainThread): Tracking: tracking
2021-07-12 03:55:53.725361 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164acd0e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164c79fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164ac72310>]}
2021-07-12 03:55:53.737905 (MainThread): Partial parsing not enabled
2021-07-12 03:55:53.739487 (MainThread): Parsing macros/adapters.sql
2021-07-12 03:55:53.770067 (MainThread): Parsing macros/catalog.sql
2021-07-12 03:55:53.777002 (MainThread): Parsing macros/relations.sql
2021-07-12 03:55:53.779751 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 03:55:53.786688 (MainThread): Parsing macros/core.sql
2021-07-12 03:55:53.797121 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 03:55:53.860884 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 03:55:53.883296 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 03:55:53.885171 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 03:55:53.888134 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 03:55:53.891619 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 03:55:53.894511 (MainThread): Parsing macros/etc/query.sql
2021-07-12 03:55:53.896193 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 03:55:53.907095 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 03:55:53.931728 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 03:55:53.933881 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 03:55:53.941440 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 03:55:53.963665 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 03:55:53.992006 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 03:55:53.993900 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 03:55:54.010137 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 03:55:54.015731 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 03:55:54.019751 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 03:55:54.024993 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 03:55:54.027394 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 03:55:54.028806 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 03:55:54.030488 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 03:55:54.036508 (MainThread): Partial parsing not enabled
2021-07-12 03:55:54.242322 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.staging
- models.spotify_project.analysis

2021-07-12 03:55:54.243985 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd4e7cbe4-abfc-4307-a12b-db2e57fde925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16509fe190>]}
2021-07-12 03:55:54.248698 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd4e7cbe4-abfc-4307-a12b-db2e57fde925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164ab907c0>]}
2021-07-12 03:55:54.249035 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 03:55:54.250090 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 03:55:54.250795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164ac2ab80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164ac2a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f164ac2a880>]}
2021-07-12 03:55:54.251138 (MainThread): Flushing usage events
2021-07-12 16:02:00.920778 (MainThread): Running with dbt=0.19.2
2021-07-12 16:02:01.451634 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 16:02:01.453364 (MainThread): Tracking: tracking
2021-07-12 16:02:01.465522 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107f071fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1080b80bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107f095070>]}
2021-07-12 16:02:01.483251 (MainThread): Partial parsing not enabled
2021-07-12 16:02:01.493604 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:02:01.529325 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:02:01.540595 (MainThread): Parsing macros/relations.sql
2021-07-12 16:02:01.550308 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:02:01.566045 (MainThread): Parsing macros/core.sql
2021-07-12 16:02:01.578953 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:02:01.633622 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:02:01.648073 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:02:01.655215 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:02:01.662928 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:02:01.670999 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:02:01.678329 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:02:01.685786 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:02:01.701495 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:02:01.720521 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:02:01.729117 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:02:01.742595 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:02:01.771060 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:02:01.806099 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:02:01.817695 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:02:01.841633 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:02:01.854496 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:02:01.865841 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:02:01.878969 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:02:01.887775 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:02:01.895603 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:02:01.903757 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:02:01.910914 (MainThread): Partial parsing not enabled
2021-07-12 16:02:02.161291 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging

2021-07-12 16:02:02.164587 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66f4e44f-e27d-4dda-9a17-f3c44c4586e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107ef95490>]}
2021-07-12 16:02:02.170061 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66f4e44f-e27d-4dda-9a17-f3c44c4586e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107ef70730>]}
2021-07-12 16:02:02.170510 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 16:02:02.171442 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 16:02:02.171956 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107f0c15b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107f0c15e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f107ef55d00>]}
2021-07-12 16:02:02.172291 (MainThread): Flushing usage events
2021-07-12 16:08:45.212292 (MainThread): Running with dbt=0.19.2
2021-07-12 16:08:45.290606 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 16:08:45.291648 (MainThread): Tracking: tracking
2021-07-12 16:08:45.309032 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6981a1d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc699cafc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6981c5100>]}
2021-07-12 16:08:45.323047 (MainThread): Partial parsing not enabled
2021-07-12 16:08:45.324527 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:08:45.355667 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:08:45.359258 (MainThread): Parsing macros/relations.sql
2021-07-12 16:08:45.361542 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:08:45.366566 (MainThread): Parsing macros/core.sql
2021-07-12 16:08:45.370331 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:08:45.404481 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:08:45.411628 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:08:45.412542 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:08:45.413993 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:08:45.415645 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:08:45.416995 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:08:45.417961 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:08:45.426219 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:08:45.437087 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:08:45.438652 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:08:45.443921 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:08:45.460188 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:08:45.484310 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:08:45.485888 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:08:45.499864 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:08:45.505295 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:08:45.509304 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:08:45.514094 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:08:45.516284 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:08:45.517591 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:08:45.519346 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:08:45.525160 (MainThread): Partial parsing not enabled
2021-07-12 16:08:45.721844 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.spotify_project.analysis
- models.spotify_project.staging

2021-07-12 16:08:45.723285 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c671361e-7760-4be5-bd13-c0ff6f7a53bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc69a124670>]}
2021-07-12 16:08:45.727215 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c671361e-7760-4be5-bd13-c0ff6f7a53bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6980b7d60>]}
2021-07-12 16:08:45.727504 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-07-12 16:08:45.728277 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-07-12 16:08:45.728745 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6981ffeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc698132e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6980e7670>]}
2021-07-12 16:08:45.728929 (MainThread): Flushing usage events
2021-07-12 16:11:54.443833 (MainThread): Running with dbt=0.19.2
2021-07-12 16:11:54.516569 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 16:11:54.517790 (MainThread): Tracking: tracking
2021-07-12 16:11:54.531421 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55dd06cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55deb7fc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55dd094070>]}
2021-07-12 16:11:54.544211 (MainThread): Partial parsing not enabled
2021-07-12 16:11:54.546091 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:11:54.568513 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:11:54.571156 (MainThread): Parsing macros/relations.sql
2021-07-12 16:11:54.572785 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:11:54.576377 (MainThread): Parsing macros/core.sql
2021-07-12 16:11:54.580395 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:11:54.617819 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:11:54.625236 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:11:54.626218 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:11:54.627806 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:11:54.629606 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:11:54.631045 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:11:54.632080 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:11:54.640368 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:11:54.651627 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:11:54.653354 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:11:54.658387 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:11:54.677434 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:11:54.704617 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:11:54.706293 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:11:54.720694 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:11:54.726085 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:11:54.730855 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:11:54.735878 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:11:54.738172 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:11:54.739548 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:11:54.741194 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:11:54.747290 (MainThread): Partial parsing not enabled
2021-07-12 16:11:54.917293 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:11:54.933617 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:11:54.943626 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:11:54.953451 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:11:54.977974 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55dd001b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55dcf7f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55dcf7f880>]}
2021-07-12 16:11:54.978292 (MainThread): Flushing usage events
2021-07-12 16:11:55.252063 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-12 16:11:55.253350 (MainThread): Encountered an error:
2021-07-12 16:11:55.254585 (MainThread): Compilation Error
  Error reading spotify_project: staging/schema.yml - Runtime Error
    Syntax error near line 23
    ------------------------------
    20 |             - name: explicit
    21 |               description: check the link under the table description
    22 |             - name:artists
    23 |               description: check the link under the table description
    24 |             - name: id_artists
    25 |               description: id of the artists. The foreign key to the "artists" table
    26 |             - name: release_date
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 23, column 26
2021-07-12 16:11:55.433564 (MainThread): Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 65, in load_yaml_text
    return safe_load(contents)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 60, in safe_load
    return yaml.load(contents, Loader=SafeLoader)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/yaml/__init__.py", line 114, in load
    return loader.get_single_data()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "yaml/_yaml.pyx", line 707, in yaml._yaml.CParser.get_single_node
  File "yaml/_yaml.pyx", line 725, in yaml._yaml.CParser._compose_document
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 853, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 905, in yaml._yaml.CParser._parse_next_event
yaml.scanner.ScannerError: mapping values are not allowed in this context
  in "<unicode string>", line 23, column 26

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 247, in _yaml_from_file
    return load_yaml_text(source_file.contents)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 72, in load_yaml_text
    raise dbt.exceptions.ValidationException(error)
dbt.exceptions.ValidationException: Runtime Error
  Syntax error near line 23
  ------------------------------
  20 |             - name: explicit
  21 |               description: check the link under the table description
  22 |             - name:artists
  23 |               description: check the link under the table description
  24 |             - name: id_artists
  25 |               description: id of the artists. The foreign key to the "artists" table
  26 |             - name: release_date
  
  Raw Error:
  ------------------------------
  mapping values are not allowed in this context
    in "<unicode string>", line 23, column 26

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 904, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 484, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 332, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 243, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 194, in parse_with_cache
    parser.parse_file(block)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 624, in parse_file
    dct = self._yaml_from_file(block.file)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 250, in _yaml_from_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Error reading spotify_project: staging/schema.yml - Runtime Error
    Syntax error near line 23
    ------------------------------
    20 |             - name: explicit
    21 |               description: check the link under the table description
    22 |             - name:artists
    23 |               description: check the link under the table description
    24 |             - name: id_artists
    25 |               description: id of the artists. The foreign key to the "artists" table
    26 |             - name: release_date
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 23, column 26

2021-07-12 16:14:54.893029 (MainThread): Running with dbt=0.19.2
2021-07-12 16:14:54.971229 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 16:14:54.972329 (MainThread): Tracking: tracking
2021-07-12 16:14:54.989818 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe40ae7f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe425ffc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe40b12100>]}
2021-07-12 16:14:55.002945 (MainThread): Partial parsing not enabled
2021-07-12 16:14:55.004528 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:14:55.026919 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:14:55.030971 (MainThread): Parsing macros/relations.sql
2021-07-12 16:14:55.033449 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:14:55.038252 (MainThread): Parsing macros/core.sql
2021-07-12 16:14:55.042455 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:14:55.080244 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:14:55.087613 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:14:55.088653 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:14:55.090202 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:14:55.092000 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:14:55.093451 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:14:55.094469 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:14:55.102706 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:14:55.113916 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:14:55.115568 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:14:55.120838 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:14:55.137351 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:14:55.161270 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:14:55.162871 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:14:55.177830 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:14:55.184524 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:14:55.188744 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:14:55.193713 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:14:55.196018 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:14:55.197381 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:14:55.199127 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:14:55.205059 (MainThread): Partial parsing not enabled
2021-07-12 16:14:55.375618 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:14:55.385751 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:14:55.391062 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:14:55.395057 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:14:55.407802 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe40b4ebb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe409ff760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe409ffc10>]}
2021-07-12 16:14:55.408063 (MainThread): Flushing usage events
2021-07-12 16:14:55.722449 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-12 16:14:55.724175 (MainThread): Encountered an error:
2021-07-12 16:14:55.725726 (MainThread): Compilation Error
  Error reading spotify_project: staging/schema.yml - Runtime Error
    Syntax error near line 23
    ------------------------------
    20 |             - name: explicit
    21 |               description: check the link under the table description
    22 |             - name:artists
    23 |               description: check the link under the table description
    24 |             - name: id_artists
    25 |               description: id of the artists. The foreign key to the artists table
    26 |             - name: release_date
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 23, column 26
2021-07-12 16:14:55.753420 (MainThread): Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 65, in load_yaml_text
    return safe_load(contents)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 60, in safe_load
    return yaml.load(contents, Loader=SafeLoader)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/yaml/__init__.py", line 114, in load
    return loader.get_single_data()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "yaml/_yaml.pyx", line 707, in yaml._yaml.CParser.get_single_node
  File "yaml/_yaml.pyx", line 725, in yaml._yaml.CParser._compose_document
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 851, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 776, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 890, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 774, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 853, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 905, in yaml._yaml.CParser._parse_next_event
yaml.scanner.ScannerError: mapping values are not allowed in this context
  in "<unicode string>", line 23, column 26

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 247, in _yaml_from_file
    return load_yaml_text(source_file.contents)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/yaml_helper.py", line 72, in load_yaml_text
    raise dbt.exceptions.ValidationException(error)
dbt.exceptions.ValidationException: Runtime Error
  Syntax error near line 23
  ------------------------------
  20 |             - name: explicit
  21 |               description: check the link under the table description
  22 |             - name:artists
  23 |               description: check the link under the table description
  24 |             - name: id_artists
  25 |               description: id of the artists. The foreign key to the artists table
  26 |             - name: release_date
  
  Raw Error:
  ------------------------------
  mapping values are not allowed in this context
    in "<unicode string>", line 23, column 26

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 904, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 484, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 332, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 243, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/manifest.py", line 194, in parse_with_cache
    parser.parse_file(block)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 624, in parse_file
    dct = self._yaml_from_file(block.file)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/parser/schemas.py", line 250, in _yaml_from_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Error reading spotify_project: staging/schema.yml - Runtime Error
    Syntax error near line 23
    ------------------------------
    20 |             - name: explicit
    21 |               description: check the link under the table description
    22 |             - name:artists
    23 |               description: check the link under the table description
    24 |             - name: id_artists
    25 |               description: id of the artists. The foreign key to the artists table
    26 |             - name: release_date
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 23, column 26

2021-07-12 16:16:52.423370 (MainThread): Running with dbt=0.19.2
2021-07-12 16:16:52.498941 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 16:16:52.500156 (MainThread): Tracking: tracking
2021-07-12 16:16:52.512572 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddae05cfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddafb6fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddae085040>]}
2021-07-12 16:16:52.525124 (MainThread): Partial parsing not enabled
2021-07-12 16:16:52.526638 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:16:52.547272 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:16:52.549919 (MainThread): Parsing macros/relations.sql
2021-07-12 16:16:52.551541 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:16:52.555137 (MainThread): Parsing macros/core.sql
2021-07-12 16:16:52.559136 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:16:52.596550 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:16:52.604499 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:16:52.605565 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:16:52.607122 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:16:52.608919 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:16:52.610352 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:16:52.611408 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:16:52.619725 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:16:52.631090 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:16:52.632792 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:16:52.638014 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:16:52.654720 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:16:52.680199 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:16:52.681873 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:16:52.696985 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:16:52.702479 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:16:52.706659 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:16:52.711915 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:16:52.714306 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:16:52.715765 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:16:52.717457 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:16:52.723450 (MainThread): Partial parsing not enabled
2021-07-12 16:16:52.887875 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:52.897832 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:52.902159 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:52.905945 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:52.978798 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddade2e730>]}
2021-07-12 16:16:52.984957 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddade52fd0>]}
2021-07-12 16:16:52.985262 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 16:16:52.986269 (MainThread): 
2021-07-12 16:16:52.986732 (MainThread): Acquiring new postgres connection "master".
2021-07-12 16:16:52.987768 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k".
2021-07-12 16:16:52.996271 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k".
2021-07-12 16:16:52.996450 (ThreadPoolExecutor-0_0): On list_spotify600k: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k"} */

    select distinct nspname from pg_namespace
  
2021-07-12 16:16:52.996553 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 16:16:53.097656 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.10 seconds
2021-07-12 16:16:53.108807 (ThreadPoolExecutor-0_0): On list_spotify600k: Close
2021-07-12 16:16:53.110874 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:16:53.117686 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:16:53.117860 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 16:16:53.118026 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 16:16:53.166484 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 16:16:53.166670 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:16:53.166761 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 16:16:53.197837 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.03 seconds
2021-07-12 16:16:53.198460 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 16:16:53.198825 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 16:16:53.203134 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.203314 (MainThread): On master: BEGIN
2021-07-12 16:16:53.203417 (MainThread): Opening a new connection, currently in state init
2021-07-12 16:16:53.251587 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 16:16:53.251776 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.251865 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 16:16:53.289867 (MainThread): SQL status: SELECT 1 in 0.04 seconds
2021-07-12 16:16:53.290498 (MainThread): On master: ROLLBACK
2021-07-12 16:16:53.290837 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.290953 (MainThread): On master: BEGIN
2021-07-12 16:16:53.293492 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-07-12 16:16:53.293670 (MainThread): On master: COMMIT
2021-07-12 16:16:53.293770 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.293849 (MainThread): On master: COMMIT
2021-07-12 16:16:53.294132 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.294283 (MainThread): On master: Close
2021-07-12 16:16:53.294757 (MainThread): 11:16:53 | Concurrency: 1 threads (target='local')
2021-07-12 16:16:53.295413 (MainThread): 11:16:53 | 
2021-07-12 16:16:53.311918 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 16:16:53.312268 (Thread-1): 11:16:53 | 1 of 4 START view model dbt_spotify.stg_artists...................... [RUN]
2021-07-12 16:16:53.312800 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.312949 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 16:16:53.315348 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 16:16:53.317653 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.338478 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.338677 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" cascade
2021-07-12 16:16:53.338791 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 16:16:53.388009 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 16:16:53.390096 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.390231 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 16:16:53.391840 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.396147 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-12 16:16:53.397826 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.398003 (Thread-1): On model.spotify_project.stg_artists: BEGIN
2021-07-12 16:16:53.400679 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 16:16:53.400852 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.400945 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */

  create view "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" as (
    SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM "spotify600k"."spotify"."artists"
  );

2021-07-12 16:16:53.429125 (Thread-1): SQL status: CREATE VIEW in 0.03 seconds
2021-07-12 16:16:53.434287 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.434464 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
alter table "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" rename to "stg_artists"
2021-07-12 16:16:53.435061 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 16:16:53.440469 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 16:16:53.440634 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.440730 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 16:16:53.442698 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.445590 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:16:53.445744 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 16:16:53.447320 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.448363 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.448515 (Thread-1): On model.spotify_project.stg_artists: Close
2021-07-12 16:16:53.448890 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddaddd2dc0>]}
2021-07-12 16:16:53.449372 (Thread-1): 11:16:53 | 1 of 4 OK created view model dbt_spotify.stg_artists................. [CREATE VIEW in 0.14s]
2021-07-12 16:16:53.450713 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 16:16:53.451062 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 16:16:53.451527 (Thread-1): 11:16:53 | 2 of 4 START view model dbt_spotify.stg_tracks....................... [RUN]
2021-07-12 16:16:53.452186 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.452405 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 16:16:53.454848 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 16:16:53.456046 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.459444 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.459646 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" cascade
2021-07-12 16:16:53.459779 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 16:16:53.513180 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 16:16:53.515203 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.515350 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 16:16:53.516989 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.518337 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-12 16:16:53.519540 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.519721 (Thread-1): On model.spotify_project.stg_tracks: BEGIN
2021-07-12 16:16:53.521922 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 16:16:53.522112 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.522214 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */

  create view "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" as (
    SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		EXTRACT(year FROM TO_DATE(release_date, 'YYYY')) AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM "spotify600k"."spotify"."tracks"
  );

2021-07-12 16:16:53.535719 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 16:16:53.538767 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.538929 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
alter table "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" rename to "stg_tracks"
2021-07-12 16:16:53.539530 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 16:16:53.540493 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 16:16:53.540606 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.540687 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 16:16:53.541806 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.543184 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:16:53.543308 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 16:16:53.544852 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.545989 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.546194 (Thread-1): On model.spotify_project.stg_tracks: Close
2021-07-12 16:16:53.546638 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddac53b280>]}
2021-07-12 16:16:53.547061 (Thread-1): 11:16:53 | 2 of 4 OK created view model dbt_spotify.stg_tracks.................. [CREATE VIEW in 0.09s]
2021-07-12 16:16:53.547683 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 16:16:53.548032 (Thread-1): Began running node model.spotify_project.top100_artist_genres
2021-07-12 16:16:53.548620 (Thread-1): 11:16:53 | 3 of 4 START view model dbt_spotify.top100_artist_genres............. [RUN]
2021-07-12 16:16:53.549443 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.549690 (Thread-1): Compiling model.spotify_project.top100_artist_genres
2021-07-12 16:16:53.552062 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 16:16:53.553471 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.555754 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.555896 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" cascade
2021-07-12 16:16:53.555993 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 16:16:53.611857 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2021-07-12 16:16:53.613639 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.613766 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_backup" cascade
2021-07-12 16:16:53.615576 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.616578 (Thread-1): Writing runtime SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 16:16:53.618041 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.618246 (Thread-1): On model.spotify_project.top100_artist_genres: BEGIN
2021-07-12 16:16:53.620604 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 16:16:53.620719 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.620794 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */

  create view "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" as (
    WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
),
cte2 AS
(
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		rnk_followers,
		REPLACE(
			UNNEST(
				string_to_array(
					REPLACE(
						REPLACE(genres,'[',''),
					']',''),
				', '))
			, '''', '') AS genres
FROM cte1
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		CAST(genres AS VARCHAR) AS genres
FROM cte2
WHERE rnk_followers<=100
  );

2021-07-12 16:16:53.633395 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 16:16:53.636068 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.636254 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
alter table "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" rename to "top100_artist_genres"
2021-07-12 16:16:53.636840 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 16:16:53.638177 (Thread-1): On model.spotify_project.top100_artist_genres: COMMIT
2021-07-12 16:16:53.638314 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.638418 (Thread-1): On model.spotify_project.top100_artist_genres: COMMIT
2021-07-12 16:16:53.639480 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.641239 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:16:53.641443 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_backup" cascade
2021-07-12 16:16:53.642987 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.644158 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.644329 (Thread-1): On model.spotify_project.top100_artist_genres: Close
2021-07-12 16:16:53.644779 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddade85550>]}
2021-07-12 16:16:53.645262 (Thread-1): 11:16:53 | 3 of 4 OK created view model dbt_spotify.top100_artist_genres........ [CREATE VIEW in 0.10s]
2021-07-12 16:16:53.645919 (Thread-1): Finished running node model.spotify_project.top100_artist_genres
2021-07-12 16:16:53.646130 (Thread-1): Began running node model.spotify_project.top100_artist_tracks
2021-07-12 16:16:53.646555 (Thread-1): 11:16:53 | 4 of 4 START view model dbt_spotify.top100_artist_tracks............. [RUN]
2021-07-12 16:16:53.647240 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.647489 (Thread-1): Compiling model.spotify_project.top100_artist_tracks
2021-07-12 16:16:53.650570 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 16:16:53.651823 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.654421 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.654596 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" cascade
2021-07-12 16:16:53.654701 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 16:16:53.709586 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 16:16:53.712361 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.712538 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_backup" cascade
2021-07-12 16:16:53.714103 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.715609 (Thread-1): Writing runtime SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 16:16:53.716963 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.717163 (Thread-1): On model.spotify_project.top100_artist_tracks: BEGIN
2021-07-12 16:16:53.719268 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 16:16:53.719433 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.719547 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */

  create view "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" as (
    WITH cte1 AS
(
SELECT unnest(
			string_to_array(
			REPLACE(REPLACE(artist_id,'[',''),']',''),',')) AS new_artist_id,
		*
FROM "spotify600k"."dbt_spotify"."stg_tracks"
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=100
  );

2021-07-12 16:16:53.729665 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 16:16:53.732420 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.732580 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
alter table "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" rename to "top100_artist_tracks"
2021-07-12 16:16:53.733283 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 16:16:53.734685 (Thread-1): On model.spotify_project.top100_artist_tracks: COMMIT
2021-07-12 16:16:53.734831 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.734935 (Thread-1): On model.spotify_project.top100_artist_tracks: COMMIT
2021-07-12 16:16:53.736005 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.738395 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:16:53.738607 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_backup" cascade
2021-07-12 16:16:53.740053 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 16:16:53.741017 (Thread-1): finished collecting timing info
2021-07-12 16:16:53.741165 (Thread-1): On model.spotify_project.top100_artist_tracks: Close
2021-07-12 16:16:53.741549 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f3821e3-faee-4e38-aee6-76deef0b9530', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddadf0e040>]}
2021-07-12 16:16:53.741914 (Thread-1): 11:16:53 | 4 of 4 OK created view model dbt_spotify.top100_artist_tracks........ [CREATE VIEW in 0.09s]
2021-07-12 16:16:53.742595 (Thread-1): Finished running node model.spotify_project.top100_artist_tracks
2021-07-12 16:16:53.744820 (MainThread): Acquiring new postgres connection "master".
2021-07-12 16:16:53.745086 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.745231 (MainThread): On master: BEGIN
2021-07-12 16:16:53.745364 (MainThread): Opening a new connection, currently in state closed
2021-07-12 16:16:53.803573 (MainThread): SQL status: BEGIN in 0.06 seconds
2021-07-12 16:16:53.803785 (MainThread): On master: COMMIT
2021-07-12 16:16:53.803872 (MainThread): Using postgres connection "master".
2021-07-12 16:16:53.803948 (MainThread): On master: COMMIT
2021-07-12 16:16:53.804168 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 16:16:53.804284 (MainThread): On master: Close
2021-07-12 16:16:53.804677 (MainThread): 11:16:53 | 
2021-07-12 16:16:53.805578 (MainThread): 11:16:53 | Finished running 4 view models in 0.82s.
2021-07-12 16:16:53.805897 (MainThread): Connection 'master' was properly closed.
2021-07-12 16:16:53.806065 (MainThread): Connection 'list_spotify600k' was properly closed.
2021-07-12 16:16:53.806284 (MainThread): Connection 'model.spotify_project.top100_artist_tracks' was properly closed.
2021-07-12 16:16:53.812492 (MainThread): 
2021-07-12 16:16:53.812847 (MainThread): Completed successfully
2021-07-12 16:16:53.813434 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-12 16:16:53.814660 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddade8c3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddade8c070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddae0bfbb0>]}
2021-07-12 16:16:53.815035 (MainThread): Flushing usage events
2021-07-12 16:18:41.817382 (MainThread): Running with dbt=0.19.2
2021-07-12 16:18:41.895246 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-07-12 16:18:41.896483 (MainThread): Tracking: tracking
2021-07-12 16:18:41.910534 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8c2456d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8f6b7e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8c1d40a0>]}
2021-07-12 16:18:41.923177 (MainThread): Partial parsing not enabled
2021-07-12 16:18:41.924671 (MainThread): Parsing macros/adapters.sql
2021-07-12 16:18:41.945963 (MainThread): Parsing macros/catalog.sql
2021-07-12 16:18:41.948456 (MainThread): Parsing macros/relations.sql
2021-07-12 16:18:41.950081 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 16:18:41.953707 (MainThread): Parsing macros/core.sql
2021-07-12 16:18:41.957801 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 16:18:41.995027 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 16:18:42.002345 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 16:18:42.003332 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 16:18:42.004861 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 16:18:42.006661 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 16:18:42.008244 (MainThread): Parsing macros/etc/query.sql
2021-07-12 16:18:42.009287 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 16:18:42.017286 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 16:18:42.028552 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 16:18:42.030237 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 16:18:42.035275 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 16:18:42.051661 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 16:18:42.075727 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 16:18:42.077390 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 16:18:42.091416 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 16:18:42.096724 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 16:18:42.100715 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 16:18:42.105748 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 16:18:42.108072 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 16:18:42.109457 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 16:18:42.111086 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 16:18:42.116923 (MainThread): Partial parsing not enabled
2021-07-12 16:18:42.282843 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:18:42.292932 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:18:42.297282 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:18:42.301112 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:18:42.381107 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9c74c37-748d-41b1-899a-cb768d0c585d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8c033cd0>]}
2021-07-12 16:18:42.386933 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9c74c37-748d-41b1-899a-cb768d0c585d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8c080700>]}
2021-07-12 16:18:42.387230 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 16:18:42.388468 (MainThread): 
2021-07-12 16:18:42.388956 (MainThread): Acquiring new postgres connection "master".
2021-07-12 16:18:42.389977 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:18:42.398133 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:18:42.398429 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 16:18:42.398594 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 16:18:42.449542 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 16:18:42.449737 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 16:18:42.449828 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 16:18:42.458093 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.01 seconds
2021-07-12 16:18:42.460688 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 16:18:42.461075 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 16:18:42.467744 (MainThread): Using postgres connection "master".
2021-07-12 16:18:42.467920 (MainThread): On master: BEGIN
2021-07-12 16:18:42.468018 (MainThread): Opening a new connection, currently in state init
2021-07-12 16:18:42.514483 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 16:18:42.514667 (MainThread): Using postgres connection "master".
2021-07-12 16:18:42.514751 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 16:18:42.533804 (MainThread): SQL status: SELECT 6 in 0.02 seconds
2021-07-12 16:18:42.534540 (MainThread): On master: ROLLBACK
2021-07-12 16:18:42.534819 (MainThread): On master: Close
2021-07-12 16:18:42.535189 (MainThread): 11:18:42 | Concurrency: 1 threads (target='local')
2021-07-12 16:18:42.535798 (MainThread): 11:18:42 | 
2021-07-12 16:18:42.544899 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 16:18:42.545510 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 16:18:42.545730 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 16:18:42.547776 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 16:18:42.549356 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.549641 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.549970 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 16:18:42.550119 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 16:18:42.550358 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 16:18:42.550470 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 16:18:42.552515 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 16:18:42.553401 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.553583 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.553875 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 16:18:42.554004 (Thread-1): Began running node model.spotify_project.top100_artist_genres
2021-07-12 16:18:42.554333 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 16:18:42.554452 (Thread-1): Compiling model.spotify_project.top100_artist_genres
2021-07-12 16:18:42.556474 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 16:18:42.557367 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.557549 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.557844 (Thread-1): Finished running node model.spotify_project.top100_artist_genres
2021-07-12 16:18:42.557975 (Thread-1): Began running node model.spotify_project.top100_artist_tracks
2021-07-12 16:18:42.558299 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 16:18:42.558407 (Thread-1): Compiling model.spotify_project.top100_artist_tracks
2021-07-12 16:18:42.560528 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 16:18:42.561397 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.561569 (Thread-1): finished collecting timing info
2021-07-12 16:18:42.561855 (Thread-1): Finished running node model.spotify_project.top100_artist_tracks
2021-07-12 16:18:42.563344 (MainThread): Connection 'master' was properly closed.
2021-07-12 16:18:42.563503 (MainThread): Connection 'model.spotify_project.top100_artist_tracks' was properly closed.
2021-07-12 16:18:42.568507 (MainThread): 11:18:42 | Done.
2021-07-12 16:18:42.760253 (MainThread): Acquiring new postgres connection "generate_catalog".
2021-07-12 16:18:42.760410 (MainThread): 11:18:42 | Building catalog
2021-07-12 16:18:42.762144 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "spotify600k.information_schema".
2021-07-12 16:18:42.767828 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 16:18:42.768100 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: BEGIN
2021-07-12 16:18:42.768211 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 16:18:42.814610 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 16:18:42.814794 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 16:18:42.814876 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "spotify600k.information_schema"} */

    
    

    select
        'spotify600k' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('dbt_spotify') or upper(sch.nspname) = upper('spotify'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2021-07-12 16:18:42.842700 (ThreadPoolExecutor-1_0): SQL status: SELECT 81 in 0.03 seconds
2021-07-12 16:18:42.849573 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: ROLLBACK
2021-07-12 16:18:42.850018 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: Close
2021-07-12 16:18:42.859743 (MainThread): 11:18:42 | Catalog written to /home/zfan/meltano-projects/dbt/target/catalog.json
2021-07-12 16:18:42.860505 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8c2456d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8bf56df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b8bf63940>]}
2021-07-12 16:18:42.860812 (MainThread): Flushing usage events
2021-07-12 16:18:43.164813 (MainThread): Connection 'generate_catalog' was properly closed.
2021-07-12 16:18:43.166281 (MainThread): Connection 'spotify600k.information_schema' was properly closed.
2021-07-12 16:18:51.760347 (MainThread): Running with dbt=0.19.2
2021-07-12 16:18:51.841265 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-07-12 16:18:51.842381 (MainThread): Tracking: tracking
2021-07-12 16:18:51.860474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa10d895e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa10d895e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa10d8b30d0>]}
2021-07-12 16:18:51.863982 (MainThread): Serving docs at 0.0.0.0:8080
2021-07-12 16:18:51.864664 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-07-12 16:18:51.865125 (MainThread): Press Ctrl+C to exit.


2021-07-12 16:33:47.513981 (MainThread): Flushing usage events
2021-07-12 16:33:47.836263 (MainThread): ctrl-c
2021-07-12 21:39:17.703515 (MainThread): Running with dbt=0.19.2
2021-07-12 21:39:17.830435 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 21:39:17.832112 (MainThread): Tracking: tracking
2021-07-12 21:39:17.845056 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7e33160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb989dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcc79175e0>]}
2021-07-12 21:39:17.858528 (MainThread): Partial parsing not enabled
2021-07-12 21:39:17.860964 (MainThread): Parsing macros/adapters.sql
2021-07-12 21:39:17.884577 (MainThread): Parsing macros/catalog.sql
2021-07-12 21:39:17.887217 (MainThread): Parsing macros/relations.sql
2021-07-12 21:39:17.889153 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 21:39:17.894021 (MainThread): Parsing macros/core.sql
2021-07-12 21:39:17.899197 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 21:39:17.944281 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 21:39:17.951870 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 21:39:17.952966 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 21:39:17.954619 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 21:39:17.956900 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 21:39:17.958623 (MainThread): Parsing macros/etc/query.sql
2021-07-12 21:39:17.960007 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 21:39:17.967827 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 21:39:17.979658 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 21:39:17.981494 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 21:39:17.987369 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 21:39:18.004506 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 21:39:18.030485 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 21:39:18.032433 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 21:39:18.047403 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 21:39:18.053068 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 21:39:18.058007 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 21:39:18.063387 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 21:39:18.066021 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 21:39:18.067658 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 21:39:18.069537 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 21:39:18.075862 (MainThread): Partial parsing not enabled
2021-07-12 21:39:18.207832 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.218873 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.223475 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.227613 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.304213 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb79d2a30>]}
2021-07-12 21:39:18.310643 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7a959d0>]}
2021-07-12 21:39:18.311030 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 21:39:18.312525 (MainThread): 
2021-07-12 21:39:18.313023 (MainThread): Acquiring new postgres connection "master".
2021-07-12 21:39:18.314107 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k".
2021-07-12 21:39:18.322464 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k".
2021-07-12 21:39:18.322828 (ThreadPoolExecutor-0_0): On list_spotify600k: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k"} */

    select distinct nspname from pg_namespace
  
2021-07-12 21:39:18.322976 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 21:39:18.368955 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-07-12 21:39:18.371763 (ThreadPoolExecutor-0_0): On list_spotify600k: Close
2021-07-12 21:39:18.374334 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:18.380398 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:18.380573 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 21:39:18.380685 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-12 21:39:18.428207 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 21:39:18.428392 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:18.428482 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 21:39:18.436136 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.01 seconds
2021-07-12 21:39:18.436846 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 21:39:18.437293 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 21:39:18.442428 (MainThread): Using postgres connection "master".
2021-07-12 21:39:18.442608 (MainThread): On master: BEGIN
2021-07-12 21:39:18.442709 (MainThread): Opening a new connection, currently in state init
2021-07-12 21:39:18.490496 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 21:39:18.490682 (MainThread): Using postgres connection "master".
2021-07-12 21:39:18.490768 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 21:39:18.511094 (MainThread): SQL status: SELECT 6 in 0.02 seconds
2021-07-12 21:39:18.511891 (MainThread): On master: ROLLBACK
2021-07-12 21:39:18.512252 (MainThread): Using postgres connection "master".
2021-07-12 21:39:18.512361 (MainThread): On master: BEGIN
2021-07-12 21:39:18.514893 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-07-12 21:39:18.515142 (MainThread): On master: COMMIT
2021-07-12 21:39:18.515290 (MainThread): Using postgres connection "master".
2021-07-12 21:39:18.515413 (MainThread): On master: COMMIT
2021-07-12 21:39:18.515740 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:18.515888 (MainThread): On master: Close
2021-07-12 21:39:18.516280 (MainThread): 16:39:18 | Concurrency: 1 threads (target='local')
2021-07-12 21:39:18.516884 (MainThread): 16:39:18 | 
2021-07-12 21:39:18.526686 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 21:39:18.527061 (Thread-1): 16:39:18 | 1 of 4 START view model dbt_spotify.stg_artists...................... [RUN]
2021-07-12 21:39:18.527602 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.527771 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 21:39:18.530170 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 21:39:18.531752 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.551909 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.552090 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" cascade
2021-07-12 21:39:18.552201 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 21:39:18.600363 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 21:39:18.602605 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.602747 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 21:39:18.604331 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.608981 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-12 21:39:18.610419 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.610580 (Thread-1): On model.spotify_project.stg_artists: BEGIN
2021-07-12 21:39:18.612721 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 21:39:18.612869 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.612958 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */

  create view "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" as (
    SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM "spotify600k"."spotify"."artists"
  );

2021-07-12 21:39:18.620796 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 21:39:18.626967 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.627145 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
alter table "spotify600k"."dbt_spotify"."stg_artists" rename to "stg_artists__dbt_backup"
2021-07-12 21:39:18.627789 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.629641 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.629768 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
alter table "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" rename to "stg_artists"
2021-07-12 21:39:18.630337 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.636452 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 21:39:18.636626 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.636711 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 21:39:18.638136 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:18.641505 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:18.641679 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 21:39:18.660487 (Thread-1): SQL status: DROP VIEW in 0.02 seconds
2021-07-12 21:39:18.661682 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.661847 (Thread-1): On model.spotify_project.stg_artists: Close
2021-07-12 21:39:18.662312 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7991d90>]}
2021-07-12 21:39:18.662769 (Thread-1): 16:39:18 | 1 of 4 OK created view model dbt_spotify.stg_artists................. [CREATE VIEW in 0.13s]
2021-07-12 21:39:18.663454 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 21:39:18.663719 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 21:39:18.664218 (Thread-1): 16:39:18 | 2 of 4 START view model dbt_spotify.stg_tracks....................... [RUN]
2021-07-12 21:39:18.664915 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.665148 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 21:39:18.668770 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 21:39:18.670065 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.673986 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.674215 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" cascade
2021-07-12 21:39:18.674431 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 21:39:18.730752 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2021-07-12 21:39:18.733586 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.733761 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 21:39:18.735290 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.736929 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-12 21:39:18.738207 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.738417 (Thread-1): On model.spotify_project.stg_tracks: BEGIN
2021-07-12 21:39:18.740882 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 21:39:18.741103 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.741215 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */

  create view "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" as (
    SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM "spotify600k"."spotify"."tracks"
  );

2021-07-12 21:39:18.749134 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 21:39:18.751933 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.752113 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
alter table "spotify600k"."dbt_spotify"."stg_tracks" rename to "stg_tracks__dbt_backup"
2021-07-12 21:39:18.752745 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.755221 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.755376 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
alter table "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" rename to "stg_tracks"
2021-07-12 21:39:18.756225 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.757563 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 21:39:18.757703 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.757799 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 21:39:18.759195 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:18.762313 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:18.762479 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 21:39:18.765799 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.766817 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.767012 (Thread-1): On model.spotify_project.stg_tracks: Close
2021-07-12 21:39:18.767519 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb713ce80>]}
2021-07-12 21:39:18.768040 (Thread-1): 16:39:18 | 2 of 4 OK created view model dbt_spotify.stg_tracks.................. [CREATE VIEW in 0.10s]
2021-07-12 21:39:18.768861 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 21:39:18.769197 (Thread-1): Began running node model.spotify_project.top100_artist_genres
2021-07-12 21:39:18.769760 (Thread-1): 16:39:18 | 3 of 4 START view model dbt_spotify.top100_artist_genres............. [RUN]
2021-07-12 21:39:18.770360 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.770569 (Thread-1): Compiling model.spotify_project.top100_artist_genres
2021-07-12 21:39:18.773376 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 21:39:18.774799 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.777146 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.777287 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" cascade
2021-07-12 21:39:18.777384 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 21:39:18.831611 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 21:39:18.834232 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.834391 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_backup" cascade
2021-07-12 21:39:18.835840 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.837131 (Thread-1): Writing runtime SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 21:39:18.838413 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.838582 (Thread-1): On model.spotify_project.top100_artist_genres: BEGIN
2021-07-12 21:39:18.840766 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 21:39:18.840963 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.841070 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */

  create view "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" as (
    WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
),
cte2 AS
(
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		rnk_followers,
		REPLACE(
			UNNEST(
				string_to_array(
					REPLACE(
						REPLACE(genres,'[',''),
					']',''),
				', '))
			, '''', '') AS genres
FROM cte1
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		CAST(genres AS VARCHAR) AS genres
FROM cte2
WHERE rnk_followers<=100
  );

2021-07-12 21:39:18.849005 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 21:39:18.851594 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.851758 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
alter table "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_tmp" rename to "top100_artist_genres"
2021-07-12 21:39:18.852402 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.853668 (Thread-1): On model.spotify_project.top100_artist_genres: COMMIT
2021-07-12 21:39:18.853797 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.853903 (Thread-1): On model.spotify_project.top100_artist_genres: COMMIT
2021-07-12 21:39:18.855095 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:18.856920 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:18.857101 (Thread-1): On model.spotify_project.top100_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_genres__dbt_backup" cascade
2021-07-12 21:39:18.858537 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.859840 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.860034 (Thread-1): On model.spotify_project.top100_artist_genres: Close
2021-07-12 21:39:18.860467 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7131a30>]}
2021-07-12 21:39:18.861000 (Thread-1): 16:39:18 | 3 of 4 OK created view model dbt_spotify.top100_artist_genres........ [CREATE VIEW in 0.09s]
2021-07-12 21:39:18.861703 (Thread-1): Finished running node model.spotify_project.top100_artist_genres
2021-07-12 21:39:18.862050 (Thread-1): Began running node model.spotify_project.top100_artist_tracks
2021-07-12 21:39:18.862353 (Thread-1): 16:39:18 | 4 of 4 START view model dbt_spotify.top100_artist_tracks............. [RUN]
2021-07-12 21:39:18.862998 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.863255 (Thread-1): Compiling model.spotify_project.top100_artist_tracks
2021-07-12 21:39:18.866796 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 21:39:18.868075 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.870729 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.870876 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" cascade
2021-07-12 21:39:18.870975 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 21:39:18.925458 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 21:39:18.927802 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.927986 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_backup" cascade
2021-07-12 21:39:18.929511 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.931029 (Thread-1): Writing runtime SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 21:39:18.932206 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.932345 (Thread-1): On model.spotify_project.top100_artist_tracks: BEGIN
2021-07-12 21:39:18.934329 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 21:39:18.934505 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.934608 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */

  create view "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" as (
    WITH cte1 AS
(
SELECT unnest(
			string_to_array(
			REPLACE(REPLACE(artist_id,'[',''),']',''),',')) AS new_artist_id,
		*
FROM "spotify600k"."dbt_spotify"."stg_tracks"
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=100
  );

2021-07-12 21:39:18.942960 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 21:39:18.945666 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.945820 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
alter table "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_tmp" rename to "top100_artist_tracks"
2021-07-12 21:39:18.946510 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 21:39:18.947772 (Thread-1): On model.spotify_project.top100_artist_tracks: COMMIT
2021-07-12 21:39:18.947906 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.948003 (Thread-1): On model.spotify_project.top100_artist_tracks: COMMIT
2021-07-12 21:39:18.949150 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:18.951003 (Thread-1): Using postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:18.951181 (Thread-1): On model.spotify_project.top100_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top100_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top100_artist_tracks__dbt_backup" cascade
2021-07-12 21:39:18.952685 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 21:39:18.954099 (Thread-1): finished collecting timing info
2021-07-12 21:39:18.954282 (Thread-1): On model.spotify_project.top100_artist_tracks: Close
2021-07-12 21:39:18.954740 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85082672-1e7b-4ab8-8fe9-b0ea04040dfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7131b50>]}
2021-07-12 21:39:18.955282 (Thread-1): 16:39:18 | 4 of 4 OK created view model dbt_spotify.top100_artist_tracks........ [CREATE VIEW in 0.09s]
2021-07-12 21:39:18.956188 (Thread-1): Finished running node model.spotify_project.top100_artist_tracks
2021-07-12 21:39:18.959188 (MainThread): Acquiring new postgres connection "master".
2021-07-12 21:39:18.959434 (MainThread): Using postgres connection "master".
2021-07-12 21:39:18.959553 (MainThread): On master: BEGIN
2021-07-12 21:39:18.959678 (MainThread): Opening a new connection, currently in state closed
2021-07-12 21:39:19.009294 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 21:39:19.009504 (MainThread): On master: COMMIT
2021-07-12 21:39:19.009585 (MainThread): Using postgres connection "master".
2021-07-12 21:39:19.009663 (MainThread): On master: COMMIT
2021-07-12 21:39:19.009875 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 21:39:19.009985 (MainThread): On master: Close
2021-07-12 21:39:19.010390 (MainThread): 16:39:19 | 
2021-07-12 21:39:19.010961 (MainThread): 16:39:19 | Finished running 4 view models in 0.70s.
2021-07-12 21:39:19.011214 (MainThread): Connection 'master' was properly closed.
2021-07-12 21:39:19.011316 (MainThread): Connection 'model.spotify_project.top100_artist_tracks' was properly closed.
2021-07-12 21:39:19.017199 (MainThread): 
2021-07-12 21:39:19.017528 (MainThread): Completed successfully
2021-07-12 21:39:19.017867 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-12 21:39:19.024262 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7b33c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb797b2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb7981970>]}
2021-07-12 21:39:19.024661 (MainThread): Flushing usage events
2021-07-12 21:39:52.001253 (MainThread): Running with dbt=0.19.2
2021-07-12 21:39:52.175761 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-07-12 21:39:52.177940 (MainThread): Tracking: tracking
2021-07-12 21:39:52.199988 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1d098a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1eb0ec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd2cb876d0>]}
2021-07-12 21:39:52.223522 (MainThread): Partial parsing not enabled
2021-07-12 21:39:52.225711 (MainThread): Parsing macros/adapters.sql
2021-07-12 21:39:52.262862 (MainThread): Parsing macros/catalog.sql
2021-07-12 21:39:52.265315 (MainThread): Parsing macros/relations.sql
2021-07-12 21:39:52.267042 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 21:39:52.272583 (MainThread): Parsing macros/core.sql
2021-07-12 21:39:52.278600 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 21:39:52.330529 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 21:39:52.338645 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 21:39:52.339721 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 21:39:52.341425 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 21:39:52.343403 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 21:39:52.345011 (MainThread): Parsing macros/etc/query.sql
2021-07-12 21:39:52.346165 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 21:39:52.354663 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 21:39:52.367479 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 21:39:52.369392 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 21:39:52.375812 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 21:39:52.394859 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 21:39:52.421936 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 21:39:52.423646 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 21:39:52.437763 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 21:39:52.443117 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 21:39:52.447275 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 21:39:52.452356 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 21:39:52.454681 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 21:39:52.456100 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 21:39:52.457743 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 21:39:52.465422 (MainThread): Partial parsing not enabled
2021-07-12 21:39:52.663412 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:52.673851 (MainThread): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:52.677800 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:52.682594 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:52.756396 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '479e9642-6e39-4dc5-a083-e25668f29284', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cc40a30>]}
2021-07-12 21:39:52.761839 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '479e9642-6e39-4dc5-a083-e25668f29284', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cc33eb0>]}
2021-07-12 21:39:52.762146 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 21:39:52.763592 (MainThread): 
2021-07-12 21:39:52.764036 (MainThread): Acquiring new postgres connection "master".
2021-07-12 21:39:52.765091 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:52.773568 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:52.773742 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 21:39:52.773841 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 21:39:52.834095 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2021-07-12 21:39:52.834294 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 21:39:52.834386 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 21:39:52.842117 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.01 seconds
2021-07-12 21:39:52.845015 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 21:39:52.845327 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 21:39:52.852598 (MainThread): Using postgres connection "master".
2021-07-12 21:39:52.852775 (MainThread): On master: BEGIN
2021-07-12 21:39:52.852878 (MainThread): Opening a new connection, currently in state init
2021-07-12 21:39:52.899264 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 21:39:52.899435 (MainThread): Using postgres connection "master".
2021-07-12 21:39:52.899517 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 21:39:52.918486 (MainThread): SQL status: SELECT 6 in 0.02 seconds
2021-07-12 21:39:52.919459 (MainThread): On master: ROLLBACK
2021-07-12 21:39:52.919919 (MainThread): On master: Close
2021-07-12 21:39:52.920841 (MainThread): 16:39:52 | Concurrency: 1 threads (target='local')
2021-07-12 21:39:52.921536 (MainThread): 16:39:52 | 
2021-07-12 21:39:52.930494 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 21:39:52.930914 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 21:39:52.931087 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 21:39:52.933510 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 21:39:52.934427 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.934667 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.935060 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 21:39:52.935284 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 21:39:52.935640 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 21:39:52.935766 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 21:39:52.937785 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 21:39:52.938879 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.939128 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.939564 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 21:39:52.939806 (Thread-1): Began running node model.spotify_project.top100_artist_genres
2021-07-12 21:39:52.940403 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_genres".
2021-07-12 21:39:52.940546 (Thread-1): Compiling model.spotify_project.top100_artist_genres
2021-07-12 21:39:52.942593 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_genres"
2021-07-12 21:39:52.943501 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.943686 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.943996 (Thread-1): Finished running node model.spotify_project.top100_artist_genres
2021-07-12 21:39:52.944163 (Thread-1): Began running node model.spotify_project.top100_artist_tracks
2021-07-12 21:39:52.944550 (Thread-1): Acquiring new postgres connection "model.spotify_project.top100_artist_tracks".
2021-07-12 21:39:52.944665 (Thread-1): Compiling model.spotify_project.top100_artist_tracks
2021-07-12 21:39:52.946886 (Thread-1): Writing injected SQL for node "model.spotify_project.top100_artist_tracks"
2021-07-12 21:39:52.947831 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.948036 (Thread-1): finished collecting timing info
2021-07-12 21:39:52.948353 (Thread-1): Finished running node model.spotify_project.top100_artist_tracks
2021-07-12 21:39:52.949976 (MainThread): Connection 'master' was properly closed.
2021-07-12 21:39:52.950141 (MainThread): Connection 'model.spotify_project.top100_artist_tracks' was properly closed.
2021-07-12 21:39:52.959180 (MainThread): 16:39:52 | Done.
2021-07-12 21:39:52.964689 (MainThread): Acquiring new postgres connection "generate_catalog".
2021-07-12 21:39:52.965008 (MainThread): 16:39:52 | Building catalog
2021-07-12 21:39:52.968460 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "spotify600k.information_schema".
2021-07-12 21:39:52.983850 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 21:39:52.984133 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: BEGIN
2021-07-12 21:39:52.984408 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 21:39:53.057537 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.07 seconds
2021-07-12 21:39:53.057898 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 21:39:53.058124 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "spotify600k.information_schema"} */

    
    

    select
        'spotify600k' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('dbt_spotify') or upper(sch.nspname) = upper('spotify'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2021-07-12 21:39:53.077538 (ThreadPoolExecutor-1_0): SQL status: SELECT 81 in 0.02 seconds
2021-07-12 21:39:53.092330 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: ROLLBACK
2021-07-12 21:39:53.092730 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: Close
2021-07-12 21:39:53.111516 (MainThread): 16:39:53 | Catalog written to /home/zfan/meltano-projects/dbt/target/catalog.json
2021-07-12 21:39:53.112814 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1d098a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cc284c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cc28a00>]}
2021-07-12 21:39:53.113378 (MainThread): Flushing usage events
2021-07-12 21:39:54.192798 (MainThread): Connection 'generate_catalog' was properly closed.
2021-07-12 21:39:54.194754 (MainThread): Connection 'spotify600k.information_schema' was properly closed.
2021-07-12 21:39:59.283948 (MainThread): Running with dbt=0.19.2
2021-07-12 21:39:59.401540 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-07-12 21:39:59.402659 (MainThread): Tracking: tracking
2021-07-12 21:39:59.416164 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3deb9b29d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ded41ed60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dfb495730>]}
2021-07-12 21:39:59.419829 (MainThread): Serving docs at 0.0.0.0:8080
2021-07-12 21:39:59.420489 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-07-12 21:39:59.420774 (MainThread): Press Ctrl+C to exit.


2021-07-12 21:43:17.397272 (MainThread): Flushing usage events
2021-07-12 21:43:17.725407 (MainThread): ctrl-c
2021-07-12 23:05:24.906113 (MainThread): Running with dbt=0.19.2
2021-07-12 23:05:25.027809 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-12 23:05:25.029283 (MainThread): Tracking: tracking
2021-07-12 23:05:25.042477 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d58640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab87cee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ac68486a0>]}
2021-07-12 23:05:25.055978 (MainThread): Partial parsing not enabled
2021-07-12 23:05:25.057965 (MainThread): Parsing macros/adapters.sql
2021-07-12 23:05:25.079472 (MainThread): Parsing macros/catalog.sql
2021-07-12 23:05:25.082153 (MainThread): Parsing macros/relations.sql
2021-07-12 23:05:25.083985 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 23:05:25.089009 (MainThread): Parsing macros/core.sql
2021-07-12 23:05:25.093248 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 23:05:25.130700 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 23:05:25.138181 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 23:05:25.139256 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 23:05:25.140857 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 23:05:25.142707 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 23:05:25.144255 (MainThread): Parsing macros/etc/query.sql
2021-07-12 23:05:25.145413 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 23:05:25.153143 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 23:05:25.164486 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 23:05:25.166392 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 23:05:25.172224 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 23:05:25.188835 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 23:05:25.215013 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 23:05:25.216944 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 23:05:25.231842 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 23:05:25.237726 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 23:05:25.242254 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 23:05:25.247753 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 23:05:25.250260 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 23:05:25.251801 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 23:05:25.253693 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 23:05:25.259727 (MainThread): Partial parsing not enabled
2021-07-12 23:05:25.384532 (MainThread): Acquiring new postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:25.394365 (MainThread): Acquiring new postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:25.398440 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.402432 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:25.476316 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6902af0>]}
2021-07-12 23:05:25.482291 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab69c2880>]}
2021-07-12 23:05:25.482627 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 23:05:25.484053 (MainThread): 
2021-07-12 23:05:25.484558 (MainThread): Acquiring new postgres connection "master".
2021-07-12 23:05:25.485654 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k".
2021-07-12 23:05:25.493744 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k".
2021-07-12 23:05:25.494052 (ThreadPoolExecutor-0_0): On list_spotify600k: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k"} */

    select distinct nspname from pg_namespace
  
2021-07-12 23:05:25.494186 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 23:05:25.540949 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-07-12 23:05:25.545519 (ThreadPoolExecutor-0_0): On list_spotify600k: Close
2021-07-12 23:05:25.548185 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:05:25.558127 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:05:25.558356 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 23:05:25.558522 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-12 23:05:25.607976 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-07-12 23:05:25.608157 (ThreadPoolExecutor-1_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:05:25.608252 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 23:05:25.616691 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.01 seconds
2021-07-12 23:05:25.617958 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 23:05:25.618317 (ThreadPoolExecutor-1_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 23:05:25.623029 (MainThread): Using postgres connection "master".
2021-07-12 23:05:25.623224 (MainThread): On master: BEGIN
2021-07-12 23:05:25.623408 (MainThread): Opening a new connection, currently in state init
2021-07-12 23:05:25.835140 (MainThread): SQL status: BEGIN in 0.21 seconds
2021-07-12 23:05:25.835400 (MainThread): Using postgres connection "master".
2021-07-12 23:05:25.835542 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 23:05:25.862459 (MainThread): SQL status: SELECT 6 in 0.03 seconds
2021-07-12 23:05:25.863425 (MainThread): On master: ROLLBACK
2021-07-12 23:05:25.863817 (MainThread): Using postgres connection "master".
2021-07-12 23:05:25.863970 (MainThread): On master: BEGIN
2021-07-12 23:05:25.866916 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-07-12 23:05:25.867091 (MainThread): On master: COMMIT
2021-07-12 23:05:25.867212 (MainThread): Using postgres connection "master".
2021-07-12 23:05:25.867366 (MainThread): On master: COMMIT
2021-07-12 23:05:25.867745 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:25.867920 (MainThread): On master: Close
2021-07-12 23:05:25.868368 (MainThread): 18:05:25 | Concurrency: 1 threads (target='local')
2021-07-12 23:05:25.869164 (MainThread): 18:05:25 | 
2021-07-12 23:05:25.881637 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 23:05:25.882093 (Thread-1): 18:05:25 | 1 of 4 START view model dbt_spotify.stg_artists...................... [RUN]
2021-07-12 23:05:25.882628 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.882824 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 23:05:25.885691 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 23:05:25.887651 (Thread-1): finished collecting timing info
2021-07-12 23:05:25.915046 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.915284 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" cascade
2021-07-12 23:05:25.915458 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 23:05:25.968405 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 23:05:25.970678 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.970812 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 23:05:25.972487 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:25.977052 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-12 23:05:25.978600 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.978757 (Thread-1): On model.spotify_project.stg_artists: BEGIN
2021-07-12 23:05:25.980942 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 23:05:25.981072 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.981155 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */

  create view "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" as (
    SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM "spotify600k"."spotify"."artists"
  );

2021-07-12 23:05:25.988034 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 23:05:25.993983 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.994173 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
alter table "spotify600k"."dbt_spotify"."stg_artists" rename to "stg_artists__dbt_backup"
2021-07-12 23:05:25.994760 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:25.996780 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:25.996964 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
alter table "spotify600k"."dbt_spotify"."stg_artists__dbt_tmp" rename to "stg_artists"
2021-07-12 23:05:25.997491 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:26.003857 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 23:05:26.004071 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:26.004167 (Thread-1): On model.spotify_project.stg_artists: COMMIT
2021-07-12 23:05:26.006332 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:26.009671 (Thread-1): Using postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:05:26.009855 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_artists"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_artists__dbt_backup" cascade
2021-07-12 23:05:26.025078 (Thread-1): SQL status: DROP VIEW in 0.02 seconds
2021-07-12 23:05:26.026694 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.026913 (Thread-1): On model.spotify_project.stg_artists: Close
2021-07-12 23:05:26.027443 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab69aedf0>]}
2021-07-12 23:05:26.028029 (Thread-1): 18:05:26 | 1 of 4 OK created view model dbt_spotify.stg_artists................. [CREATE VIEW in 0.14s]
2021-07-12 23:05:26.028881 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 23:05:26.029208 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 23:05:26.029818 (Thread-1): 18:05:26 | 2 of 4 START view model dbt_spotify.stg_tracks....................... [RUN]
2021-07-12 23:05:26.030409 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.030626 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 23:05:26.034198 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 23:05:26.035561 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.039133 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.039352 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" cascade
2021-07-12 23:05:26.039493 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 23:05:26.089806 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 23:05:26.091721 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.091864 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 23:05:26.093824 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.095595 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-12 23:05:26.096937 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.097122 (Thread-1): On model.spotify_project.stg_tracks: BEGIN
2021-07-12 23:05:26.099369 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 23:05:26.099550 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.099658 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */

  create view "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" as (
    SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM "spotify600k"."spotify"."tracks"
  );

2021-07-12 23:05:26.107570 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 23:05:26.109620 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.109752 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
alter table "spotify600k"."dbt_spotify"."stg_tracks" rename to "stg_tracks__dbt_backup"
2021-07-12 23:05:26.110366 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:26.112182 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.112328 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
alter table "spotify600k"."dbt_spotify"."stg_tracks__dbt_tmp" rename to "stg_tracks"
2021-07-12 23:05:26.112893 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:26.113826 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 23:05:26.113938 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.114016 (Thread-1): On model.spotify_project.stg_tracks: COMMIT
2021-07-12 23:05:26.115183 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:26.117774 (Thread-1): Using postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:05:26.117934 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.stg_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."stg_tracks__dbt_backup" cascade
2021-07-12 23:05:26.121538 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.122605 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.122771 (Thread-1): On model.spotify_project.stg_tracks: Close
2021-07-12 23:05:26.123203 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab606df10>]}
2021-07-12 23:05:26.123649 (Thread-1): 18:05:26 | 2 of 4 OK created view model dbt_spotify.stg_tracks.................. [CREATE VIEW in 0.09s]
2021-07-12 23:05:26.124318 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 23:05:26.124543 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-12 23:05:26.125026 (Thread-1): 18:05:26 | 3 of 4 START view model dbt_spotify.top20_artist_genres.............. [RUN]
2021-07-12 23:05:26.125761 (Thread-1): Acquiring new postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.126021 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-12 23:05:26.129041 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-12 23:05:26.130454 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.133970 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.134172 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_genres__dbt_tmp" cascade
2021-07-12 23:05:26.134372 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 23:05:26.185543 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 23:05:26.187395 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.187539 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_genres__dbt_backup" cascade
2021-07-12 23:05:26.189528 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.191060 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_genres"
2021-07-12 23:05:26.192599 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.192797 (Thread-1): On model.spotify_project.top20_artist_genres: BEGIN
2021-07-12 23:05:26.195523 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 23:05:26.195685 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.195777 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_genres"} */

  create view "spotify600k"."dbt_spotify"."top20_artist_genres__dbt_tmp" as (
    WITH cte1 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
),
cte2 AS
(
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		rnk_followers,
		REPLACE(
			UNNEST(
				string_to_array(
					REPLACE(
						REPLACE(genres,'[',''),
					']',''),
				', '))
			, '''', '') AS genres
FROM cte1
)
SELECT artist_id,
		artist_name,
		followers,
		artist_popularity,
		CAST(genres AS VARCHAR) AS genres
FROM cte2
WHERE rnk_followers<=20
  );

2021-07-12 23:05:26.203541 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 23:05:26.206267 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.206423 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_genres"} */
alter table "spotify600k"."dbt_spotify"."top20_artist_genres__dbt_tmp" rename to "top20_artist_genres"
2021-07-12 23:05:26.207003 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:26.208310 (Thread-1): On model.spotify_project.top20_artist_genres: COMMIT
2021-07-12 23:05:26.208447 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.208555 (Thread-1): On model.spotify_project.top20_artist_genres: COMMIT
2021-07-12 23:05:26.209806 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:26.211645 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:05:26.211808 (Thread-1): On model.spotify_project.top20_artist_genres: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_genres"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_genres__dbt_backup" cascade
2021-07-12 23:05:26.213334 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.214684 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.214874 (Thread-1): On model.spotify_project.top20_artist_genres: Close
2021-07-12 23:05:26.215350 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6062250>]}
2021-07-12 23:05:26.215923 (Thread-1): 18:05:26 | 3 of 4 OK created view model dbt_spotify.top20_artist_genres......... [CREATE VIEW in 0.09s]
2021-07-12 23:05:26.216790 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-12 23:05:26.217098 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-12 23:05:26.217495 (Thread-1): 18:05:26 | 4 of 4 START view model dbt_spotify.top20_artist_tracks.............. [RUN]
2021-07-12 23:05:26.218126 (Thread-1): Acquiring new postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.218318 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-12 23:05:26.221173 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-12 23:05:26.222316 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.224633 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.224778 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_tracks__dbt_tmp" cascade
2021-07-12 23:05:26.224874 (Thread-1): Opening a new connection, currently in state closed
2021-07-12 23:05:26.278212 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-07-12 23:05:26.280117 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.280251 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_tracks__dbt_backup" cascade
2021-07-12 23:05:26.282131 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.283124 (Thread-1): Writing runtime SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-12 23:05:26.284320 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.284542 (Thread-1): On model.spotify_project.top20_artist_tracks: BEGIN
2021-07-12 23:05:26.286633 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-07-12 23:05:26.286763 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.286847 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_tracks"} */

  create view "spotify600k"."dbt_spotify"."top20_artist_tracks__dbt_tmp" as (
    WITH cte1 AS
(
SELECT unnest(
			string_to_array(
			REPLACE(REPLACE(artist_id,'[',''),']',''),',')) AS new_artist_id,
		*
FROM "spotify600k"."dbt_spotify"."stg_tracks"
),
cte2 AS
(
SELECT *,
		DENSE_RANK() OVER (ORDER BY followers desc) AS rnk_followers
FROM "spotify600k"."dbt_spotify"."stg_artists"
)
SELECT c2.artist_id,
		c2.artist_name,
		c2.followers,
		c2.artist_popularity,
		c1.track_id,
		c1.track_name,
		c1.track_popularity,
		c1.release_year,
		c1.explicit,
		c1.danceability,
		c1.energy,
		c1.speechiness,
		c1.acousticness,
		c1.instrumentalness,
		c1.liveness,
		c1.valence
FROM cte1 c1
INNER JOIN cte2 c2
ON c1.new_artist_id LIKE CONCAT('%',c2.artist_id,'%')
WHERE c2.rnk_followers<=20
  );

2021-07-12 23:05:26.295611 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2021-07-12 23:05:26.298362 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.298540 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_tracks"} */
alter table "spotify600k"."dbt_spotify"."top20_artist_tracks__dbt_tmp" rename to "top20_artist_tracks"
2021-07-12 23:05:26.299237 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-07-12 23:05:26.300689 (Thread-1): On model.spotify_project.top20_artist_tracks: COMMIT
2021-07-12 23:05:26.300835 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.300935 (Thread-1): On model.spotify_project.top20_artist_tracks: COMMIT
2021-07-12 23:05:26.302082 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:26.303845 (Thread-1): Using postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:05:26.303998 (Thread-1): On model.spotify_project.top20_artist_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "node_id": "model.spotify_project.top20_artist_tracks"} */
drop view if exists "spotify600k"."dbt_spotify"."top20_artist_tracks__dbt_backup" cascade
2021-07-12 23:05:26.305624 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2021-07-12 23:05:26.306686 (Thread-1): finished collecting timing info
2021-07-12 23:05:26.306837 (Thread-1): On model.spotify_project.top20_artist_tracks: Close
2021-07-12 23:05:26.307348 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '998b41fc-e2ee-49d0-b878-b753fb5a36a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab69b4820>]}
2021-07-12 23:05:26.307874 (Thread-1): 18:05:26 | 4 of 4 OK created view model dbt_spotify.top20_artist_tracks......... [CREATE VIEW in 0.09s]
2021-07-12 23:05:26.308679 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-12 23:05:26.311708 (MainThread): Acquiring new postgres connection "master".
2021-07-12 23:05:26.311976 (MainThread): Using postgres connection "master".
2021-07-12 23:05:26.312144 (MainThread): On master: BEGIN
2021-07-12 23:05:26.312297 (MainThread): Opening a new connection, currently in state closed
2021-07-12 23:05:26.364489 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 23:05:26.364696 (MainThread): On master: COMMIT
2021-07-12 23:05:26.364787 (MainThread): Using postgres connection "master".
2021-07-12 23:05:26.364871 (MainThread): On master: COMMIT
2021-07-12 23:05:26.365106 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-07-12 23:05:26.365228 (MainThread): On master: Close
2021-07-12 23:05:26.365689 (MainThread): 18:05:26 | 
2021-07-12 23:05:26.366335 (MainThread): 18:05:26 | Finished running 4 view models in 0.88s.
2021-07-12 23:05:26.366607 (MainThread): Connection 'master' was properly closed.
2021-07-12 23:05:26.366723 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-12 23:05:26.372924 (MainThread): 
2021-07-12 23:05:26.373218 (MainThread): Completed successfully
2021-07-12 23:05:26.373427 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-07-12 23:05:26.373706 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab68ab550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab606df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6969d00>]}
2021-07-12 23:05:26.373918 (MainThread): Flushing usage events
2021-07-12 23:06:20.591389 (MainThread): Running with dbt=0.19.2
2021-07-12 23:06:20.719560 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-07-12 23:06:20.720618 (MainThread): Tracking: tracking
2021-07-12 23:06:20.735906 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cbde8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cd85dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88db8d7700>]}
2021-07-12 23:06:20.750990 (MainThread): Partial parsing not enabled
2021-07-12 23:06:20.752822 (MainThread): Parsing macros/adapters.sql
2021-07-12 23:06:20.778275 (MainThread): Parsing macros/catalog.sql
2021-07-12 23:06:20.782277 (MainThread): Parsing macros/relations.sql
2021-07-12 23:06:20.784624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-07-12 23:06:20.788411 (MainThread): Parsing macros/core.sql
2021-07-12 23:06:20.792334 (MainThread): Parsing macros/adapters/common.sql
2021-07-12 23:06:20.831287 (MainThread): Parsing macros/etc/datetime.sql
2021-07-12 23:06:20.839101 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-12 23:06:20.840145 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-12 23:06:20.841753 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-12 23:06:20.843654 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-12 23:06:20.845169 (MainThread): Parsing macros/etc/query.sql
2021-07-12 23:06:20.846275 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-12 23:06:20.854119 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-12 23:06:20.866246 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-12 23:06:20.868116 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-12 23:06:20.874003 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-12 23:06:20.890966 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-12 23:06:20.916923 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-12 23:06:20.918703 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-12 23:06:20.933697 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-12 23:06:20.939263 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-12 23:06:20.943623 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-12 23:06:20.948859 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-12 23:06:20.951319 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-12 23:06:20.952806 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-12 23:06:20.954537 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-12 23:06:20.960819 (MainThread): Partial parsing not enabled
2021-07-12 23:06:21.093235 (MainThread): Acquiring new postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:06:21.103875 (MainThread): Acquiring new postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:06:21.108054 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:06:21.112590 (MainThread): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:06:21.235896 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c08edca8-24a5-4d5e-8310-1276c7776b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cb990af0>]}
2021-07-12 23:06:21.242576 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c08edca8-24a5-4d5e-8310-1276c7776b63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cb983fa0>]}
2021-07-12 23:06:21.242937 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-12 23:06:21.244891 (MainThread): 
2021-07-12 23:06:21.245728 (MainThread): Acquiring new postgres connection "master".
2021-07-12 23:06:21.247255 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:06:21.259367 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:06:21.259778 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: BEGIN
2021-07-12 23:06:21.259982 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-12 23:06:21.321363 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2021-07-12 23:06:21.321557 (ThreadPoolExecutor-0_0): Using postgres connection "list_spotify600k_dbt_spotify".
2021-07-12 23:06:21.321642 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "list_spotify600k_dbt_spotify"} */
select
      'spotify600k' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_spotify'
    union all
    select
      'spotify600k' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_spotify'
  
2021-07-12 23:06:21.329057 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.01 seconds
2021-07-12 23:06:21.332045 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: ROLLBACK
2021-07-12 23:06:21.332423 (ThreadPoolExecutor-0_0): On list_spotify600k_dbt_spotify: Close
2021-07-12 23:06:21.340112 (MainThread): Using postgres connection "master".
2021-07-12 23:06:21.340295 (MainThread): On master: BEGIN
2021-07-12 23:06:21.340421 (MainThread): Opening a new connection, currently in state init
2021-07-12 23:06:21.387752 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-07-12 23:06:21.387939 (MainThread): Using postgres connection "master".
2021-07-12 23:06:21.388027 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-07-12 23:06:21.407274 (MainThread): SQL status: SELECT 6 in 0.02 seconds
2021-07-12 23:06:21.408043 (MainThread): On master: ROLLBACK
2021-07-12 23:06:21.408285 (MainThread): On master: Close
2021-07-12 23:06:21.408723 (MainThread): 18:06:21 | Concurrency: 1 threads (target='local')
2021-07-12 23:06:21.409425 (MainThread): 18:06:21 | 
2021-07-12 23:06:21.420359 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-12 23:06:21.420826 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_artists".
2021-07-12 23:06:21.421014 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-12 23:06:21.423500 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-12 23:06:21.424480 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.424907 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.425493 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-12 23:06:21.425661 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-12 23:06:21.426093 (Thread-1): Acquiring new postgres connection "model.spotify_project.stg_tracks".
2021-07-12 23:06:21.426221 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-12 23:06:21.428356 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-12 23:06:21.429802 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.430184 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.430800 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-12 23:06:21.431128 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-12 23:06:21.432007 (Thread-1): Acquiring new postgres connection "model.spotify_project.top20_artist_genres".
2021-07-12 23:06:21.432338 (Thread-1): Compiling model.spotify_project.top20_artist_genres
2021-07-12 23:06:21.434727 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_genres"
2021-07-12 23:06:21.435700 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.435896 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.436211 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-12 23:06:21.436343 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-12 23:06:21.436700 (Thread-1): Acquiring new postgres connection "model.spotify_project.top20_artist_tracks".
2021-07-12 23:06:21.436813 (Thread-1): Compiling model.spotify_project.top20_artist_tracks
2021-07-12 23:06:21.439000 (Thread-1): Writing injected SQL for node "model.spotify_project.top20_artist_tracks"
2021-07-12 23:06:21.439886 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.440073 (Thread-1): finished collecting timing info
2021-07-12 23:06:21.440376 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-12 23:06:21.441940 (MainThread): Connection 'master' was properly closed.
2021-07-12 23:06:21.442123 (MainThread): Connection 'model.spotify_project.top20_artist_tracks' was properly closed.
2021-07-12 23:06:21.447553 (MainThread): 18:06:21 | Done.
2021-07-12 23:06:21.451553 (MainThread): Acquiring new postgres connection "generate_catalog".
2021-07-12 23:06:21.451776 (MainThread): 18:06:21 | Building catalog
2021-07-12 23:06:21.456072 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "spotify600k.information_schema".
2021-07-12 23:06:21.463410 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 23:06:21.463608 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: BEGIN
2021-07-12 23:06:21.463711 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-07-12 23:06:21.694249 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.23 seconds
2021-07-12 23:06:21.694686 (ThreadPoolExecutor-1_0): Using postgres connection "spotify600k.information_schema".
2021-07-12 23:06:21.694937 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "local", "connection_name": "spotify600k.information_schema"} */

    
    

    select
        'spotify600k' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('dbt_spotify') or upper(sch.nspname) = upper('spotify'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2021-07-12 23:06:21.725438 (ThreadPoolExecutor-1_0): SQL status: SELECT 81 in 0.03 seconds
2021-07-12 23:06:21.746617 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: ROLLBACK
2021-07-12 23:06:21.747499 (ThreadPoolExecutor-1_0): On spotify600k.information_schema: Close
2021-07-12 23:06:21.776049 (MainThread): 18:06:21 | Catalog written to /home/zfan/meltano-projects/dbt/target/catalog.json
2021-07-12 23:06:21.777821 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cbde8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cb9788e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88cb978640>]}
2021-07-12 23:06:21.778667 (MainThread): Flushing usage events
2021-07-12 23:06:22.056486 (MainThread): Connection 'generate_catalog' was properly closed.
2021-07-12 23:06:22.057669 (MainThread): Connection 'spotify600k.information_schema' was properly closed.
2021-07-12 23:06:28.694533 (MainThread): Running with dbt=0.19.2
2021-07-12 23:06:28.819309 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-07-12 23:06:28.820427 (MainThread): Tracking: tracking
2021-07-12 23:06:28.832608 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa302593a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303ffdd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3120736a0>]}
2021-07-12 23:06:28.835844 (MainThread): Serving docs at 0.0.0.0:8080
2021-07-12 23:06:28.836454 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-07-12 23:06:28.836921 (MainThread): Press Ctrl+C to exit.


2021-07-13 16:28:08.936465 (MainThread): Running with dbt=0.19.2
2021-07-13 16:28:09.586419 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 16:28:09.599332 (MainThread): Tracking: tracking
2021-07-13 16:28:09.610743 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f690ebb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4050fdbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f691f370>]}
2021-07-13 16:28:09.630691 (MainThread): Partial parsing not enabled
2021-07-13 16:28:09.641388 (MainThread): Parsing macros/adapters.sql
2021-07-13 16:28:09.671857 (MainThread): Parsing macros/catalog.sql
2021-07-13 16:28:09.684322 (MainThread): Parsing macros/etc.sql
2021-07-13 16:28:09.693502 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 16:28:09.705717 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 16:28:09.728191 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 16:28:09.737689 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 16:28:09.747536 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 16:28:09.763987 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 16:28:09.776867 (MainThread): Parsing macros/core.sql
2021-07-13 16:28:09.791733 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 16:28:09.838163 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 16:28:09.852419 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 16:28:09.859846 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 16:28:09.867971 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 16:28:09.876401 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 16:28:09.884551 (MainThread): Parsing macros/etc/query.sql
2021-07-13 16:28:09.892248 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 16:28:09.907712 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 16:28:09.931295 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 16:28:09.940230 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 16:28:09.953268 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 16:28:09.982663 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 16:28:10.018026 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 16:28:10.030599 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 16:28:10.053859 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 16:28:10.066850 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 16:28:10.078365 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 16:28:10.093095 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 16:28:10.102306 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 16:28:10.110305 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 16:28:10.118653 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 16:28:10.125902 (MainThread): Partial parsing not enabled
2021-07-13 16:28:10.351229 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 16:28:10.367798 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 16:28:10.378232 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:28:10.388683 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:28:10.488488 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0918199d-8aac-4662-9b28-948a34405372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6654430>]}
2021-07-13 16:28:10.494414 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0918199d-8aac-4662-9b28-948a34405372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6788040>]}
2021-07-13 16:28:10.494750 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 16:28:10.496014 (MainThread): 
2021-07-13 16:28:10.496499 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:28:10.497513 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 16:28:10.497693 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 16:28:10.904873 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 16:28:10.905630 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 16:28:10.918445 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 16:28:11.296399 (MainThread): 11:28:11 | Concurrency: 1 threads (target='prod')
2021-07-13 16:28:11.297913 (MainThread): 11:28:11 | 
2021-07-13 16:28:11.353244 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 16:28:11.354151 (Thread-1): 11:28:11 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 16:28:11.356210 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:28:11.356731 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 16:28:11.365077 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:28:11.368855 (Thread-1): finished collecting timing info
2021-07-13 16:28:11.426205 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:28:11.428408 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:28:11.434713 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:28:11.950430 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:28:11.951104 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a33828ee-4766-45e6-9dd2-26b720e2990d?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US

(job ID: a33828ee-4766-45e6-9dd2-26b720e2990d)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-07-13 16:28:11.951888 (Thread-1): finished collecting timing info
2021-07-13 16:28:11.953061 (Thread-1): Runtime Error in model stg_artists (models/staging/stg_artists.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a33828ee-4766-45e6-9dd2-26b720e2990d?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
  
  (job ID: a33828ee-4766-45e6-9dd2-26b720e2990d)
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a33828ee-4766-45e6-9dd2-26b720e2990d?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US

(job ID: a33828ee-4766-45e6-9dd2-26b720e2990d)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 183, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stg_artists (models/staging/stg_artists.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a33828ee-4766-45e6-9dd2-26b720e2990d?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
  
  (job ID: a33828ee-4766-45e6-9dd2-26b720e2990d)
2021-07-13 16:28:12.158537 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0918199d-8aac-4662-9b28-948a34405372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f66ef820>]}
2021-07-13 16:28:12.158911 (Thread-1): 11:28:12 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 0.80s]
2021-07-13 16:28:12.159590 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 16:28:12.159763 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 16:28:12.159979 (Thread-1): 11:28:12 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 16:28:12.160543 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:28:12.160683 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 16:28:12.161867 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64333, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:28:12.162098 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64334, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:28:12.163870 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:28:12.165248 (Thread-1): finished collecting timing info
2021-07-13 16:28:12.167301 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:28:12.168586 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:28:12.173352 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:28:12.749533 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:28:12.750339 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a2b46aed-1edc-4b96-83a1-ce2845528a22?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US

(job ID: a2b46aed-1edc-4b96-83a1-ce2845528a22)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-07-13 16:28:12.751149 (Thread-1): finished collecting timing info
2021-07-13 16:28:12.752395 (Thread-1): Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a2b46aed-1edc-4b96-83a1-ce2845528a22?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
  
  (job ID: a2b46aed-1edc-4b96-83a1-ce2845528a22)
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a2b46aed-1edc-4b96-83a1-ce2845528a22?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US

(job ID: a2b46aed-1edc-4b96-83a1-ce2845528a22)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 183, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a2b46aed-1edc-4b96-83a1-ce2845528a22?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
  
  (job ID: a2b46aed-1edc-4b96-83a1-ce2845528a22)
2021-07-13 16:28:12.755640 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0918199d-8aac-4662-9b28-948a34405372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6697850>]}
2021-07-13 16:28:12.756763 (Thread-1): 11:28:12 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 0.60s]
2021-07-13 16:28:12.758856 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 16:28:12.759473 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 16:28:12.760603 (Thread-1): 11:28:12 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 16:28:12.762228 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 16:28:12.762811 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 16:28:12.763655 (Thread-1): 11:28:12 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 16:28:12.764917 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 16:28:12.771515 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:28:12.772777 (MainThread): 11:28:12 | 
2021-07-13 16:28:12.773911 (MainThread): 11:28:12 | Finished running 4 view models in 2.28s.
2021-07-13 16:28:12.775162 (MainThread): Connection 'master' was properly closed.
2021-07-13 16:28:12.775600 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 16:28:12.778988 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64335, 0, 0), raddr=('2607:f8b0:4000:80a::200a', 443, 0, 0)>
2021-07-13 16:28:12.779767 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64336, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 16:28:12.786933 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64329, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 16:28:12.787705 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64328, 0, 0), raddr=('2607:f8b0:4000:807::200a', 443, 0, 0)>
2021-07-13 16:28:12.788264 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64331, 0, 0), raddr=('2607:f8b0:4023:1000::5f', 443, 0, 0)>
2021-07-13 16:28:12.788749 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64332, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 16:28:12.809873 (MainThread): 
2021-07-13 16:28:12.810967 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 16:28:12.812138 (MainThread): 
2021-07-13 16:28:12.814069 (MainThread): Runtime Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 16:28:12.816112 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a33828ee-4766-45e6-9dd2-26b720e2990d?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
2021-07-13 16:28:12.819178 (MainThread):   
2021-07-13 16:28:12.821117 (MainThread):   (job ID: a33828ee-4766-45e6-9dd2-26b720e2990d)
2021-07-13 16:28:12.823120 (MainThread): 
2021-07-13 16:28:12.825791 (MainThread): Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 16:28:12.827582 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/a2b46aed-1edc-4b96-83a1-ce2845528a22?maxResults=0&location=US&prettyPrint=false: Not found: Dataset spotify600k:spotify was not found in location US
2021-07-13 16:28:12.848364 (MainThread):   
2021-07-13 16:28:12.850333 (MainThread):   (job ID: a2b46aed-1edc-4b96-83a1-ce2845528a22)
2021-07-13 16:28:12.852331 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 16:28:12.855965 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f67e5be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f672b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f668d460>]}
2021-07-13 16:28:12.856845 (MainThread): Flushing usage events
2021-07-13 16:31:58.559141 (MainThread): Running with dbt=0.19.2
2021-07-13 16:31:59.202655 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 16:31:59.203693 (MainThread): Tracking: tracking
2021-07-13 16:31:59.215742 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de3c4f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39ecb9ed00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de3d92b0>]}
2021-07-13 16:31:59.228530 (MainThread): Partial parsing not enabled
2021-07-13 16:31:59.230144 (MainThread): Parsing macros/adapters.sql
2021-07-13 16:31:59.249872 (MainThread): Parsing macros/catalog.sql
2021-07-13 16:31:59.255591 (MainThread): Parsing macros/etc.sql
2021-07-13 16:31:59.257833 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 16:31:59.262391 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 16:31:59.274005 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 16:31:59.276592 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 16:31:59.278373 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 16:31:59.286513 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 16:31:59.291082 (MainThread): Parsing macros/core.sql
2021-07-13 16:31:59.294492 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 16:31:59.328393 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 16:31:59.335266 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 16:31:59.336188 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 16:31:59.337606 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 16:31:59.339271 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 16:31:59.340633 (MainThread): Parsing macros/etc/query.sql
2021-07-13 16:31:59.341585 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 16:31:59.348618 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 16:31:59.360479 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 16:31:59.362064 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 16:31:59.367165 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 16:31:59.383358 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 16:31:59.407386 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 16:31:59.408946 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 16:31:59.422527 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 16:31:59.427619 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 16:31:59.431605 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 16:31:59.436363 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 16:31:59.438569 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 16:31:59.439910 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 16:31:59.441495 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 16:31:59.447638 (MainThread): Partial parsing not enabled
2021-07-13 16:31:59.668780 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 16:31:59.677976 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 16:31:59.682456 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:31:59.686182 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:31:59.757742 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7dc89521-bc22-4dc7-a492-899a22e8e76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de112fd0>]}
2021-07-13 16:31:59.762713 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7dc89521-bc22-4dc7-a492-899a22e8e76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de237460>]}
2021-07-13 16:31:59.763006 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 16:31:59.764249 (MainThread): 
2021-07-13 16:31:59.764734 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:31:59.765762 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 16:31:59.765939 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 16:32:00.154379 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 16:32:00.155351 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 16:32:00.169523 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 16:32:00.550295 (MainThread): 11:32:00 | Concurrency: 1 threads (target='prod')
2021-07-13 16:32:00.551738 (MainThread): 11:32:00 | 
2021-07-13 16:32:00.583359 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 16:32:00.584288 (Thread-1): 11:32:00 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 16:32:00.585934 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:32:00.586717 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 16:32:00.599413 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:32:00.601738 (Thread-1): finished collecting timing info
2021-07-13 16:32:00.654719 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:32:00.655710 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:32:00.659908 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:32:01.303929 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:32:01.304687 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/454b74a5-3e4c-428e-b534-7acf150011d6?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.artists was not found in location US

(job ID: 454b74a5-3e4c-428e-b534-7acf150011d6)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-07-13 16:32:01.305497 (Thread-1): finished collecting timing info
2021-07-13 16:32:01.306816 (Thread-1): Runtime Error in model stg_artists (models/staging/stg_artists.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/454b74a5-3e4c-428e-b534-7acf150011d6?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.artists was not found in location US
  
  (job ID: 454b74a5-3e4c-428e-b534-7acf150011d6)
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/454b74a5-3e4c-428e-b534-7acf150011d6?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.artists was not found in location US

(job ID: 454b74a5-3e4c-428e-b534-7acf150011d6)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 183, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stg_artists (models/staging/stg_artists.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/454b74a5-3e4c-428e-b534-7acf150011d6?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.artists was not found in location US
  
  (job ID: 454b74a5-3e4c-428e-b534-7acf150011d6)
2021-07-13 16:32:01.327892 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7dc89521-bc22-4dc7-a492-899a22e8e76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de12bee0>]}
2021-07-13 16:32:01.328965 (Thread-1): 11:32:01 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 0.74s]
2021-07-13 16:32:01.330817 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 16:32:01.331639 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 16:32:01.332732 (Thread-1): 11:32:01 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 16:32:01.335227 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:32:01.335945 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 16:32:01.339501 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53739, 0, 0), raddr=('2607:f8b0:4000:809::200a', 443, 0, 0)>
2021-07-13 16:32:01.340515 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53740, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 16:32:01.346819 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:32:01.349471 (Thread-1): finished collecting timing info
2021-07-13 16:32:01.357060 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:32:01.362494 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:32:01.382759 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:32:01.942047 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:32:01.942670 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/ee66d8cf-3d9c-4d47-bffb-3c6b405435ac?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.tracks was not found in location US

(job ID: ee66d8cf-3d9c-4d47-bffb-3c6b405435ac)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-07-13 16:32:01.943358 (Thread-1): finished collecting timing info
2021-07-13 16:32:01.944854 (Thread-1): Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/ee66d8cf-3d9c-4d47-bffb-3c6b405435ac?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.tracks was not found in location US
  
  (job ID: ee66d8cf-3d9c-4d47-bffb-3c6b405435ac)
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/ee66d8cf-3d9c-4d47-bffb-3c6b405435ac?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.tracks was not found in location US

(job ID: ee66d8cf-3d9c-4d47-bffb-3c6b405435ac)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 183, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/ee66d8cf-3d9c-4d47-bffb-3c6b405435ac?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.tracks was not found in location US
  
  (job ID: ee66d8cf-3d9c-4d47-bffb-3c6b405435ac)
2021-07-13 16:32:01.948715 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7dc89521-bc22-4dc7-a492-899a22e8e76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de2342b0>]}
2021-07-13 16:32:01.950003 (Thread-1): 11:32:01 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 0.61s]
2021-07-13 16:32:01.952512 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 16:32:01.953549 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 16:32:01.954667 (Thread-1): 11:32:01 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 16:32:01.958264 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 16:32:01.959522 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 16:32:01.960866 (Thread-1): 11:32:01 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 16:32:01.962331 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 16:32:01.970951 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:32:01.972957 (MainThread): 11:32:01 | 
2021-07-13 16:32:01.982663 (MainThread): 11:32:01 | Finished running 4 view models in 2.21s.
2021-07-13 16:32:01.985120 (MainThread): Connection 'master' was properly closed.
2021-07-13 16:32:01.986153 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 16:32:01.991111 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53741, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:32:01.992863 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53742, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 16:32:01.999541 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53736, 0, 0), raddr=('2607:f8b0:4000:80a::200a', 443, 0, 0)>
2021-07-13 16:32:02.000769 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53735, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:32:02.002218 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53737, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 16:32:02.003955 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 53738, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:32:02.025193 (MainThread): 
2021-07-13 16:32:02.025755 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 16:32:02.026734 (MainThread): 
2021-07-13 16:32:02.027532 (MainThread): Runtime Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 16:32:02.028506 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/454b74a5-3e4c-428e-b534-7acf150011d6?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.artists was not found in location US
2021-07-13 16:32:02.029996 (MainThread):   
2021-07-13 16:32:02.030912 (MainThread):   (job ID: 454b74a5-3e4c-428e-b534-7acf150011d6)
2021-07-13 16:32:02.031829 (MainThread): 
2021-07-13 16:32:02.036979 (MainThread): Runtime Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 16:32:02.044599 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/ee66d8cf-3d9c-4d47-bffb-3c6b405435ac?maxResults=0&location=US&prettyPrint=false: Not found: Table spotify600k:spotify.tracks was not found in location US
2021-07-13 16:32:02.045349 (MainThread):   
2021-07-13 16:32:02.046275 (MainThread):   (job ID: ee66d8cf-3d9c-4d47-bffb-3c6b405435ac)
2021-07-13 16:32:02.047235 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 16:32:02.053779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de1ded90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de2341f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39de0f2d00>]}
2021-07-13 16:32:02.054968 (MainThread): Flushing usage events
2021-07-13 16:35:38.092901 (MainThread): Running with dbt=0.19.2
2021-07-13 16:35:38.758535 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 16:35:38.759707 (MainThread): Tracking: tracking
2021-07-13 16:35:38.773937 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd1731adf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd25afec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd1732d370>]}
2021-07-13 16:35:38.787321 (MainThread): Partial parsing not enabled
2021-07-13 16:35:38.788959 (MainThread): Parsing macros/adapters.sql
2021-07-13 16:35:38.818261 (MainThread): Parsing macros/catalog.sql
2021-07-13 16:35:38.833780 (MainThread): Parsing macros/etc.sql
2021-07-13 16:35:38.837929 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 16:35:38.844612 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 16:35:38.859766 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 16:35:38.862567 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 16:35:38.864454 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 16:35:38.873211 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 16:35:38.877276 (MainThread): Parsing macros/core.sql
2021-07-13 16:35:38.881543 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 16:35:38.917544 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 16:35:38.925015 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 16:35:38.926023 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 16:35:38.927547 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 16:35:38.929369 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 16:35:38.930883 (MainThread): Parsing macros/etc/query.sql
2021-07-13 16:35:38.931964 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 16:35:38.939457 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 16:35:38.950679 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 16:35:38.952292 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 16:35:38.957629 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 16:35:38.973968 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 16:35:38.998479 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 16:35:39.000053 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 16:35:39.014015 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 16:35:39.019262 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 16:35:39.023961 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 16:35:39.028969 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 16:35:39.031267 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 16:35:39.032655 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 16:35:39.034280 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 16:35:39.040742 (MainThread): Partial parsing not enabled
2021-07-13 16:35:39.253395 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 16:35:39.262750 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 16:35:39.266505 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:35:39.270094 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:35:39.341251 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '747cf858-6141-4206-a21b-52ec3fc8d40c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd170545e0>]}
2021-07-13 16:35:39.345995 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '747cf858-6141-4206-a21b-52ec3fc8d40c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd17187e80>]}
2021-07-13 16:35:39.346282 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 16:35:39.347495 (MainThread): 
2021-07-13 16:35:39.347929 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:35:39.348948 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 16:35:39.349234 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 16:35:39.734971 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 16:35:39.735743 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 16:35:39.750402 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 16:35:40.145679 (MainThread): 11:35:40 | Concurrency: 1 threads (target='prod')
2021-07-13 16:35:40.147379 (MainThread): 11:35:40 | 
2021-07-13 16:35:40.176152 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 16:35:40.177099 (Thread-1): 11:35:40 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 16:35:40.178670 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:35:40.179263 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 16:35:40.190015 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:35:40.193032 (Thread-1): finished collecting timing info
2021-07-13 16:35:40.255506 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:35:40.257321 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:35:40.266510 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:35:40.967552 (Thread-1): finished collecting timing info
2021-07-13 16:35:40.968841 (Thread-1): Database Error in model stg_artists (models/staging/stg_artists.sql)
  Access Denied: Table spotify600k:spotify.artists: User does not have permission to query table spotify600k:spotify.artists.
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/2ecc6882-e36d-447a-bfa9-25673e3db77f?maxResults=0&location=US&prettyPrint=false: Access Denied: Table spotify600k:spotify.artists: User does not have permission to query table spotify600k:spotify.artists.

(job ID: 2ecc6882-e36d-447a-bfa9-25673e3db77f)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 159, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_artists (models/staging/stg_artists.sql)
  Access Denied: Table spotify600k:spotify.artists: User does not have permission to query table spotify600k:spotify.artists.
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:35:40.989688 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '747cf858-6141-4206-a21b-52ec3fc8d40c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd17039f40>]}
2021-07-13 16:35:40.990765 (Thread-1): 11:35:40 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 0.81s]
2021-07-13 16:35:40.992570 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 16:35:40.993132 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 16:35:40.994569 (Thread-1): 11:35:40 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 16:35:40.996064 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:35:40.996588 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 16:35:40.999776 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55157, 0, 0), raddr=('2607:f8b0:4023:1000::5f', 443, 0, 0)>
2021-07-13 16:35:41.000898 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55158, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 16:35:41.009207 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:35:41.012063 (Thread-1): finished collecting timing info
2021-07-13 16:35:41.020276 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:35:41.023761 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:35:41.039553 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:35:41.634033 (Thread-1): finished collecting timing info
2021-07-13 16:35:41.635491 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Access Denied: Table spotify600k:spotify.tracks: User does not have permission to query table spotify600k:spotify.tracks.
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/3e022354-3bca-4d85-a9ff-66a0f8b8d40c?maxResults=0&location=US&prettyPrint=false: Access Denied: Table spotify600k:spotify.tracks: User does not have permission to query table spotify600k:spotify.tracks.

(job ID: 3e022354-3bca-4d85-a9ff-66a0f8b8d40c)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 159, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Access Denied: Table spotify600k:spotify.tracks: User does not have permission to query table spotify600k:spotify.tracks.
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:35:41.639249 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '747cf858-6141-4206-a21b-52ec3fc8d40c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd170355b0>]}
2021-07-13 16:35:41.640668 (Thread-1): 11:35:41 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 0.64s]
2021-07-13 16:35:41.642770 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 16:35:41.643404 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 16:35:41.644484 (Thread-1): 11:35:41 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 16:35:41.646102 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 16:35:41.646683 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 16:35:41.647643 (Thread-1): 11:35:41 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 16:35:41.648828 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 16:35:41.655949 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:35:41.657311 (MainThread): 11:35:41 | 
2021-07-13 16:35:41.658440 (MainThread): 11:35:41 | Finished running 4 view models in 2.31s.
2021-07-13 16:35:41.659515 (MainThread): Connection 'master' was properly closed.
2021-07-13 16:35:41.659931 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 16:35:41.665120 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55159, 0, 0), raddr=('2607:f8b0:4023:1004::5f', 443, 0, 0)>
2021-07-13 16:35:41.666301 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55160, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 16:35:41.672565 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55154, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 16:35:41.673545 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55153, 0, 0), raddr=('2607:f8b0:4023:1000::5f', 443, 0, 0)>
2021-07-13 16:35:41.674260 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55155, 0, 0), raddr=('2607:f8b0:4023:1004::5f', 443, 0, 0)>
2021-07-13 16:35:41.674880 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 55156, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:35:41.694439 (MainThread): 
2021-07-13 16:35:41.695424 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 16:35:41.696527 (MainThread): 
2021-07-13 16:35:41.697407 (MainThread): Database Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 16:35:41.698403 (MainThread):   Access Denied: Table spotify600k:spotify.artists: User does not have permission to query table spotify600k:spotify.artists.
2021-07-13 16:35:41.700521 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:35:41.702851 (MainThread): 
2021-07-13 16:35:41.705512 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 16:35:41.707372 (MainThread):   Access Denied: Table spotify600k:spotify.tracks: User does not have permission to query table spotify600k:spotify.tracks.
2021-07-13 16:35:41.718512 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:35:41.720740 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 16:35:41.731281 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd1712b0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd17097bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd172bdd00>]}
2021-07-13 16:35:41.732202 (MainThread): Flushing usage events
2021-07-13 16:53:44.923726 (MainThread): Running with dbt=0.19.2
2021-07-13 16:53:45.622392 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 16:53:45.623471 (MainThread): Tracking: tracking
2021-07-13 16:53:45.639913 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71abadcca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d30d520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d30d550>]}
2021-07-13 16:53:45.656421 (MainThread): Partial parsing not enabled
2021-07-13 16:53:45.658110 (MainThread): Parsing macros/adapters.sql
2021-07-13 16:53:45.689500 (MainThread): Parsing macros/catalog.sql
2021-07-13 16:53:45.696679 (MainThread): Parsing macros/etc.sql
2021-07-13 16:53:45.699044 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 16:53:45.703672 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 16:53:45.715790 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 16:53:45.718525 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 16:53:45.720373 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 16:53:45.729472 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 16:53:45.733850 (MainThread): Parsing macros/core.sql
2021-07-13 16:53:45.737396 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 16:53:45.772537 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 16:53:45.780013 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 16:53:45.781044 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 16:53:45.782546 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 16:53:45.784271 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 16:53:45.785667 (MainThread): Parsing macros/etc/query.sql
2021-07-13 16:53:45.786653 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 16:53:45.793994 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 16:53:45.805460 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 16:53:45.807105 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 16:53:45.812635 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 16:53:45.829516 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 16:53:45.854641 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 16:53:45.856341 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 16:53:45.870591 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 16:53:45.875959 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 16:53:45.880524 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 16:53:45.885544 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 16:53:45.887892 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 16:53:45.889291 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 16:53:45.890936 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 16:53:45.897499 (MainThread): Partial parsing not enabled
2021-07-13 16:53:46.115631 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 16:53:46.125292 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 16:53:46.129769 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:53:46.133869 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:53:46.210681 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42db5d9b-4a9a-4b4e-8bc5-8f725470bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d0403a0>]}
2021-07-13 16:53:46.216230 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42db5d9b-4a9a-4b4e-8bc5-8f725470bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d167220>]}
2021-07-13 16:53:46.216567 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 16:53:46.217825 (MainThread): 
2021-07-13 16:53:46.218261 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:53:46.219275 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 16:53:46.219458 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 16:53:46.618214 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 16:53:46.619091 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 16:53:46.633728 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 16:53:47.034730 (MainThread): 11:53:47 | Concurrency: 1 threads (target='prod')
2021-07-13 16:53:47.036631 (MainThread): 11:53:47 | 
2021-07-13 16:53:47.074037 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 16:53:47.075095 (Thread-1): 11:53:47 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 16:53:47.077095 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:53:47.078232 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 16:53:47.090023 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:53:47.093109 (Thread-1): finished collecting timing info
2021-07-13 16:53:47.174467 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:53:47.175828 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:53:47.181958 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:53:48.182487 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/768a7268-b353-4325-8b8e-748d59bfa023?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]')
2021-07-13 16:53:49.076496 (Thread-1): finished collecting timing info
2021-07-13 16:53:49.078750 (Thread-1): Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/2dfc7312-d0fb-4e1d-be5a-d52dd77dbaf9?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]

(job ID: 2dfc7312-d0fb-4e1d-be5a-d52dd77dbaf9)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:53:49.107301 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42db5d9b-4a9a-4b4e-8bc5-8f725470bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d10ef10>]}
2021-07-13 16:53:49.108178 (Thread-1): 11:53:49 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 2.03s]
2021-07-13 16:53:49.109688 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 16:53:49.110138 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 16:53:49.111684 (Thread-1): 11:53:49 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 16:53:49.113147 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:53:49.113572 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 16:53:49.115174 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64784, 0, 0), raddr=('2607:f8b0:4000:809::200a', 443, 0, 0)>
2021-07-13 16:53:49.115597 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64785, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 16:53:49.119898 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:53:49.121441 (Thread-1): finished collecting timing info
2021-07-13 16:53:49.124496 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:53:49.125983 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:53:49.132913 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:53:49.879981 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/73171637-8d16-4ce6-9435-4f1d9179cd07?maxResults=0&location=US&prettyPrint=false: Function not found: TO_DATE at [13:17]')
2021-07-13 16:53:50.871648 (Thread-1): finished collecting timing info
2021-07-13 16:53:50.873500 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Function not found: TO_DATE at [13:17]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/73bedffc-bbc7-49c1-ba5e-47c50b2045df?maxResults=0&location=US&prettyPrint=false: Function not found: TO_DATE at [13:17]

(job ID: 73bedffc-bbc7-49c1-ba5e-47c50b2045df)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Function not found: TO_DATE at [13:17]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:53:50.877547 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42db5d9b-4a9a-4b4e-8bc5-8f725470bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719c67ee80>]}
2021-07-13 16:53:50.879485 (Thread-1): 11:53:50 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 1.76s]
2021-07-13 16:53:50.882789 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 16:53:50.884044 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 16:53:50.886001 (Thread-1): 11:53:50 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 16:53:50.888422 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 16:53:50.889617 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 16:53:50.891330 (Thread-1): 11:53:50 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 16:53:50.893005 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 16:53:50.904714 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:53:50.906912 (MainThread): 11:53:50 | 
2021-07-13 16:53:50.914509 (MainThread): 11:53:50 | Finished running 4 view models in 4.69s.
2021-07-13 16:53:50.921612 (MainThread): Connection 'master' was properly closed.
2021-07-13 16:53:50.922372 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 16:53:50.937888 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64781, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:53:50.939672 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64780, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 16:53:50.941024 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64782, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:53:50.941948 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64783, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:53:50.950406 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64786, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:53:50.951737 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 64787, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:53:50.985371 (MainThread): 
2021-07-13 16:53:50.987554 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 16:53:51.004904 (MainThread): 
2021-07-13 16:53:51.018299 (MainThread): Database Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 16:53:51.021874 (MainThread):   Type not found: varchar at [12:30]
2021-07-13 16:53:51.025124 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:53:51.030004 (MainThread): 
2021-07-13 16:53:51.033329 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 16:53:51.036845 (MainThread):   Function not found: TO_DATE at [13:17]
2021-07-13 16:53:51.057437 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:53:51.060254 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 16:53:51.067704 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d019070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719d164d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71bbe1d1f0>]}
2021-07-13 16:53:51.069656 (MainThread): Flushing usage events
2021-07-13 16:58:53.631811 (MainThread): Running with dbt=0.19.2
2021-07-13 16:58:54.306434 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 16:58:54.307650 (MainThread): Tracking: tracking
2021-07-13 16:58:54.321713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313e02fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3225eed00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313e1f3d0>]}
2021-07-13 16:58:54.334521 (MainThread): Partial parsing not enabled
2021-07-13 16:58:54.336171 (MainThread): Parsing macros/adapters.sql
2021-07-13 16:58:54.355874 (MainThread): Parsing macros/catalog.sql
2021-07-13 16:58:54.361623 (MainThread): Parsing macros/etc.sql
2021-07-13 16:58:54.363882 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 16:58:54.368418 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 16:58:54.379884 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 16:58:54.382390 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 16:58:54.384120 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 16:58:54.392211 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 16:58:54.396109 (MainThread): Parsing macros/core.sql
2021-07-13 16:58:54.399329 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 16:58:54.433011 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 16:58:54.439791 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 16:58:54.440672 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 16:58:54.442084 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 16:58:54.443762 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 16:58:54.445130 (MainThread): Parsing macros/etc/query.sql
2021-07-13 16:58:54.446093 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 16:58:54.453281 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 16:58:54.463956 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 16:58:54.465533 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 16:58:54.470341 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 16:58:54.486140 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 16:58:54.509951 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 16:58:54.511502 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 16:58:54.525038 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 16:58:54.530356 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 16:58:54.534341 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 16:58:54.539100 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 16:58:54.541346 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 16:58:54.542971 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 16:58:54.544754 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 16:58:54.550816 (MainThread): Partial parsing not enabled
2021-07-13 16:58:54.762594 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 16:58:54.771740 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 16:58:54.775393 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:58:54.779005 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:58:54.849018 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85d29811-6127-47d6-b846-3037d2e4b397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313b50fd0>]}
2021-07-13 16:58:54.853902 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85d29811-6127-47d6-b846-3037d2e4b397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313c77070>]}
2021-07-13 16:58:54.854195 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 16:58:54.855433 (MainThread): 
2021-07-13 16:58:54.855903 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:58:54.856947 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 16:58:54.857255 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 16:58:55.258265 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 16:58:55.259038 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 16:58:55.272684 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 16:58:55.644039 (MainThread): 11:58:55 | Concurrency: 1 threads (target='prod')
2021-07-13 16:58:55.645726 (MainThread): 11:58:55 | 
2021-07-13 16:58:55.675772 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 16:58:55.676877 (Thread-1): 11:58:55 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 16:58:55.679083 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 16:58:55.679689 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 16:58:55.689172 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:58:55.691489 (Thread-1): finished collecting timing info
2021-07-13 16:58:55.737621 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 16:58:55.738784 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:58:55.743157 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS nvarchar) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 16:58:56.776597 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/9d067b2e-0409-401e-b426-efa52d6b5dc5?maxResults=0&location=US&prettyPrint=false: Type not found: nvarchar at [12:30]')
2021-07-13 16:58:58.247889 (Thread-1): finished collecting timing info
2021-07-13 16:58:58.249510 (Thread-1): Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: nvarchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/36f9f20a-745f-4d46-befa-e102665f687f?maxResults=0&location=US&prettyPrint=false: Type not found: nvarchar at [12:30]

(job ID: 36f9f20a-745f-4d46-befa-e102665f687f)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS nvarchar) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: nvarchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:58:58.274138 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85d29811-6127-47d6-b846-3037d2e4b397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313c1b340>]}
2021-07-13 16:58:58.275855 (Thread-1): 11:58:58 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 2.60s]
2021-07-13 16:58:58.278357 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 16:58:58.279157 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 16:58:58.281059 (Thread-1): 11:58:58 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 16:58:58.282996 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 16:58:58.283543 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 16:58:58.286616 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51681, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:58:58.287911 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51682, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:58:58.297092 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:58:58.300410 (Thread-1): finished collecting timing info
2021-07-13 16:58:58.310769 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 16:58:58.314438 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 16:58:58.334136 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		TO_DATE(release_date, 'YYYY') AS release_year,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 16:58:59.133227 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/8ed7f2f3-96ed-48c7-986d-a7853be31fd5?maxResults=0&location=US&prettyPrint=false: Function not found: TO_DATE at [13:17]')
2021-07-13 16:59:00.831265 (Thread-1): finished collecting timing info
2021-07-13 16:59:00.833488 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Function not found: TO_DATE at [13:17]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/f2be6dd4-1546-46a7-b7f4-f2b8462a186a?maxResults=0&location=US&prettyPrint=false: Function not found: TO_DATE at [13:17]

(job ID: f2be6dd4-1546-46a7-b7f4-f2b8462a186a)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		TO_DATE(release_date, 'YYYY') AS release_year,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Function not found: TO_DATE at [13:17]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:59:00.838037 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85d29811-6127-47d6-b846-3037d2e4b397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe31318ef10>]}
2021-07-13 16:59:00.839613 (Thread-1): 11:59:00 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 2.56s]
2021-07-13 16:59:00.842363 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 16:59:00.843176 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 16:59:00.844637 (Thread-1): 11:59:00 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 16:59:00.846962 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 16:59:00.847963 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 16:59:00.849061 (Thread-1): 11:59:00 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 16:59:00.850616 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 16:59:00.861563 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 16:59:00.863936 (MainThread): 11:59:00 | 
2021-07-13 16:59:00.867369 (MainThread): 11:59:00 | Finished running 4 view models in 6.01s.
2021-07-13 16:59:00.868784 (MainThread): Connection 'master' was properly closed.
2021-07-13 16:59:00.869344 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 16:59:00.877406 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51678, 0, 0), raddr=('2607:f8b0:4000:805::200a', 443, 0, 0)>
2021-07-13 16:59:00.879374 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51677, 0, 0), raddr=('2607:f8b0:4023:1000::5f', 443, 0, 0)>
2021-07-13 16:59:00.880667 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51679, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:59:00.881656 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51680, 0, 0), raddr=('2607:f8b0:4023:1006::5f', 443, 0, 0)>
2021-07-13 16:59:00.887085 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51683, 0, 0), raddr=('2607:f8b0:4023:1004::5f', 443, 0, 0)>
2021-07-13 16:59:00.888291 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 51684, 0, 0), raddr=('2607:f8b0:4000:806::200a', 443, 0, 0)>
2021-07-13 16:59:00.918110 (MainThread): 
2021-07-13 16:59:00.919495 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 16:59:00.937067 (MainThread): 
2021-07-13 16:59:00.939233 (MainThread): Database Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 16:59:00.949375 (MainThread):   Type not found: nvarchar at [12:30]
2021-07-13 16:59:00.950635 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 16:59:00.958792 (MainThread): 
2021-07-13 16:59:00.959643 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 16:59:00.961357 (MainThread):   Function not found: TO_DATE at [13:17]
2021-07-13 16:59:00.962547 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 16:59:00.963604 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 16:59:00.965605 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313c619d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313b2aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe313b44a90>]}
2021-07-13 16:59:00.966377 (MainThread): Flushing usage events
2021-07-13 17:22:00.691495 (MainThread): Running with dbt=0.19.2
2021-07-13 17:22:01.335219 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/zfan/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-07-13 17:22:01.336325 (MainThread): Tracking: tracking
2021-07-13 17:22:01.352757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae0a6ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aff5ad160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae0a8f460>]}
2021-07-13 17:22:01.369376 (MainThread): Partial parsing not enabled
2021-07-13 17:22:01.371584 (MainThread): Parsing macros/adapters.sql
2021-07-13 17:22:01.404377 (MainThread): Parsing macros/catalog.sql
2021-07-13 17:22:01.413220 (MainThread): Parsing macros/etc.sql
2021-07-13 17:22:01.416417 (MainThread): Parsing macros/materializations/copy.sql
2021-07-13 17:22:01.422301 (MainThread): Parsing macros/materializations/incremental.sql
2021-07-13 17:22:01.432586 (MainThread): Parsing macros/materializations/seed.sql
2021-07-13 17:22:01.434928 (MainThread): Parsing macros/materializations/snapshot.sql
2021-07-13 17:22:01.436539 (MainThread): Parsing macros/materializations/table.sql
2021-07-13 17:22:01.444338 (MainThread): Parsing macros/materializations/view.sql
2021-07-13 17:22:01.452397 (MainThread): Parsing macros/core.sql
2021-07-13 17:22:01.455944 (MainThread): Parsing macros/adapters/common.sql
2021-07-13 17:22:01.490201 (MainThread): Parsing macros/etc/datetime.sql
2021-07-13 17:22:01.497360 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-07-13 17:22:01.498353 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-07-13 17:22:01.499886 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-07-13 17:22:01.501680 (MainThread): Parsing macros/etc/is_incremental.sql
2021-07-13 17:22:01.503146 (MainThread): Parsing macros/etc/query.sql
2021-07-13 17:22:01.504175 (MainThread): Parsing macros/materializations/helpers.sql
2021-07-13 17:22:01.511913 (MainThread): Parsing macros/materializations/common/merge.sql
2021-07-13 17:22:01.522655 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-07-13 17:22:01.524324 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-07-13 17:22:01.529138 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-07-13 17:22:01.544889 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-07-13 17:22:01.568439 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-07-13 17:22:01.569976 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-07-13 17:22:01.583514 (MainThread): Parsing macros/materializations/table/table.sql
2021-07-13 17:22:01.588691 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-07-13 17:22:01.592583 (MainThread): Parsing macros/materializations/view/view.sql
2021-07-13 17:22:01.597333 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-07-13 17:22:01.599526 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-07-13 17:22:01.600843 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-07-13 17:22:01.602520 (MainThread): Parsing macros/schema_tests/unique.sql
2021-07-13 17:22:01.608548 (MainThread): Partial parsing not enabled
2021-07-13 17:22:01.814668 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_genres".
2021-07-13 17:22:01.824594 (MainThread): Acquiring new bigquery connection "model.spotify_project.top20_artist_tracks".
2021-07-13 17:22:01.828434 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:22:01.831962 (MainThread): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:22:01.902594 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'caa89982-20ad-436b-a025-3a98ae6fc61e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae07c0fd0>]}
2021-07-13 17:22:01.907403 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'caa89982-20ad-436b-a025-3a98ae6fc61e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae08e6850>]}
2021-07-13 17:22:01.907722 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-07-13 17:22:01.908946 (MainThread): 
2021-07-13 17:22:01.909374 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:22:01.910405 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_spotify600k".
2021-07-13 17:22:01.910697 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-07-13 17:22:02.322786 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_spotify600k_tap_csv".
2021-07-13 17:22:02.323565 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-07-13 17:22:02.336582 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-07-13 17:22:02.718940 (MainThread): 12:22:02 | Concurrency: 1 threads (target='prod')
2021-07-13 17:22:02.720387 (MainThread): 12:22:02 | 
2021-07-13 17:22:02.746284 (Thread-1): Began running node model.spotify_project.stg_artists
2021-07-13 17:22:02.747300 (Thread-1): 12:22:02 | 1 of 4 START view model tap_csv.stg_artists.......................... [RUN]
2021-07-13 17:22:02.748589 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_artists".
2021-07-13 17:22:02.749060 (Thread-1): Compiling model.spotify_project.stg_artists
2021-07-13 17:22:02.756428 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:22:02.758877 (Thread-1): finished collecting timing info
2021-07-13 17:22:02.807037 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_artists"
2021-07-13 17:22:02.808233 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:22:02.812752 (Thread-1): On model.spotify_project.stg_artists: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
  OPTIONS()
  as SELECT id AS artist_id,
		CASE WHEN followers='' THEN 0
			 ELSE CAST(CAST(followers AS numeric) AS integer)
		END
		AS followers,
		genres,
		CAST(name AS varchar(255)) AS artist_name,
		CAST(popularity AS integer) AS artist_popularity
FROM `spotify600k`.`spotify`.`artists`;


2021-07-13 17:22:03.714760 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/6957b85c-f906-41b3-ba93-9ba377dff780?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]')
2021-07-13 17:22:05.035973 (Thread-1): finished collecting timing info
2021-07-13 17:22:05.037608 (Thread-1): Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/cd3548e3-0674-45cd-ae9a-fe5a2425af12?maxResults=0&location=US&prettyPrint=false: Type not found: varchar at [12:30]

(job ID: cd3548e3-0674-45cd-ae9a-fe5a2425af12)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_artists"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_artists`
   5:  OPTIONS()
   6:  as SELECT id AS artist_id,
   7:		CASE WHEN followers='' THEN 0
   8:			 ELSE CAST(CAST(followers AS numeric) AS integer)
   9:		END
  10:		AS followers,
  11:		genres,
  12:		CAST(name AS varchar(255)) AS artist_name,
  13:		CAST(popularity AS integer) AS artist_popularity
  14:FROM `spotify600k`.`spotify`.`artists`;
  15:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_artists (models/staging/stg_artists.sql)
  Type not found: varchar at [12:30]
  compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 17:22:05.063767 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caa89982-20ad-436b-a025-3a98ae6fc61e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae088c250>]}
2021-07-13 17:22:05.065482 (Thread-1): 12:22:05 | 1 of 4 ERROR creating view model tap_csv.stg_artists................. [ERROR in 2.32s]
2021-07-13 17:22:05.067995 (Thread-1): Finished running node model.spotify_project.stg_artists
2021-07-13 17:22:05.068739 (Thread-1): Began running node model.spotify_project.stg_tracks
2021-07-13 17:22:05.070592 (Thread-1): 12:22:05 | 2 of 4 START view model tap_csv.stg_tracks........................... [RUN]
2021-07-13 17:22:05.072518 (Thread-1): Acquiring new bigquery connection "model.spotify_project.stg_tracks".
2021-07-13 17:22:05.073069 (Thread-1): Compiling model.spotify_project.stg_tracks
2021-07-13 17:22:05.076018 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62974, 0, 0), raddr=('2607:f8b0:4023:1000::5f', 443, 0, 0)>
2021-07-13 17:22:05.077029 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62975, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 17:22:05.087369 (Thread-1): Writing injected SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:22:05.091060 (Thread-1): finished collecting timing info
2021-07-13 17:22:05.099870 (Thread-1): Writing runtime SQL for node "model.spotify_project.stg_tracks"
2021-07-13 17:22:05.103627 (Thread-1): Opening a new connection, currently in state closed
2021-07-13 17:22:05.122304 (Thread-1): On model.spotify_project.stg_tracks: /* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */


  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
  OPTIONS()
  as SELECT id AS track_id,
		name AS track_name,
		CAST(popularity AS integer) AS track_popularity,
		CAST(duration_ms AS integer) AS duration_ms,
		CAST(explicit AS boolean) AS explicit ,
		artists,
		id_artists AS artist_id,
		release_date,
		CAST(danceability AS float) AS danceability,
		CAST(energy AS float) AS energy,
		CAST(key AS integer) AS key,
		CAST(loudness AS float) AS loudness,
		CAST(mode AS integer) AS mode,
		CAST(speechiness AS float) AS speechiness,
		CAST(acousticness AS float) AS acousticness,
		CAST(instrumentalness AS float) AS instrumentalness,
		CAST(liveness AS float) AS liveness,
		CAST(valence AS float) AS valence,
		CAST(tempo AS float) AS tempo,
		CAST(time_signature AS integer) AS time_signature
FROM `spotify600k`.`spotify`.`tracks`;


2021-07-13 17:22:05.802379 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/80ea261e-9cfa-4c71-876b-41f744f54b58?maxResults=0&location=US&prettyPrint=false: Type not found: float at [14:38]')
2021-07-13 17:22:07.239578 (Thread-1): finished collecting timing info
2021-07-13 17:22:07.241023 (Thread-1): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Type not found: float at [14:38]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 151, in exception_handler
    yield
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 522, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/spotify600k/queries/8ffc463b-233c-4dd9-85da-c464ea298c5c?maxResults=0&location=US&prettyPrint=false: Type not found: float at [14:38]

(job ID: 8ffc463b-233c-4dd9-85da-c464ea298c5c)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.2", "profile_name": "spotify_project", "target_name": "prod", "node_id": "model.spotify_project.stg_tracks"} */
   2:
   3:
   4:  create or replace view `spotify600k`.`tap_csv`.`stg_tracks`
   5:  OPTIONS()
   6:  as SELECT id AS track_id,
   7:		name AS track_name,
   8:		CAST(popularity AS integer) AS track_popularity,
   9:		CAST(duration_ms AS integer) AS duration_ms,
  10:		CAST(explicit AS boolean) AS explicit ,
  11:		artists,
  12:		id_artists AS artist_id,
  13:		release_date,
  14:		CAST(danceability AS float) AS danceability,
  15:		CAST(energy AS float) AS energy,
  16:		CAST(key AS integer) AS key,
  17:		CAST(loudness AS float) AS loudness,
  18:		CAST(mode AS integer) AS mode,
  19:		CAST(speechiness AS float) AS speechiness,
  20:		CAST(acousticness AS float) AS acousticness,
  21:		CAST(instrumentalness AS float) AS instrumentalness,
  22:		CAST(liveness AS float) AS liveness,
  23:		CAST(valence AS float) AS valence,
  24:		CAST(tempo AS float) AS tempo,
  25:		CAST(time_signature AS integer) AS time_signature
  26:FROM `spotify600k`.`spotify`.`tracks`;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 340, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 331, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 536, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 155, in exception_handler
    self.handle_error(e, message)
  File "/home/zfan/.venv/meltano/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 143, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_tracks (models/staging/stg_tracks.sql)
  Type not found: float at [14:38]
  compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:22:07.244513 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caa89982-20ad-436b-a025-3a98ae6fc61e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae060eb20>]}
2021-07-13 17:22:07.245791 (Thread-1): 12:22:07 | 2 of 4 ERROR creating view model tap_csv.stg_tracks.................. [ERROR in 2.17s]
2021-07-13 17:22:07.248123 (Thread-1): Finished running node model.spotify_project.stg_tracks
2021-07-13 17:22:07.248873 (Thread-1): Began running node model.spotify_project.top20_artist_genres
2021-07-13 17:22:07.250510 (Thread-1): 12:22:07 | 3 of 4 SKIP relation tap_csv.top20_artist_genres..................... [SKIP]
2021-07-13 17:22:07.251693 (Thread-1): Finished running node model.spotify_project.top20_artist_genres
2021-07-13 17:22:07.252315 (Thread-1): Began running node model.spotify_project.top20_artist_tracks
2021-07-13 17:22:07.253274 (Thread-1): 12:22:07 | 4 of 4 SKIP relation tap_csv.top20_artist_tracks..................... [SKIP]
2021-07-13 17:22:07.254622 (Thread-1): Finished running node model.spotify_project.top20_artist_tracks
2021-07-13 17:22:07.265142 (MainThread): Acquiring new bigquery connection "master".
2021-07-13 17:22:07.266703 (MainThread): 12:22:07 | 
2021-07-13 17:22:07.268012 (MainThread): 12:22:07 | Finished running 4 view models in 5.36s.
2021-07-13 17:22:07.269250 (MainThread): Connection 'master' was properly closed.
2021-07-13 17:22:07.269737 (MainThread): Connection 'model.spotify_project.stg_tracks' was properly closed.
2021-07-13 17:22:07.283182 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62971, 0, 0), raddr=('2607:f8b0:4000:800::200a', 443, 0, 0)>
2021-07-13 17:22:07.284660 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62970, 0, 0), raddr=('2607:f8b0:4023:1002::5f', 443, 0, 0)>
2021-07-13 17:22:07.286025 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62972, 0, 0), raddr=('2607:f8b0:4000:810::200a', 443, 0, 0)>
2021-07-13 17:22:07.287298 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62973, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 17:22:07.296630 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62976, 0, 0), raddr=('2607:f8b0:4000:80e::200a', 443, 0, 0)>
2021-07-13 17:22:07.303326 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('2603:8080:570a:8100:7d3c:f450:51bb:ac40', 62977, 0, 0), raddr=('2607:f8b0:4000:80a::200a', 443, 0, 0)>
2021-07-13 17:22:07.316351 (MainThread): 
2021-07-13 17:22:07.316929 (MainThread): Completed with 2 errors and 0 warnings:
2021-07-13 17:22:07.317567 (MainThread): 
2021-07-13 17:22:07.318747 (MainThread): Database Error in model stg_artists (models/staging/stg_artists.sql)
2021-07-13 17:22:07.319651 (MainThread):   Type not found: varchar at [12:30]
2021-07-13 17:22:07.320529 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_artists.sql
2021-07-13 17:22:07.321434 (MainThread): 
2021-07-13 17:22:07.322234 (MainThread): Database Error in model stg_tracks (models/staging/stg_tracks.sql)
2021-07-13 17:22:07.323097 (MainThread):   Type not found: float at [14:38]
2021-07-13 17:22:07.323974 (MainThread):   compiled SQL at target/run/spotify_project/models/staging/stg_tracks.sql
2021-07-13 17:22:07.324908 (MainThread): 
Done. PASS=0 WARN=0 ERROR=2 SKIP=2 TOTAL=4
2021-07-13 17:22:07.326457 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae07995e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae0816c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ae0a0a5b0>]}
2021-07-13 17:22:07.326914 (MainThread): Flushing usage events
